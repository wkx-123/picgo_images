---
typora-root-url: ./
---

![image-20220228104845816](/assets/image-20220228104845816.png)

第一天 

## 一、HTTP 介绍

HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。

HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。

### 1、HTTP 工作原理

HTTP协议工作于客户端-服务端架构上。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。

Web服务器有：Nginx，Apache服务器，IIS服务器（Internet Information Services）等。

Web服务器根据接收到的请求后，向客户端发送响应信息。

HTTP默认端口号为80，但是你也可以改为8080或者其他端口。

**HTTP三点注意事项：**

- HTTP是无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。
- HTTP是媒体独立的：这意味着，只要客户端和服务器知道如何处理的数据内容，任何类型的数据都可以通过HTTP发送。客户端以及服务器指定使用适合的MIME-type内容类型。 
- HTTP是无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。

以下图表展示了HTTP协议通信流程：

![cgiarch](assets/cgiarch.gif)

### 2、HTTP 消息结构

HTTP是基于客户端/服务端（C/S）的架构模型，通过一个可靠的链接来交换信息，是一个无状态的请求/响应协议。

一个HTTP"客户端"是一个应用程序（Web浏览器或其他任何客户端），通过连接到服务器达到向服务器发送一个或多个HTTP的请求的目的。

一个HTTP"服务器"同样也是一个应用程序（通常是一个Web服务，如Apache Web服务器或IIS服务器等），通过接收客户端的请求并向客户端发送HTTP响应数据。

HTTP使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。

一旦建立连接后，数据消息就通过类似Internet邮件所使用的格式[RFC5322]和多用途Internet邮件扩展（MIME）[RFC2045]来传送。

### 3、客户端请求消息

客户端发送一个HTTP请求到服务器的请求消息包括以下格式：请求行（request line）、请求头部（header）、空行和请求数据四个部分组成，下图给出了请求报文的一般格式。![2012072810301161](assets/2012072810301161.png)

### 4、服务器响应消息

HTTP响应也由四个部分组成，分别是：状态行、消息报头、空行和响应正文。

![httpmessage](assets/httpmessage.jpg)

**实例**

下面实例是一点典型的使用GET来传递数据的实例：

客户端请求：

```http
GET /hello.txt HTTP/1.1
User-Agent: curl/7.16.3 libcurl/7.16.3 OpenSSL/0.9.7l zlib/1.2.3
Host: www.example.com
Accept-Language: en, mi
```

服务端响应:

```http
HTTP/1.1 200 OK
Date: Mon, 27 Jul 2009 12:28:53 GMT
Server: Apache
Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT
ETag: "34aa387-d-1568eb00"
Accept-Ranges: bytes
Content-Length: 51
Vary: Accept-Encoding
Content-Type: text/plain
```

输出结果：

```http
Hello World! My payload includes a trailing CRLF.
```

### 5、HTTP 请求方法

根据HTTP标准，HTTP请求可以使用多种请求方法。

HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法。

HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。

| 序号 | 方法    | 描述                                                         |
| ---- | ------- | ------------------------------------------------------------ |
| 1    | GET     | 请求指定的页面信息，并返回实体主体。                         |
| 2    | HEAD    | 类似于get请求，只不过返回的响应中没有具体的内容，用于获取报头 |
| 3    | POST    | 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改。 |
| 4    | PUT     | 从客户端向服务器传送的数据取代指定的文档的内容。             |
| 5    | DELETE  | 请求服务器删除指定的页面。                                   |
| 6    | CONNECT | HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。     |
| 7    | OPTIONS | 允许客户端查看服务器的性能。                                 |
| 8    | TRACE   | 回显服务器收到的请求，主要用于测试或诊断。                   |

### 6、HTTP 响应头信息

HTTP请求头提供了关于请求，响应或者其他的发送实体的信息。

在本章节中我们将具体来介绍HTTP响应头信息。

| 应答头           | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| Allow            | 服务器支持哪些请求方法（如GET、POST等）。                    |
| Content-Encoding | 文档的编码（Encode）方法。只有在解码之后才可以得到Content-Type头指定的内容类型。利用gzip压缩文档能够显著地减少HTML文档的下载时间。Java的GZIPOutputStream可以很方便地进行gzip压缩，但只有Unix上的Netscape和Windows上的IE 4、IE 5才支持它。因此，Servlet应该通过查看Accept-Encoding头（即request.getHeader("Accept-Encoding")）检查浏览器是否支持gzip，为支持gzip的浏览器返回经gzip压缩的HTML页面，为其他浏览器返回普通页面。 |
| Content-Length   | 表示内容长度。只有当浏览器使用持久HTTP连接时才需要这个数据。如果你想要利用持久连接的优势，可以把输出文档写入 ByteArrayOutputStream，完成后查看其大小，然后把该值放入Content-Length头，最后通过byteArrayStream.writeTo(response.getOutputStream()发送内容。 |
| Content-Type     | 表示后面的文档属于什么MIME类型。Servlet默认为text/plain，但通常需要显式地指定为text/html。由于经常要设置Content-Type，因此HttpServletResponse提供了一个专用的方法setContentType。 |
| Date             | 当前的GMT时间。你可以用setDateHeader来设置这个头以避免转换时间格式的麻烦。 |
| Expires          | 应该在什么时候认为文档已经过期，从而不再缓存它？             |
| Last-Modified    | 文档的最后改动时间。客户可以通过If-Modified-Since请求头提供一个日期，该请求将被视为一个条件GET，只有改动时间迟于指定时间的文档才会返回，否则返回一个304（Not Modified）状态。Last-Modified也可用setDateHeader方法来设置。 |
| Location         | 表示客户应当到哪里去提取文档。Location通常不是直接设置的，而是通过HttpServletResponse的sendRedirect方法，该方法同时设置状态代码为302。 |
| Refresh          | 表示浏览器应该在多少时间之后刷新文档，以秒计。除了刷新当前文档之外，你还可以通过setHeader("Refresh", "5; URL=http://host/path")让浏览器读取指定的页面。  注意这种功能通常是通过设置HTML页面HEAD区的＜META HTTP-EQUIV="Refresh" CONTENT="5;URL=http://host/path"＞实现，这是因为，自动刷新或重定向对于那些不能使用CGI或Servlet的HTML编写者十分重要。但是，对于Servlet来说，直接设置Refresh头更加方便。   注意Refresh的意义是"N秒之后刷新本页面或访问指定页面"，而不是"每隔N秒刷新本页面或访问指定页面"。因此，连续刷新要求每次都发送一个Refresh头，而发送204状态代码则可以阻止浏览器继续刷新，不管是使用Refresh头还是＜META HTTP-EQUIV="Refresh" ...＞。   注意Refresh头不属于HTTP 1.1正式规范的一部分，而是一个扩展，但Netscape和IE都支持它。 |
| Server           | 服务器名字。Servlet一般不设置这个值，而是由Web服务器自己设置。 |
| Set-Cookie       | 设置和页面关联的Cookie。Servlet不应使用response.setHeader("Set-Cookie", ...)，而是应使用HttpServletResponse提供的专用方法addCookie。参见下文有关Cookie设置的讨论。 |
| WWW-Authenticate | 客户应该在Authorization头中提供什么类型的授权信息？在包含401（Unauthorized）状态行的应答中这个头是必需的。例如，response.setHeader("WWW-Authenticate", "BASIC realm=＼"executives＼"")。  注意Servlet一般不进行这方面的处理，而是让Web服务器的专门机制来控制受密码保护页面的访问（例如.htaccess）。 |

### 7、HTTP 状态码

当浏览者访问一个网页时，浏览者的浏览器会向网页所在服务器发出请求。当浏览器接收并显示网页前，此网页所在的服务器会返回一个包含HTTP状态码的信息头（server header）用以响应浏览器的请求。

HTTP状态码的英文为HTTP Status Code。

下面是常见的HTTP状态码：

- 200 - 请求成功
- 301 - 资源（网页等）被永久转移到其它URL
- 404 - 请求的资源（网页等）不存在
- 500 - 内部服务器错误

**HTTP状态码分类**

HTTP状态码由三个十进制数字组成，第一个十进制数字定义了状态码的类型，后两个数字没有分类的作用。HTTP状态码共分为5种类型：

| 分类 | 分类描述                                       |
| ---- | ---------------------------------------------- |
| 1**  | 信息，服务器收到请求，需要请求者继续执行操作   |
| 2**  | 成功，操作被成功接收并处理                     |
| 3**  | 重定向，需要进一步的操作以完成请求             |
| 4**  | 客户端错误，请求包含语法错误或无法完成请求     |
| 5**  | 服务器错误，服务器在处理请求的过程中发生了错误 |

HTTP状态码列表:

| 状态码 | 状态码英文名称                  | 中文描述                                                     |
| ------ | ------------------------------- | ------------------------------------------------------------ |
| 100    | Continue                        | 继续。客户端应继续其请求                                     |
| 101    | Switching Protocols             | 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 |
|        |                                 |                                                              |
| 200    | OK                              | 请求成功。一般用于GET与POST请求                              |
| 201    | Created                         | 已创建。成功请求并创建了新的资源                             |
| 202    | Accepted                        | 已接受。已经接受请求，但未处理完成                           |
| 203    | Non-Authoritative Information   | 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 |
| 204    | No Content                      | 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 |
| 205    | Reset Content                   | 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 |
| 206    | Partial Content                 | 部分内容。服务器成功处理了部分GET请求                        |
|        |                                 |                                                              |
| 300    | Multiple Choices                | 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 |
| 301    | Moved Permanently               | 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 |
| 302    | Found                           | 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI |
| 303    | See Other                       | 查看其它地址。与301类似。使用GET和POST请求查看               |
| 304    | Not Modified                    | 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 |
| 305    | Use Proxy                       | 使用代理。所请求的资源必须通过代理访问                       |
| 306    | Unused                          | 已经被废弃的HTTP状态码                                       |
| 307    | Temporary Redirect              | 临时重定向。与302类似。使用GET请求重定向                     |
|        |                                 |                                                              |
| 400    | Bad Request                     | 客户端请求的语法错误，服务器无法理解                         |
| 401    | Unauthorized                    | 请求要求用户的身份认证                                       |
| 402    | Payment Required                | 保留，将来使用                                               |
| 403    | Forbidden                       | 服务器理解请求客户端的请求，但是拒绝执行此请求               |
| 404    | Not Found                       | 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面 |
| 405    | Method Not Allowed              | 客户端请求中的方法被禁止                                     |
| 406    | Not Acceptable                  | 服务器无法根据客户端请求的内容特性完成请求                   |
| 407    | Proxy Authentication Required   | 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 |
| 408    | Request Time-out                | 服务器等待客户端发送的请求时间过长，超时                     |
| 409    | Conflict                        | 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突 |
| 410    | Gone                            | 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 |
| 411    | Length Required                 | 服务器无法处理客户端发送的不带Content-Length的请求信息       |
| 412    | Precondition Failed             | 客户端请求信息的先决条件错误                                 |
| 413    | Request Entity Too Large        | 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 |
| 414    | Request-URI Too Large           | 请求的URI过长（URI通常为网址），服务器无法处理               |
| 415    | Unsupported Media Type          | 服务器无法处理请求附带的媒体格式                             |
| 416    | Requested range not satisfiable | 客户端请求的范围无效                                         |
| 417    | Expectation Failed              | 服务器无法满足Expect的请求头信息                             |
|        |                                 |                                                              |
| 500    | Internal Server Error           | 服务器内部错误，无法完成请求                                 |
| 501    | Not Implemented                 | 服务器不支持请求的功能，无法完成请求                         |
| 502    | Bad Gateway                     | 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 |
| 503    | Service Unavailable             | 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 |
| 504    | Gateway Time-out                | 充当网关或代理的服务器，未及时从远端服务器获取请求           |
| 505    | HTTP Version not supported      | 服务器不支持请求的HTTP协议的版本，无法完成处理               |

## 二、nginx 服务

### 1、nginx 介绍

![nginx](assets/nginx.jpg)

 *Nginx* (engine x) 是一个高性能的 HTTP 和 反向代理 服务，也是一个IMAP/POP3/SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，第一个公开版本0.1.0发布于2004年10月4日。其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。2011年6月1日，nginx 1.0.4发布。

Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、[京东](https://baike.baidu.com/item/%E4%BA%AC%E4%B8%9C/210931)、[新浪](https://baike.baidu.com/item/%E6%96%B0%E6%B5%AA/125692)、[网易](https://baike.baidu.com/item/%E7%BD%91%E6%98%93/185754)、[腾讯](https://baike.baidu.com/item/%E8%85%BE%E8%AE%AF/112204)、[淘宝](https://baike.baidu.com/item/%E6%B7%98%E5%AE%9D/145661)等。

在高连接并发的情况下，Nginx是Apache服务器不错的替代品。

**创始人伊戈尔·赛索耶夫**

![2fdda3cc7cd98d10d7efa38e2b3fb80e7bec9052](assets/2fdda3cc7cd98d10d7efa38e2b3fb80e7bec9052.jpg)

![123](/assets/123.jpg)

### 2、为什么选择 nginx 

Nginx 是一个高性能的 Web 和反向代理服务器, 它具有有很多非常优越的特性:

**作为 Web 服务器**：相比 Apache，Nginx 使用更少的资源，支持更多的并发连接，体现更高的效率，这点使 Nginx 尤其受到虚拟主机提供商的欢迎。能够支持高达 50,000 个并发连接数的响应，感谢 Nginx 为我们选择了 epoll and kqueue 作为开发模型.

**作为负载均衡服务器**：Nginx 既可以在内部直接支持 Rails 和 PHP，也可以支持作为 HTTP代理服务器 对外进行服务。Nginx 用 C 编写, 不论是系统资源开销还是 CPU 使用效率都比 Perlbal 要好的多。

**作为邮件代理服务器**: Nginx 同时也是一个非常优秀的邮件代理服务器（最早开发这个产品的目的之一也是作为邮件代理服务器），Last.fm 描述了成功并且美妙的使用经验。

**Nginx 安装非常的简单，配置文件 非常简洁（还能够支持perl语法），Bugs非常少的服务器**: Nginx 启动特别容易，并且几乎可以做到7*24不间断运行，即使运行数个月也不需要重新启动。你还能够在 不间断服务的情况下进行软件版本的升级。

### 3、IO多路复用

#### 1、I/O multiplexing【多并发】

第一种方法就是最传统的多进程并发模型 (每进来一个新的I/O流会分配一个新的进程管理。)

第二种方法就是I/O多路复用 (单个线程，通过记录跟踪每个I/O流(sock)的状态，来同时管理多个I/O流 。)

![1](assets/1.png)

I/O multiplexing 这里面的 multiplexing 指的其实是在单个线程通过记录跟踪每一个Sock(I/O流)的状态来同

时管理多个I/O流。发明它的原因，是尽量多的提高服务器的吞吐能力。

在同一个线程里面， 通过拨开关的方式，来同时传输多个I/O流

![2](assets/2-1552270732106.png)

#### 2、一个请求到来了，nginx使用epoll接收请求的过程是怎样的?

ngnix会有很多连接进来， epoll会把他们都监视起来，然后像拨开关一样，谁有数据就拨向谁，然后调用相

应的代码处理。

- **select, poll, epoll** 都是I/O多路复用的具体的实现，其实是他们出现是有先后顺序的。 

I/O多路复用这个概念被提出来以后， 相继出现了多个方案

- **select**是第一个实现 (1983 左右在BSD里面实现的)。 

select 被实现以后，很快就暴露出了很多问题。

• select 会修改传入的参数数组，这个对于一个需要调用很多次的函数，是非常不友好的。

• select 如果任何一个sock(I/O stream)出现了数据，select 仅仅会返回，但是并不会告诉你是那个sock上有数

据，于是你只能自己一个一个的找，10几个sock可能还好，要是几万的sock每次都找一遍...

• select 只能监视1024个链接。

• select 不是线程安全的，如果你把一个sock加入到select, 然后突然另外一个线程发现，这个sock不用，要收

回，这个select 不支持的，如果你丧心病狂的竟然关掉这个sock, select的标准行为是不可预测的

- 于是14年以后(1997年）一帮人又实现了**poll,**  poll 修复了select的很多问题，比如

• poll 去掉了1024个链接的限制，于是要多少链接呢， 主人你开心就好。

• poll 从设计上来说，不再修改传入数组，不过这个要看你的平台了，所以行走江湖，还是小心为妙。

其实拖14年那么久也不是效率问题， 而是那个时代的硬件实在太弱，一台服务器处理1千多个链接简直就是神

一样的存在了，select很长段时间已经满足需求。 

但是poll仍然不是线程安全的， 这就意味着，不管服务器有多强悍，你也只能在一个线程里面处理一组I/O流。

你当然可以那多进程来配合了，不过然后你就有了多进程的各种问题。

- 于是5年以后, 在2002, 大神 Davide Libenzi 实现了**epoll**. 

epoll 可以说是I/O 多路复用最新的一个实现，epoll 修复了poll 和select绝大部分问题, 比如：

• epoll 现在是线程安全的。 

• epoll 现在不仅告诉你sock组里面数据，还会告诉你具体哪个sock有数据，你不用自己去找了。

#### 3、异步，非阻塞

$ pstree |grep nginx
 |-+= 81666 root nginx: master process nginx
 | |--- 82500 nobody nginx: worker process
 | \--- 82501 nobody nginx: worker process

 1个master进程，2个work进程

​     每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到什么程度呢？处理

到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理

的worker不会这么一直等着，他会在发送完请求后，注册一个事件：“如果upstream返回了，告诉我一声，

我再接着干”。于是他就休息去了。这就是异步。此时，如果再有request 进来，他就可以很快再按这种

方式处理。这就是非阻塞和IO多路复用。而一旦上游服务器返回了，就会触发这个事件，worker才会来

接手，这个request才会接着往下走。这就是异步回调。

### 4、nginx 的内部技术架构  

Nginx服务器，以其处理网络请求的高并发、高性能及高效率，获得了行业界的广泛认可，近年已稳居web服务器部署排名第二的位置，并被广泛用于反向代理和负载均衡。

Nginx是如何实现这些目标的呢？答案就是其独特的内部技术架构设计。看懂下面这张图，就明白了Nginx的内部技术架构。

![img](assets/2517ca78056c497db1c3a804118bb891_th.png)

简要说明几点：

1）nginx启动时，会生成两种类型的进程，一个是主进程（Master），一个（windows版本的目前只有一个）或多个工作进程（Worker）。主进程并不处理网络请求，主要负责调度工作进程，也就是图示的三项：加载配置、启动工作进程及非停升级。所以，nginx启动以后，查看操作系统的进程列表，我们就能看到至少有两个nginx进程。

2）服务器实际处理网络请求及响应的是工作进程（worker），在类unix系统上，nginx可以配置多个worker，而每个worker进程都可以同时处理数以千计的网络请求。

3）模块化设计。nginx的worker，包括核心和功能性模块，核心模块负责维持一个运行循环（run-loop），执行网络请求处理的不同阶段的模块功能，如网络读写、存储读写、内容传输、外出过滤，以及将请求发往上游服务器等。而其代码的模块化设计，也使得我们可以根据需要对功能模块进行适当的选择和修改，编译成具有特定功能的服务器。

4）事件驱动、异步及非阻塞，可以说是nginx得以获得高并发、高性能的关键因素，同时也得益于对Linux、Solaris及类BSD等操作系统内核中事件通知及I/O性能增强功能的采用，如kqueue、epoll及event ports。

5）代理（proxy）设计，可以说是nginx深入骨髓的设计，无论是对于HTTP，还是对于FastCGI、memcache、Redis等的网络请求或响应，本质上都采用了代理机制。所以，nginx天生就是高性能的代理服务器   

### 5、nginx 安装部署和配置管理

#### 1、nginx 部署-Yum

访问nginx官方网站：http://www.nginx.org

Nginx版本类型

Mainline version：   主线版，即开发版

Stable version：       最新稳定版，生产环境上建议使用的版本

Legacy versions：    遗留的老版本的稳定版

![捕获](assets/捕获.PNG)

**Yum安装Nginx**

##### a、**官方安装指导**

Installation instructions

Before you install nginx for the first time on a new machine, you need to set up the nginx packages repository. Afterward, you can install and update nginx from the repository.

**RHEL/CentOS**

Install the prerequisites:

> ```
> sudo yum install yum-utils
> ```

To set up the yum repository, create the file named `/etc/yum.repos.d/nginx.repo` with the following contents:

> ```
> [nginx-stable]
> name=nginx stable repo
> baseurl=http://nginx.org/packages/centos/$releasever/$basearch/
> gpgcheck=1
> enabled=1
> gpgkey=https://nginx.org/keys/nginx_signing.key
> 
> [nginx-mainline]
> name=nginx mainline repo
> baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/
> gpgcheck=1
> enabled=0
> gpgkey=https://nginx.org/keys/nginx_signing.key
> ```

By default, the repository for stable nginx packages is used. If you would like to use mainline nginx packages, run the following command:

> ```
> sudo yum-config-manager --enable nginx-mainline
> ```

To install nginx, run the following command:

> ```
> sudo yum install nginx
> ```

When prompted to accept the GPG key, verify that the fingerprint matches `573B FD6B 3D8F BC64 1079 A6AB ABF5 BD82 7BD9 BF62`, and if so, accept it.

##### b 、安装

[root@tianyun ~]# yum -y install nginx

[root@tianyun ~]# systemctl start nginx

[root@tianyun ~]# systemctl enable nginx

**查看防火墙状态， 需要关闭防火墙**

[root@tianyun ~]# getenforce 

Disabled

[root@tianyun ~]# systemctl status firewalld

● firewalld.service - firewalld - dynamic firewall daemon

   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor pres

et: enabled)   Active: inactive (dead)

​     Docs: man:firewalld(1)

**查看 nginx 安装版本**

[root@tianyun ~]# nginx -v

nginx version: nginx/1.14.2

[root@tianyun ~]# nginx -V

nginx version: nginx/1.14.2

built by gcc 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) 

built with OpenSSL 1.0.1e-fips 11 Feb 2013

TLS SNI support enabled

configure arguments:

 --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path

=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -pie'

**浏览器访问 tianyun.me (在访问机器上添加 hosts 解析)**

![nginx-html](assets/nginx-html.png)

#### 2、nginx 编译安装与配置使用

##### 1、安装编译环境

yum -y install gcc gcc-c++

##### 2、安装pcre软件包（使nginx支持http rewrite模块）

yum install -y pcre pcre-devel

##### 3、安装openssl-devel（使nginx支持ssl）

yum install -y openssl openssl-devel 

##### 4、安装zlib

yum install -y zlib zlib-devel

##### 5、创建用户nginx

useradd nginx 

passwd nginx

##### 6、安装nginx

```shell
[root@localhost ～]# wget http://nginx.org/download/nginx-1.14.2.tar.gz
```

```shell
[root@localhost ～] #tar -vzxf nginx-1.14.2.tar.gz -C /usr/local
[root@localhost ～] #cd nginx-1.14.2/ 
[root@localhost nginx-1.14.2]# ./configure \ 
--group=nginx \ 
--user=nginx \ 
--prefix=/usr/local/nginx \ 
--sbin-path=/usr/sbin/nginx \ 
--conf-path=/etc/nginx/nginx.conf \ 
--error-log-path=/var/log/nginx/error.log \ 
--http-log-path=/var/log/nginx/access.log \ 
--http-client-body-temp-path=/tmp/nginx/client_body \ 
--http-proxy-temp-path=/tmp/nginx/proxy \ 
--http-fastcgi-temp-path=/tmp/nginx/fastcgi \ 
--pid-path=/var/run/nginx.pid \ 
--lock-path=/var/lock/nginx \ 
--with-http_stub_status_module \ 
--with-http_ssl_module \ 
--with-http_gzip_static_module \ 
--with-pcre 
[root@localhost nginx-1.11.3]# make &&make install




---
./configure  --group=nginx --user=nginx --prefix=/usr/local/nginx --sbin-path=/usr/sbin/nginx  --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/tmp/nginx/client_body  --http-proxy-temp-path=/tmp/nginx/proxy  --http-fastcgi-temp-path=/tmp/nginx/fastcgi --pid-path=/var/run/nginx.pid --lock-path=/var/lock/nginx  --with-http_stub_status_module --with-http_ssl_module   --with-http_gzip_static_module --with-pcre
```

##### 7、Nginx 编译参数

```shell
# 查看 nginx 安装的模块
[root@tianyun ~]# nginx -V

# 模块参数具体功能 
--with-cc-opt='-g -O2 -fPIE -fstack-protector    //设置额外的参数将被添加到CFLAGS变量。（FreeBSD或者ubuntu使用）
--param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2' 
--with-ld-opt='-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now' 

--prefix=/usr/share/nginx                        //指向安装目录
--conf-path=/etc/nginx/nginx.conf                //指定配置文件
--http-log-path=/var/log/nginx/access.log        //指定访问日志
--error-log-path=/var/log/nginx/error.log        //指定错误日志
--lock-path=/var/lock/nginx.lock                 //指定lock文件
--pid-path=/run/nginx.pid                        //指定pid文件

--http-client-body-temp-path=/var/lib/nginx/body    //设定http客户端请求临时文件路径
--http-fastcgi-temp-path=/var/lib/nginx/fastcgi     //设定http fastcgi临时文件路径
--http-proxy-temp-path=/var/lib/nginx/proxy         //设定http代理临时文件路径
--http-scgi-temp-path=/var/lib/nginx/scgi           //设定http scgi临时文件路径
--http-uwsgi-temp-path=/var/lib/nginx/uwsgi         //设定http uwsgi临时文件路径

--with-debug                                        //启用debug日志
--with-pcre-jit                                     //编译PCRE包含“just-in-time compilation”
--with-ipv6                                         //启用ipv6支持
--with-http_ssl_module                              //启用ssl支持
--with-http_stub_status_module                      //获取nginx自上次启动以来的状态
--with-http_realip_module                 //允许从请求标头更改客户端的IP地址值，默认为关
--with-http_auth_request_module           //实现基于一个子请求的结果的客户端授权。如果该子请求返回的2xx响应代码，所述接入是允许的。如果它返回401或403中，访问被拒绝与相应的错误代码。由子请求返回的任何其他响应代码被认为是一个错误。
--with-http_addition_module               //作为一个输出过滤器，支持不完全缓冲，分部分响应请求
--with-http_dav_module                    //增加PUT,DELETE,MKCOL：创建集合,COPY和MOVE方法 默认关闭，需编译开启
--with-http_geoip_module                  //使用预编译的MaxMind数据库解析客户端IP地址，得到变量值
--with-http_gunzip_module                 //它为不支持“gzip”编码方法的客户端解压具有“Content-Encoding: gzip”头的响应。
--with-http_gzip_static_module            //在线实时压缩输出数据流
--with-http_image_filter_module           //传输JPEG/GIF/PNG 图片的一个过滤器）（默认为不启用。gd库要用到）
--with-http_spdy_module                   //SPDY可以缩短网页的加载时间
--with-http_sub_module                    //允许用一些其他文本替换nginx响应中的一些文本
--with-http_xslt_module                   //过滤转换XML请求
--with-mail                               //启用POP3/IMAP4/SMTP代理模块支持
--with-mail_ssl_module                    //启用ngx_mail_ssl_module支持启用外部模块支持
```

##### 8、修改配置文件/etc/nginx/nginx.conf

```shell
# 全局参数设置 
worker_processes  1;          #设置nginx启动进程的数量，一般设置成与逻辑cpu数量相同 
error_log  logs/error.log;    #指定错误日志 
worker_rlimit_nofile 102400;  #设置一个nginx进程能打开的最大文件数 
pid        /var/run/nginx.pid; 
events { 
    worker_connections  1024; #设置一个进程的最大并发连接数 
} 
# http 服务相关设置 
http { 
    include      mime.types; 
    default_type  application/octet-stream; 
    log_format  main  'remote_addr - remote_user [time_local] "request" '
                      'status body_bytes_sent "$http_referer" '
                      '"http_user_agent" "http_x_forwarded_for"'; 
    access_log  /var/log/nginx/access.log  main;    #设置访问日志的位置和格式 
    sendfile          on; #是否调用sendfile函数输出文件，一般设置为on，若nginx是用来进行磁盘IO负载应用时，可以设置为off，降低系统负载 
    gzip              on;      #是否开启gzip压缩 
    keepalive_timeout  65;     #设置长连接的超时时间 
# 虚拟服务器的相关设置 
    server { 
        listen      80;        #设置监听的端口 
        server_name  localhost;        #设置绑定的主机名、域名或ip地址 
        charset koi8-r;        # 设置编码字符
        location / { 
            root  /var/www/nginx;           #设置服务器默认网站的根目录位置 
            index  index.html index.htm;    #设置默认打开的文档 
            } 
        error_page  500 502 503 504  /50x.html; #设置错误信息返回页面 
        location = /50x.html { 
            root  html;        #这里的绝对位置是/var/www/nginx/html 
        } 
    } 
 }
```

##### 9、检测 nginx 配置文件是否正确

```shell
[root@localhost ~]#/usr/local/nginx/sbin/nginx -t
```

##### 10、启动nginx服务

```shell
/usr/local/nginx/sbin/nginx
```

##### 11、通过 nginx 命令控制 nginx 服务

```shell
nginx -c /path/to/nginx.conf  	 # 以特定目录下的配置文件启动nginx:
nginx -s reload            	 	 # 修改配置后重新加载生效
nginx -s reopen   			 	 # 重新打开日志文件
nginx -s stop  				 	 # 快速停止nginx
nginx -s quit  				  	 # 完整有序的停止nginx
nginx -t    					 # 测试当前配置文件是否正确
nginx -t -c /path/to/nginx.conf  # 测试特定的nginx配置文件是否正确
```

##### 12、实现nginx开机自启（使用源码安装，yum 安装可以直接enable）

 a、添加启动脚本  vim /etc/init.d/nginx

```shell
#!/bin/sh 
# 
# nginx - this script starts and stops the nginx daemon 
# 
# chkconfig:  - 85 15  
# description:  Nginx is an HTTP(S) server, HTTP(S) reverse \ 
#              proxy and IMAP/POP3 proxy server 
# processname: nginx 
# config:      /etc/nginx/nginx.conf 
# config:      /etc/sysconfig/nginx 
# pidfile:    /var/run/nginx.pid 
  
# Source function library. 
. /etc/rc.d/init.d/functions
  
# Source networking configuration. 
. /etc/sysconfig/network
  
# Check that networking is up. 
[ "$NETWORKING" = "no" ] && exit 0 
  
nginx="/usr/sbin/nginx"
prog=$(basename $nginx) 
  
NGINX_CONF_FILE="/etc/nginx/nginx.conf"
  
[ -f /etc/sysconfig/nginx ] && . /etc/sysconfig/nginx
  
lockfile=/var/lock/subsys/nginx
  
make_dirs() { 
  # make required directories 
  user=`nginx -V 2>&1 | grep "configure arguments:" | sed 's/[^*]*--user=\([^ ]*\).*/\1/g' -` 
  options=`$nginx -V 2>&1 | grep 'configure arguments:'` 
  for opt in $options; do
      if [ `echo $opt | grep '.*-temp-path'` ]; then
          value=`echo $opt | cut -d "=" -f 2` 
          if [ ! -d "$value" ]; then
              # echo "creating" $value 
              mkdir -p $value && chown -R $user $value 
          fi
      fi
  done
} 
  
start() { 
    [ -x $nginx ] || exit 5 
    [ -f $NGINX_CONF_FILE ] || exit 6 
    make_dirs 
    echo -n $"Starting $prog: "
    daemon $nginx -c $NGINX_CONF_FILE 
    retval=$? 
    echo
    [ $retval -eq 0 ] && touch $lockfile 
    return $retval 
} 
  
stop() { 
    echo -n $"Stopping $prog: "
    killproc $prog -QUIT 
    retval=$? 
    echo
    [ $retval -eq 0 ] && rm -f $lockfile 
    return $retval 
} 
  
restart() { 
    configtest || return $? 
    stop 
    sleep 1 
    start 
} 
  
reload() { 
    configtest || return $? 
    echo -n $"Reloading $prog: "
    killproc $nginx -HUP 
    RETVAL=$? 
    echo
} 
  
force_reload() { 
    restart 
} 
  
configtest() { 
  $nginx -t -c $NGINX_CONF_FILE 
} 
  
rh_status() { 
    status $prog 
} 
  
rh_status_q() { 
    rh_status >/dev/null 2>&1 
} 
  
case "$1" in
    start) 
        rh_status_q && exit 0 
        $1 
        ;; 
    stop) 
        rh_status_q || exit 0 
        $1 
        ;; 
    restart|configtest) 
        $1 
        ;; 
    reload) 
        rh_status_q || exit 7 
        $1 
        ;; 
    force-reload) 
        force_reload 
        ;; 
    status) 
        rh_status 
        ;; 
    condrestart|try-restart) 
        rh_status_q || exit 0 
            ;; 
    *) 
        echo $"Usage: $0 {start|stop|status|restart|condrestart|try-restart|reload|force-reload|configtest}"
        exit 2 
esac
```

b、添加权限

```shell
chmod +x /etc/init.d/nginx
```

c、重载系统启动文件

```shell
systemctl daemon-reload
```

d、设置开机自启

```shell
systemctl start nginx
```

10、nginx 日志文件详解

​    nginx 日志文件分为 **log_format** 和 **access_log** 两部分

​    log_format 定义记录的格式，其语法格式为

​    log_format        样式名称        样式详情

​    配置文件中默认有

```
log_format  main  'remote_addr - remote_user [time_local] "request" '
                  'status body_bytes_sent "$http_referer" '
                  '"http_user_agent" "http_x_forwarded_for"';
```

| 变量                                | 说明                                                        |
| ----------------------------------- | ----------------------------------------------------------- |
| $remote_addr和$http_x_forwarded_for | 客户端的ip                                                  |
| $remote_user                        | 客户端的名称                                                |
| $time_local                         | 访问时的本地时间                                            |
| $request                            | 请求的URL和http协议                                         |
| $status                             | 访问的状态码                                                |
| $body_bytes_sent                    | 发送给客户端的主体内容大小                                  |
| $http_referer                       | 记录客户端是从哪个页面链接访问过来的，若没有链接，则访问‘-’ |
| $http_user_agent                    | 记录客户端使用的浏览器的相关信息                            |

#### 6、nginx 高级应用

#####     1、使用 alias 实现虚拟目录

```shell
   location /tiger { 
    	alias /var/www/tiger; 
    	index index.html;    #访问http://x.x.x.x/tiger时实际上访问是/var/www/tiger/index.html
    	}
```

#####     2、通过 stub_status 模块监控 nginx 的工作状态

​        1、通过 nginx  -V 命令查看是否已安装 stub_status 模块

​        2、编辑 /etc/nginx/nginx.conf 配置文件

```shell
#添加以下内容～～ 
location /nginx-status { 
      stub_status on; 
      access_log    /var/log/nginx/nginxstatus.log;    #设置日志文件的位置 
      auth_basic    "nginx-status";    #指定认证机制（与location后面的内容相同即可） 
      auth_basic_user_file    /etc/nginx/htpasswd;     #指定认证的密码文件 
      }      
```

​       3、创建认证口令文件并添加用户 tiger和 zsgg，密码用md5加密

```
htpasswd -c -m /etc/nginx/htpasswd tiger             # -c 创建解密文件，-m MD5加密
htpasswd -m /etc/nginx/htpasswd zsgg

htpasswd 是开源 http 服务器 apache httpd 的一个命令工具，用于生成 http 基本认证的密码文件。
安装htpasswd: yum -y install httpd-tools
```

​       4、重启服务

​       5、客户端访问 http://x.x.x.x/nginx-status 即可

#####     3、使用 limit_rate 限制客户端传输数据的速度

​          1、编辑/etc/nginx/nginx.conf

```
 location / { 
    root    /var/www/nginx; 
    index    index.html; 
    limit_rate    2k;        #对每个连接的限速为2k/s
    }
```

​         2、重启服务

**注意要点：**

- ​    配置文件中的每个语句要以 ; 结尾

- ​    使用 htpasswd 命令需要先安装 httpd

####   7、nginx 虚拟主机配置

**什么是虚拟主机？**
虚拟主机是一种特殊的软硬件技术，它可以将网络上的每一台计算机分成多个虚拟主机，每个虚拟主机可以独立对外提供www服务，这样就可以实现一台主机对外提供多个web服务，每个虚拟主机之间是独立的，互不影响。

![824142-20170614222954712-1804018134](assets/824142-20170614222954712-1804018134.png)

nginx可以实现虚拟主机的配置，nginx支持三种类型的虚拟主机配置。
1、基于域名的虚拟主机 （server_name来区分虚拟主机——应用：外部网站）
2、基于ip的虚拟主机， （一块主机绑定多个ip地址）
3、基于端口的虚拟主机 （端口来区分虚拟主机——应用：公司内部网站，外部网站的管理后台）

##### 1、 基于域名的虚拟主机

1、配置通过域名区分的虚拟机

```
[root@nginx]# cat conf/nginx.conf
worker_processes 1;

events {
worker_connections 1024;
}

http {
include mime.types;
default_type application/octet-stream;

    server {
        listen        80;
        server_name  web.tiger.com;
        location /{
            root /tiger/html;
            index index.html index.htm;
                }
        }
    server {
        listen        80;
        server_name  web.1000phone.com;
        location /{
            root /1000phone/html;
            index index.html index.htm;
                }
        }
}
```

2、 为 域名为 web.1000phone.com 的虚拟机，创建 index 文件

```
[root@nginx ~]# mkdir -p /root/html
[root@nginx ~]# cd /root/html/
[root@nginx html]# vim index.html
[root@nginx html]# cat index.html 
<html>
<p>
this is my 1000phone
</p>
</html>
```

3、重新加载配置文件

```
# 如果编译安装的执行
[root@nginx]# /usr/local/nginx/bin/nginx -s reload
# 如果 yum 安装的执行
[root@nginx]# nginx -s reload
```

4、客户端配置路由映射
在 C:\Windows\System32\drivers\etc\hosts 文件中添加两行(linux:/etc/hosts)

```
10.219.24.26 web.tiger.com
10.219.24.26 web.1000phone.com
```

5、 测试访问

浏览器输入：http://web.tiger.com/



浏览器输入：http://web.1000phone.com/



 6、补充：如果配置不能正常访问，

问题描述： 配置完 nginx 两个虚拟机后，客户端能够访问原始的server ,新增加的 server 虚拟机 不能够访问，报错如下页面

![img](assets/824142-20170614201534618-1766240416.png)

解决过程：

1. 查看报错日志（找到错误日志）

  ```shell
  [root@nginx]# cat logs/error.log 
  2017/06/15 04:00:57 [error] 6702#0: *14 "/root/html/index.html" is forbidden (13: Permission denied), client: 10.219.24.1, server: web.1000phone.com, request: "GET / HTTP/1.1", host: "web.1000phone.com"
  [root@logs]# date
  Tue Mar 12 10:05:53 CST 2019
  ```

2. 检查权限

  ```shell
  [root@nginx ~]# ll
  drwxr-xr-x. 2 root root 4096 Jun 15 03:59 html
  [root@nginx html]# ll
  total 8
  -rw-r--r--. 1 root root 537 Jun 15 03:59 50x.html
  -rw-r--r--. 1 root root 616 Jun 15 03:51 index.html
  说明：发现目录权限没有问题
  ```

3. 检查nginx启动进程

  ```shell
  [root@nginx]# ps anx|grep nginx
  6546 ? Ss 0:00 nginx: master process ./sbin/nginx
  6702 ? S 0:00 nginx: worker process
  6726 pts/1 S+ 0:00 grep nginx
  说明：发现nginx的work process是 nobody 的
  ```

4. 修改 nginx.conf 文件

  ```shell
  打开nginx.conf文件所在的目录，查看文件的属性 （root root）
  [root@nginx]# ll
  drwxr-xr-x. 2 root root 4096 Jun 15 04:08 conf
  在nginx.conf文件的第一行加上 user root root;
  [root@nginx]# cat conf/nginx.conf
  user root root;
  ```

5. 重新 reload nginx进程

  ```shell
  [root@nginx]#nginx -s reload
  注意：
  nginx -s reload 命令加载修改后的配置文件,命令下达后发生如下事件
  1. Nginx的master进程检查配置文件的正确性，若是错误则返回错误信息，nginx继续采用原配置文件进行工作（因为worker未受到影响）
  2. Nginx启动新的worker进程，采用新的配置文件
  3. Nginx将新的请求分配新的worker进程
  4. Nginx等待以前的worker进程的全部请求已经都返回后，关闭相关worker进程
  5. 重复上面过程，直到全部旧的worker进程都被关闭掉
  ```

6. 再次访问，成功！

##### 2、 基于ip的虚拟主机

   1、一块网卡绑定多个ip

```shell
[root@nginx]# ifconfig eth0:1 192.168.95.200
[root@nginx]# ifconfig
eth0 Link encap:Ethernet HWaddr 00:0C:29:79:F4:02 
inet addr:192.168.95.134 Bcast:10.255.255.255 Mask:255.0.0.0
...
eth0:1 Link encap:Ethernet HWaddr 00:0C:29:79:F4:02 
inet addr:192.168.95.200 Bcast:10.255.255.255 Mask:255.0.0.0
UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1
```

2、配置通过ip区分的虚拟机 

```shell
[root@nginx]# cat conf/nginx.conf
user root root; #说明：这里的user根据 自己的nginx.conf文件所在的目录的属主属性而定 
worker_processes 1;

events {
worker_connections 1024;
}

http {
include mime.types;
default_type application/octet-stream;

server {
listen 192.168.95.134:80;
server_name www.nginx01.com;
location / {
root html;
index index.html index.htm;
}
}

server {
listen 192.168.95.100:80;
server_name www.nginx01.com;
location / {
root /root/html;
index index.html index.htm;
}
}
}
```

3、重新 reopen nginx 进程

```shell
[root@nginx]#nginx -s reopen
```

4、 测试访问

浏览器输入：http://192.168.95.134



浏览器输入：http://192.168.95.200

5、补充：

```shell
-- 删除绑定的vip
[root@nginx]#ifconfig eth0:1 192.168.95.100 down
```

##### 3、 基于端口的虚拟主机

```shell
[root@nginx]# cat conf/nginx.conf
user root root; #说明：这里的user根据 自己的nginx.conf文件所在的目录的属主属性而定 
worker_processes 1;

events {
worker_connections 1024;
}

http {
include mime.types;
default_type application/octet-stream;

server {
listen 80;
server_name www.1000phone01.com;
location / {
root html;
index index.html index.htm;
}
}

server {
listen 8080;
server_name www.1000phone02.com;
location / {
root /root/html;
index index.html index.htm;
}
}
}
```

2、重新 reload nginx进程

```shell
[root@nginx]#nginx -s reload
```

3、 测试访问

浏览器输入：http://1000phone01.com/



浏览器输入：http://1000phone02.com:8080

  

#### 8、nginx Proxy 代理

##### 1、代理原理   

- 反向代理产生的背景：

  在计算机世界里，由于单个服务器的处理客户端（用户）请求能力有一个极限，当用户的接入请求蜂拥而入时，会造成服务器忙不过来的局面，可以使用多个服务器来共同分担成千上万的用户请求，这些服务器提供相同的服务，对于用户来说，根本感觉不到任何差别。

- 反向代理服务的实现：

  需要有一个负载均衡设备（即反向代理服务器）来分发用户请求，将用户请求分发到空闲的服务器上。

  服务器返回自己的服务到负载均衡设备。

  负载均衡设备将服务器的服务返回用户。

![Nginx反向代理服务器、负载均衡和正向代理](https://tigerfive.oss-cn-beijing.aliyuncs.com/img/471c0000950856272d53.jpg)

![Nginx反向代理服务器、负载均衡和正向代理](https://tigerfive.oss-cn-beijing.aliyuncs.com/img/471c0000c802f568c182.jpg)

##### 2、正/反向代理的区别

那么问题来了，很多人这时会问什么是反向代理？为什么叫反向代理？什么是正向代理？我们来举例说明

- 正向代理：

  举例：贷款

  正向代理的过程隐藏了真实的请求客户端，服务器不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替请求。我们常说的代理也就是正向代理，正向代理代理的是请求方，也就是客户端；比如我们要访问youtube，可是不能访问，只能先安装个FQ软件代你去访问，通过FQ软件才能访问，FQ软件就叫作正向代理。

![Nginx反向代理服务器、负载均衡和正向代理](assets/471e0000766656dcb5bf.jpg)

FQ软件就是正向代理

![Nginx反向代理服务器、负载均衡和正向代理](assets/471d0000bac7a5662ea4.jpg)

正向代理中，proxy和client同属一个LAN

- 反向代理：

  反向代理的过程隐藏了真实的服务器，客户不知道真正提供服务的人是谁，客户端请求的服务都被代理服务器处理。反向代理代理的是响应方，也就是服务端；我们请求www.baidu.com时这www.baidu.com就是反向代理服务器，真实提供服务的服务器有很多台，反向代理服务器会把我们的请求分转发到真实提供服务的各台服务器。Nginx就是性能非常好的反向代理服务器，用来做负载均衡。

  访问www.baidu.com是正向代理的过程

![Nginx反向代理服务器、负载均衡和正向代理](assets/471b0003f039608883c0.jpg)

反向代理中，proxy和server同属一个LAN

![Nginx反向代理服务器、负载均衡和正向代理](assets/471e0000c21bc496b009.jpg)

正向代理和反向代理对比示意图

两者的区别在于代理的对象不一样：

正向代理中代理的对象是客户端，proxy和client同属一个LAN，对server透明；

反向代理中代理的对象是服务端，proxy和server同属一个LAN，对client透明。

![Nginx反向代理服务器、负载均衡和正向代理](assets/472000004f8af7b3f4b6.jpg)

##### 3、知识扩展1

1. 没有使用LVS时，客户端请求直接到反向代理Nginx，Nginx分发到各个服务器，服务端响应再由Ngnix返回给客户端，这样请求和响应都经过Ngnix的模式使其性能降低，这时用LVS+Nginx解决。
2. LVS+Nginx，客户端请求先由LVS接收，分发给Nginx，再由Nginx转发给服务器，LVS有四种方式：NAT模式（Network Address Translation）网络地址转换，DR模式（直接路由模式），IP隧道模式，路由方式使服务器响应不经过LVS,由Nginx直接返回给客户端。

![Nginx反向代理服务器、负载均衡和正向代理](assets/471e000145e154d02a1c.jpg)

![Nginx反向代理服务器、负载均衡和正向代理](assets/471f0000f412a0bd2904.jpg)

##### 4、知识扩展2

1. HTTP Server和Application Server的区别和联系

   Apache/nignx是静态服务器（HTTP Server）：

   Nginx优点：负载均衡、反向代理、处理静态文件优势。nginx处理静态请求的速度高于apache；

   Apache优点：相对于Tomcat服务器来说处理静态文件是它的优势，速度快。Apache是静态解析，适合静态HTML、图片等。

   HTTP Server 关心的是 HTTP 协议层面的传输和访问控制，所以在 Apache/Nginx 上你可以看到代理、负载均衡等功能

   HTTP Server（Nginx/Apache）常用做静态内容服务和代理服务器，将外来请求转发给后面的应用服务（tomcat，jboss,jetty等）。

   应用服务器(tomcat/jboss/jetty)是动态服务器（Application Server）：

   应用服务器Application Server，则是一个应用执行的容器。它首先需要支持开发语言的 Runtime（对于 Tomcat 来说，就是 Java，若是Ruby/Python 等其他语言开发的应用也无法直接运行在 Tomcat 上）。

2. 但是事无绝对，为了方便，应用服务器(如tomcat)往往也会集成 HTTP Server 的功能，nginx也可以通过模块开发来提供应用功能，只是不如专业的 HTTP Server 那么强大，所以应用服务器往往是运行在 HTTP Server 的背后，执行应用，将动态的内容转化为静态的内容之后，通过 HTTP Server 分发到客户端。

3. 常用开源集群软件有：lvs，keepalived，haproxy，nginx，apache，heartbeat

   常用商业集群硬件有：F5, Netscaler，Radware，A10等

##### 5、nginx Proxy 配置

###### 1、代理模块

```shell
ngx_http_proxy_module
```

###### 2、代理配置

```shell
代理
Syntax: 	proxy_pass URL;				   #代理的后端服务器URL
Default: 	—
Context: 	location, if in location, limit_except

缓冲区
Syntax:     proxy_buffering on | off;
Default:    proxy_buffering on;			   #缓冲开关
Context: 	http, server, location
proxy_buffering开启的情况下，nignx会把后端返回的内容先放到缓冲区当中，然后再返回给客户端
（边收边传，不是全部接收完再传给客户端)。

Syntax:   	proxy_buffer_size size;
Default: 	proxy_buffer_size 4k|8k;	   #缓冲区大小
Context: 	http, server, location

Syntax: 	proxy_buffers number size;
Default: 	proxy_buffers 8 4k|8k;		   #缓冲区数量
Context: 	http, server, location

Syntax:    	proxy_busy_buffers_size size;
Default: 	proxy_busy_buffers_size 8k|16k;#忙碌的缓冲区大小控制同时传递给客户端的buffer数量
Context: 	http, server, location

头信息
Syntax: 	proxy_set_header field value;
Default: 	proxy_set_header Host $proxy_host;		#设置真实客户端地址
            proxy_set_header Connection close;
Context: 	http, server, location

超时
Syntax: 	proxy_connect_timeout time;
Default: 	proxy_connect_timeout 60s;				#链接超时
Context: 	http, server, location

Syntax: 	proxy_read_timeout time;
Default: 	proxy_read_timeout 60s;
Context: 	http, server, location

Syntax: 	proxy_send_timeout time; #nginx进程向fastcgi进程发送request的整个过程的超时时间
Default: 	proxy_send_timeout 60s;
Context: 	http, server, location

#buffer 工作原理
1. 所有的proxy buffer参数是作用到每一个请求的。每一个请求会安按照参数的配置获得自己的buffer。proxy buffer不是global而是per request的。

2. proxy_buffering 是为了开启response buffering of the proxied server，开启后proxy_buffers和proxy_busy_buffers_size参数才会起作用。

3. 无论proxy_buffering是否开启，proxy_buffer_size（main buffer）都是工作的，proxy_buffer_size所设置的buffer_size的作用是用来存储upstream端response的header。

4. 在proxy_buffering 开启的情况下，Nginx将会尽可能的读取所有的upstream端传输的数据到buffer，直到proxy_buffers设置的所有buffer们 被写满或者数据被读取完(EOF)。此时nginx开始向客户端传输数据，会同时传输这一整串buffer们。同时如果response的内容很大的 话，Nginx会接收并把他们写入到temp_file里去。大小由proxy_max_temp_file_size控制。如果busy的buffer 传输完了会从temp_file里面接着读数据，直到传输完毕。

5. 一旦proxy_buffers设置的buffer被写入，直到buffer里面的数据被完整的传输完（传输到客户端），这个buffer将会一直处 在busy状态，我们不能对这个buffer进行任何别的操作。所有处在busy状态的buffer size加起来不能超过proxy_busy_buffers_size，所以proxy_busy_buffers_size是用来控制同时传输到客户 端的buffer数量的。
```

###### 3、启用 nginx proxy 代理

环境两台nginx真实服务器
a、nginx-1 启动网站(内容)

```shell
nginx-1的IP：192.168.100.10
yum install -y nginx
systemctl start nginx
```

b、nginx-2 启动代理程序

```shell
nginx-2的IP：192.168.100.20
yum install -y nginx
systemctl start nginx

# nginx 配置文件添加 proxy 配置
vim /etc/nginx/conf.d/default.conf
location / {
.....
proxy_pass http://192.168.100.10:80;
proxy_redirect default;

proxy_set_header Host http_host;
proxy_set_header X-Real-IP remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

proxy_connect_timeout 30;
proxy_send_timeout 60;
proxy_read_timeout 60;

proxy_buffering on;
proxy_buffer_size 32k;
proxy_buffers 4 128k;
proxy_busy_buffers_size 256k;
proxy_max_temp_file_size 256k;
    }
```

 c、nginx proxy 具体配置详解

```shell
proxy_pass ：真实服务器
proxy_redirect ：如果真实服务器使用的是的真实IP:非默认端口。则改成IP：默认端口。
proxy_set_header：重新定义或者添加发往后端服务器的请求头
proxy_set_header X-Real-IP ：启用客户端真实地址（否则日志中显示的是代理在访问网站）
proxy_set_header X-Forwarded-For：记录代理地址

proxy_connect_timeout：:后端服务器连接的超时时间发起三次握手等候响应超时时间
proxy_send_timeout：后端服务器数据回传时间就是在规定时间之内后端服务器必须传完所有的数据
proxy_read_timeout ：nginx接收upstream（上游/真实） server数据超时, 默认60s, 如果连续的60s内没有收到1个字节, 连接关闭。像长连接

proxy_buffering on;开启缓存
proxy_buffer_size：proxy_buffer_size只是响应头的缓冲区
proxy_buffers 4 128k; 内容缓冲区域大小
proxy_busy_buffers_size 256k; 从proxy_buffers划出一部分缓冲区来专门向客户端传送数据的地方
proxy_max_temp_file_size 256k;超大的响应头存储成文件。
```
![jpg](assets/.jpg)					

	proxy_set_header X-Real-IP 
	未配置
	Nginxbackend 的日志：记录只有192.168.107.112
	配置
	Nginxbackend 的日志,记录的有192.168.107.16 192.168.107.107 192.168.107.112
	
	proxy_buffers 的缓冲区大小一般会设置的比较大，以应付大网页。 proxy_buffers当中单个缓冲区的大小是由系统的内存页面大小决定的，Linux系统中一般为4k。 proxy_buffers由缓冲区数量和缓冲区大小组成的。总的大小为number*size。
	若某些请求的响应过大,则超过_buffers的部分将被缓冲到硬盘(缓冲目录由_temp_path指令指定), 当然这将会使读取响应的速度减慢, 影响用户体验. 可以使用proxy_max_temp_file_size指令关闭磁盘缓冲.
**注意**：proxy_pass http://  填写nginx-1服务器的地址。

d、 使用PC客户端访问nginx-2服务器地址
   浏览器中输入http://192.168.100.20 (也可以是nginx-2服务器的域名)

   成功访问nginx-1服务器页面
e、 观察nginx-1服务器的日志

 ```shell
192.168.100.20 - - [21/Dec/2017:00:29:58 +0800] "GET / HTTP/1.0" 200 646 "-" "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:57.0) Gecko/20100101 Firefox/57.0" "192.168.100.254"
 ```

192.168.100.20  代理服务器地址

192.168.100.254 客户机地址。
访问成功。 记录了客户机的IP和代理服务器的IP

##### 6、Nginx负载均衡

###### 1、负载均衡的作用

如果你的nginx服务器给2台web服务器做代理，负载均衡算法采用轮询，那么当你的一台机器web程序关闭造成web不能访问，那么nginx服务器分发请求还是会给这台不能访问的web服务器，如果这里的响应连接时间过长，就会导致客户端的页面一直在等待响应，对用户来说体验就打打折扣，这里我们怎么避免这样的情况发生呢。这里我配张图来说明下问题。

![Nginx反向代理服务器、负载均衡和正向代理](assets/471c0000950856272d53.jpg)

如果负载均衡中其中web2发生这样的情况，nginx首先会去web1请求，但是nginx在配置不当的情况下会继续分发请求道web2，然后等待web2响应，直到我们的响应时间超时，才会把请求重新分发给web1，这里的响应时间如果过长，用户等待的时间就会越长。

下面的配置是解决方案之一。

```
proxy_connect_timeout 1;   #nginx服务器与被代理的服务器建立连接的超时时间，默认60秒
proxy_read_timeout 1;      #nginx服务器想被代理服务器组发出read请求后，等待响应的超时间，默认为60秒。
proxy_send_timeout 1;      #nginx服务器想被代理服务器组发出write请求后，等待响应的超时间，默认为60秒。
proxy_ignore_client_abort on;  #客户端断网时，nginx服务器是否中断对被代理服务器的请求。默认为off。
```

使用upstream指令配置一组服务器作为被代理服务器，服务器中的访问算法遵循配置的负载均衡规则，同时可以使用该指令配置在发生哪些异常情况时，将请求顺次交由下一组服务器处理。

```shell
proxy_next_upstream timeout;  #反向代理upstream中设置的服务器组，出现故障时，被代理服务器返回的状态值。error|timeout|invalid_header|http_500|http_502|http_503|http_504|http_404|off
```

error：建立连接或向被代理的服务器发送请求或读取响应信息时服务器发生错误。

timeout：建立连接，想被代理服务器发送请求或读取响应信息时服务器发生超时。

invalid_header:被代理服务器返回的响应头异常。

off:无法将请求分发给被代理的服务器。

http_400，....:被代理服务器返回的状态码为400，500，502，等。

###### 2、upstream 配置

首先给大家说下 upstream 这个配置的，这个配置是写一组被代理的服务器地址，然后配置负载均衡的算法。这里的被代理服务器地址有2中写法。

```shell
upstream myweb { 
      server 172.17.14.2:8080;
      server 172.17.14.3:8080;
    }
 server {
        ....
        location / {         
           proxy_pass  http://myweb;  #请求转向 myweb 定义的服务器列表         
        } 
```



```shell
upstream mysvr { 
      server  http://172.17.14.2:8080;
      server  http://172.17.14.3:8080;
    }
 server {
        ....
        location  / {         
           proxy_pass  mysvr;  #请求转向myweb 定义的服务器列表         
        } 
```

######   1、负载均衡算法

upstream 支持4种负载均衡调度算法:

A、`轮询(默认)`:每个请求按时间顺序逐一分配到不同的后端服务器;

B、`ip_hash`:每个请求按访问IP的hash结果分配，同一个IP客户端固定访问一个后端服务器。可以保证来自同一ip的请求被打到固定的机器上，可以解决session问题。#登陆会话,请求历史登陆服务器

C、`url_hash`:按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器。后台服务器为缓存的时候效率。#每个服务器缓存不同的资源，img，video，document,要配置缓存

D、`fair`:这是比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。`Nginx`本身是不支持 `fair`的，如果需要使用这种调度算法，必须下载Nginx的 `upstream_fair`模块。#一次请求失败，接着下次不请求；

###### 2、配置实例

****1、热备：如果你有2台服务器，当一台服务器发生事故时，才启用第二台服务器给提供服务。服务器处理请求的顺序：AAAAAA突然A挂啦，BBBBBBBBBBBBBB.....****

```shell
upstream myweb { 
      server 172.17.14.2:8080; 
      server 172.17.14.3:8080 backup;  #热备     
    }
```

2、轮询：nginx默认就是轮询其权重都默认为1，服务器处理请求的顺序：ABABABABAB....

```shell
upstream myweb { 
      server 172.17.14.2:8080; 
      server 172.17.14.3:8080;      
    }
```

3、加权轮询：跟据配置的权重的大小而分发给不同服务器不同数量的请求。如果不设置，则默认为1。下面服务器的请求顺序为：ABBABBABBABBABB....

```shell
 upstream myweb { 
      server 172.17.14.2:8080 weight=1;
      server 172.17.14.3:8080 weight=2;
}
```

4、ip_hash:nginx会让相同的客户端ip请求相同的服务器。

```shell
upstream myweb { 
      server 172.17.14.2:8080; 
      server 172.17.14.3:8080;
      ip_hash;
    }
```

5、nginx负载均衡配置状态参数

- down，表示当前的server暂时不参与负载均衡。
- backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。
- max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。
- fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。

```shell
 upstream myweb { 
      server 172.17.14.2:8080 weight=2 max_fails=2 fail_timeout=2;
      server 172.17.14.3:8080 weight=1 max_fails=2 fail_timeout=1;    
    }
```

如果你像跟多更深入的了解 nginx 的负载均衡算法，nginx官方提供一些插件大家可以了解下。 

###### 3、nginx配置7层协议及4层协议方法（扩展）

举例讲解下什么是7层协议，什么是4层协议。

（1）7层协议

OSI（Open System Interconnection）是一个开放性的通行系统互连参考模型，他是一个定义的非常好的协议规范，共包含七层协议。直接上图，这样更直观些：

![在这里插入图片描述](assets/20181109183229773.png)

好，详情不进行仔细讲解，可以自行[百度](https://www.baidu.com/s?wd=%E7%99%BE%E5%BA%A6&tn=24004469_oem_dg&rsv_dl=gh_pl_sl_csd)！

（2）4层协议

TCP/IP协议
之所以说TCP/IP是一个协议族，是因为TCP/IP协议包括TCP、IP、UDP、ICMP、RIP、TELNETFTP、SMTP、ARP、TFTP等许多协议，这些协议一起称为TCP/IP协议。

从协议分层模型方面来讲，TCP/IP由四个层次组成：网络接口层、网络层、传输层、应用层。

![在这里插入图片描述](assets/20181109183459393.png)

（3）协议配置

这里我们举例，在nginx做负载均衡，负载多个服务，部分服务是需要7层的，部分服务是需要4层的，也就是说7层和4层配置在同一个配置文件中。

vim nginx.conf

```shell
worker_processes  8;

events {
        worker_connections  1024;
}
#7层http负载
http {
        include       mime.types;
        default_type  application/octet-stream;
        sendfile        on;
        keepalive_timeout  65;
        gzip  on;

        #app
        upstream  app.com {
                ip_hash;
                server 172.17.14.2:8080;
                server 172.17.14.3:8080;
        }

        server {
                listen       80;
                server_name  app;
                charset utf-8;
                location / {
                        proxy_pass http://app.com;
                        proxy_set_header Host $host:$server_port;
                        proxy_set_header X-Real-IP $remote_addr;
                        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                }
                error_page   500 502 503 504  /50x.html;
                location = /50x.html {
                        root   html;
                }
        }

        #web
        upstream  web.com {
                ip_hash;
        server 172.17.14.2:8090;
        server 172.17.14.3:8090;
        }
        server {
                listen       81;
                server_name  web;
                charset utf-8;
                location / {
                        proxy_pass http://web.com;
                        proxy_set_header Host $host:$server_port;
                        proxy_set_header X-Real-IP $remote_addr;
                        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
                }
                error_page   500 502 503 504  /50x.html;
                location = /50x.html {
                        root   html;
                }
        }
}
```

nginx在1.9.0的时候，增加了一个 stream 模块，用来实现四层协议（网络层和传输层）的转发、代理、负载均衡等。stream模块的用法跟http的用法类似，允许我们配置一组TCP或者UDP等协议的监听，然后通过proxy_pass来转发我们的请求，通过upstream添加多个后端服务，实现负载均衡。

```shell
#4层tcp负载 
stream {
			upstream myweb {
                hash $remote_addr consistent;
                server 172.17.14.2:8080;
                server 172.17.14.3:8080;
        }
        server {
            listen 82;
            proxy_connect_timeout 10s;
            proxy_timeout 30s;
            proxy_pass myweb;
        }
}
```

#### 9、nginx 会话保持

   nginx会话保持主要有以下几种实现方式。

##### **1、ip_hash**

ip_hash使用源地址哈希算法，将同一客户端的请求总是发往同一个后端服务器，除非该服务器不可用。

ip_hash语法：

```shell
upstream backend {
    ip_hash;
    server backend1.example.com;
    server backend2.example.com;
    server backend3.example.com down;
}
```

ip_hash简单易用，但有如下问题：
当后端服务器宕机后，session会丢失；
来自同一局域网的客户端会被转发到同一个后端服务器，可能导致负载失衡；
不适用于CDN网络，不适用于前段还有代理的情况。

##### **2、sticky_cookie_insert**

使用sticky_cookie_insert启用会话亲缘关系，这会导致来自同一客户端的请求被传递到一组服务器的同一台服务器。与ip_hash不同之处在于，它不是基于IP来判断客户端的，而是基于cookie来判断。因此可以避免上述ip_hash中来自同一局域网的客户端和前段代理导致负载失衡的情况。(需要引入第三方模块才能实现)
语法：

```shell
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
    sticky_cookie_insert srv_id expires=1h domain=3evip.cn path=/;
}
```

说明：
expires：设置浏览器中保持cookie的时间
domain：定义cookie的域
path：为cookie定义路径

##### **3、jvm_route方式** 

　　　jvm_route是通过session_cookie这种方式来实现session粘性。将特定会话附属到特定tomcat上，从而解决session不同步问题，但是无法解决宕机后会话转移问题。如果在cookie和url中并没有session，则这只是个简单的round-robin负载均衡。k

　　jvm_route的原理

- 一开始请求过来，没有带session的信息，jvm_route就根据round robin的方法，发到一台Tomcat上面
- Tomcat添加上session信息，并返回给客户
- 用户再次请求，jvm_route看到session中有后端服务器的名称，他就把请求转到对应的服务器上

　　暂时jvm_route模块还不支持fair的模式。jvm_route的工作模式和fair是冲突的。对于某个特定用户，当一直为他服务的Tomcat宕机后，默认情况下它会重试max_fails的次数，如果还是失败，就重新启用round robin的方式，而这种情况下就会导致用户的session丢失。

**4、使用后端服务器自身通过相关机制保持session同步，如：使用数据库、redis、memcached 等做session复制**

#### 10、nginx 实现动静分离

为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。 在动静分离的tomcat的时候比较明显，因为tomcat解析静态很慢，其实这些原理的话都很好理解，简单来说，就是使用正则表达式匹配过滤，然后交给不同的服务器。

##### 1、准备环境

配置php环境

```shell
 php编译安装
yum -y install gcc automake autoconf libtool make gcc-c++ glibc libmcrypt-devel mhash-devel libxslt-devel libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5 krb5-devel libidn libidn-devel openssl openssl-devel



tar zvxf php-5.6.33.tar.gz
cd php-5.6.33
./configure --prefix=/usr/local/php  --enable-fpm --with-mcrypt  \
--enable-mbstring --disable-pdo --with-curl --disable-debug  --disable-rpath \
--enable-inline-optimization --with-bz2  --with-zlib --enable-sockets \
--enable-sysvsem --enable-sysvshm --enable-pcntl --enable-mbregex \
--with-mhash --enable-zip --with-pcre-regex --with-mysql --with-mysqli \
--with-gd --with-jpeg-dir
 
make all install

安装后内容放在/usr/local/php目录下  下面是对php-fpm运行用户进行设置

cd /usr/local/php
cp etc/php-fpm.conf.default etc/php-fpm.conf
vi etc/php-fpm.conf

修改
user = www-data
group = www-data
listen = 0.0.0.0:9000

如果www-data用户不存在，那么先添加www-data用户
groupadd www-data
useradd -g www-data www-data

启动php-fpm和nginx

/usr/local/php/sbin/php-fpm 

创建测试php文件

在/usr/local/nginx/html下创建index.php文件，输入如下内容 [简单登录测试页面 https://www.jb51.net/article/172542.htm]

<?php
    echo phpinfo();
?>
```

##### 2、本地配置

```shell
  location ~ .*\.(html|gif|jpg|png|bmp|swf|jpeg)$ {
            root   /var/www/html/static;
            index  index.html;
        }
  location ~ \.php$ {
            root   /var/www/html/move;
            index  index.php;
        }
```

##### 3、代理配置

```shell
  location ~ .*\.(html|gif|jpg|png|bmp|swf|jpeg)$ {
                proxy_pass http://172.17.14.3:80;
        }
  location ~ \.php$ {
                root /usr/share/nginx/html;
                fastcgi_pass 127.0.0.1:9000;
                fastcgi_index index.php;
                fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
                include fastcgi_params;
        }
```

##### 4、配置项说明

**location /  的作用**

定义了请求代理的时候nginx去/var/www/html/upload  下寻找index.php 当他找到index.php的时候匹配了下面的正则  location ~ \.php$。

**location ~ \.php$   的作用**

以php结尾的都以代理的方式转发给web1（172.17.14.2）,http1 去处理，这里http1要去看自己的配置文件 在自己的配置文件中定义网站根目录 /var/www/html/upload  找.index.php  然后处理解析返回给nginx 。

 **location ~ .*\.(html|gif|jpg|png|bmp|swf|jpeg)$  的作用**

以html等等的静态页面都交给web2（172.17.14.3）来处理 ，web2 去找自己的网站目录 然后返回给nginx 。

两个 web 放的肯定是一样的目录，只不过每个服务器的任务不一样。

代理本身要有网站的目录，因为最上面的 location / 先生效   如果没有目录 会直接提示找不到目录 不会再往下匹配。



#### 11、nginx 防盗链问题

##### 1、nginx 防止网站资源被盗用模块

```shell
ngx_http_referer_module
```

**如何区分哪些是不正常的用户？**

​    HTTP Referer是Header的一部分，当浏览器向Web服务器发送请求的时候，一般会带上Referer，

告诉服务器我是从哪个页面链接过来的，服务器借此可以获得一些信息用于处理，例如防止未经允许

的网站盗链图片、文件等。因此HTTP Referer头信息是可以通过程序来伪装生成的，所以通过Referer

信息防盗链并非100%可靠，但是，它能够限制大部分的盗链情况。

##### 2. 防盗链配置

**配置要点：**

```shell
# 日志格式添加"$http_referer"
log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                         '$status $body_bytes_sent "$http_referer" '
                         '"$http_user_agent" "$http_x_forwarded_for"';
# valid_referers 使用方式                         
Syntax: 	valid_referers none | blocked | server_names | string ...;
Default: 	—
Context: server, location
```

- none : 允许没有http_refer的请求访问资源；
- blocked : 允许不是http://开头的，不带协议的请求访问资源；
- server_names : 只允许指定ip/域名来的请求访问资源（白名单）；

```shell
[root@localhost ~]# vim /etc/nginx/conf.d/nginx.conf
        location / {
                root /usr/share/nginx/html;
                index index.html index.htm;

                valid_referers  *.qf.com 192.168.19.135;
                if ($invalid_referer) {
                   return 403;
                }
        }


[root@localhost ~]# vim /etc/nginx/conf.d/nginx.conf
        location ~ .*\.(gif|jpg|png|jpeg)$ {
                root  /usr/share/nginx/html;                  
                valid_referers none blocked qf.com 192.168.19.135;
                if ($invalid_referer) {
                    return 403;
                }
         }

```

- 页面配置

```shell
qf.com
[root@localhost ~]# vim /var/www/html/index.html                           
<html>
<head>
    <meta charset="utf-8">
    <title>qf.com</title>
</head>
<body style="background-color:red;">
    <img src="http://192.168.19.135/nginx-logo.png"/>
</body>
</html>
```

##### 3、 重载nginx服务

```shell
[root@localhost ~]# nginx -s reload -c /etc/nginx/nginx.conf
```

##### 4、 测试防盗链

###### 4.1、不带http_refer

```shell
[root@localhost ~]# curl -I http://192.168.19.135/qf.jpg
HTTP/1.1 200 OK
Server: nginx/1.14.1
Date: Thu, 30 Nov 2018 18:26:10 GMT
Content-Type: image/jpeg
Content-Length: 68227
Last-Modified: Thu, 30 Nov 2018 17:46:19 GMT
Connection: keep-alive
ETag: "5a2043eb-10a83"
Accept-Ranges: bytes
```

###### 4.2、带非法http_refer

```shell
[root@localhost ~]# curl -e "http://www.baidu.com" -I http://192.168.19.135/nginx-logo.png
HTTP/1.1 403 Forbidden
Server: nginx/1.14.1
Date: Thu, 30 Nov 2018 18:25:52 GMT
Content-Type: text/html
Content-Length: 169
Connection: keep-alive
```

###### 4.3  带合法http_refer

```shell
[root@localhost ~]# curl -e "http://192.168.95.135" -I http://192.168.95.135/nginx-logo.png
HTTP/1.1 200 OK
Server: nginx/1.14.1
Date: Thu, 30 Nov 2018 18:27:30 GMT
Content-Type: image/jpeg
Content-Length: 68227
Last-Modified: Thu, 30 Nov 2018 17:46:19 GMT
Connection: keep-alive
ETag: "5a2043eb-10a83"
Accept-Ranges: bytes
```

##### 5、其他配置

###### 5.1、匹配域名

**完全防盗**

```shell
location ~ .*\.(gif|jpg|png|jpeg)$ {
    valid_referers 192.168.95.134 *.baidu.com *.google.com;
    if ($invalid_referer) {
        rewrite ^/ http://192.168.95.134/fdl.jpg
        #return 403;
    }
    root  /var/www/html/images;
}
```

**直接访问图片链接可以下载**

```shell
location ~* \.(gif|jpg|png|bmp)$ {
       valid_referers none blocked  *.qf.com  ~tianyun  ~\.google\./ ~\.baidu\./;
       if ($invalid_referer) {
           return 403;
           #rewrite .* http://qf.com/403.jpg;
    }
}
```

 以上所有来自 qf.com 和域名中包含google和baidu的站点都可以访问到当前站点的图片，如果来源域名不在这个列表中，那么$invalid_referer等于1，在if语句中返回一个403给用户，这样用户便会看到一个403的页面，如果使用下面的rewrite，那么盗链的图片都会显示403.jpg。如果用户直接在浏览器输入你的图片地址，那么图片显示正常，因为它符合none这个规则。

#### 12、nginx 地址重写 rewrite

##### 1、什么是Rewrite

​	Rewrite对称URL Rewrite，即URL重写，就是把传入Web的请求重定向到其他URL的过程。

- URL Rewrite最常见的应用是URL伪静态化，是将动态页面显示为静态页面方式的一种技术。比如
  http://www.123.com/news/index.php?id=123 使用URLRewrite 转换后可以显示为 http://www.123.com/news/123.html 对于追求完美主义的网站设计师，就算是网页的地址也希望看起来尽量简洁明快。
  理论上，搜索引擎更喜欢静态页面形式的网页，搜索引擎对静态页面的评分一般要高于动态页面。所
  以，UrlRewrite可以让我们网站的网页更容易被搜索引擎所收录。
  
- 从安全角度上讲，如果在URL中暴露太多的参数，无疑会造成一定量的信息泄漏，可能会被一些黑客
  利用，对你的系统造成一定的破坏，所以静态化的URL地址可以给我们带来更高的安全性。

- 实现网站地址跳转，例如用户访问360buy.com，将其跳转到jd.com。例如当用户访问tianyun.com的
  80端口时，将其跳转到443端口。

#####  2、Rewrite 相关指令

- **Nginx Rewrite 相关指令有 if、rewrite、set、return**

###### 2.1、if 语句

- 应用环境

```shell
server，location
```

- 语法

```shell
if (condition) { … }
if 可以支持如下条件判断匹配符号
~ 					正则匹配 (区分大小写)
~* 				    正则匹配 (不区分大小写)
!~                  正则不匹配 (区分大小写)
!~*		            正则不匹配  (不区分大小写)
-f 和!-f 		    用来判断是否存在文件
-d 和!-d 		    用来判断是否存在目录
-e 和!-e 		    用来判断是否存在文件或目录
-x 和!-x 		    用来判断文件是否可执行

在匹配过程中可以引用一些Nginx的全局变量
$args				请求中的参数;
$document_root	    针对当前请求的根路径设置值;
$host				请求信息中的"Host"，如果请求中没有Host行，则等于设置的服务器名;
$limit_rate			对连接速率的限制;
$request_method		请求的方法，比如"GET"、"POST"等;
$remote_addr		客户端地址;
$remote_port		客户端端口号;
$remote_user		客户端用户名，认证用;
$request_filename   当前请求的文件路径名（带网站的主目录/usr/local/nginx/html/images /a.jpg）
$request_uri		当前请求的文件路径名（不带网站的主目录/images/a.jpg）
$query_string		与$args相同;
$scheme				用的协议，比如http或者是https
$server_protocol	请求的协议版本，"HTTP/1.0"或"HTTP/1.1";
$server_addr 		服务器地址，如果没有用listen指明服务器地址，使用这个变量将发起一次系统调用以取得地址(造成资源浪费);
$server_name		请求到达的服务器名;
$document_uri 		与$uri一样，URI地址;
$server_port 		请求到达的服务器端口号;
```

######  2.2、Rewrite flag

**rewrite**  指令根据表达式来重定向URI，或者修改字符串。可以应用于**server,location, if**环境下每行rewrite指令最后跟一个flag标记，支持的flag标记有：

```
last 			    相当于Apache里的[L]标记，表示完成rewrite
break 				本条规则匹配完成后，终止匹配，不再匹配后面的规则
redirect 			返回302临时重定向，浏览器地址会显示跳转后URL地址
permanent 		    返回301永久重定向，浏览器地址会显示跳转后URL地址
```

redirect 和 permanent区别则是返回的不同方式的重定向，对于客户端来说一般状态下是没有区别的。而对于搜索引擎，相对来说301的重定向更加友好，如果我们把一个地址采用301跳转方式跳转的话，搜索引擎会把老地址的相关信息带到新地址，同时在搜索引擎索引库中彻底废弃掉原先的老地址。使用302重定向时，搜索引擎(特别是google)有时会查看跳转前后哪个网址更直观，然后决定显示哪个，如果它觉的跳转前的URL更好的话，也许地址栏不会更改，那么很有可能出现URL劫持的现像。在做URI重写时，有时会发现URI中含有相关参数，如果需要将这些参数保存下来，并且在重写过程中重新引用，可以用到 () 和 $N 的方式来解决。

###### 2.3、Rewrite匹配参考示例

```shell
示例1：
# http://www.tianyun.com/a/1.html ==> http://www.tianyun.com/b/2.html
location /a {
    rewrite .* /b/2.html permanent;
    #return 301 /b/2.html;
}

例2：
# http://www.tianyun.com/2019/a/1.html ==> http://www.tianyun.com/2018/a/1.html
# http://www.tianyun.com/2019/a/2.html ==> http://www.tianyun.com/2018/a/2.html
location /2019 {
     rewrite ^/2019/(.*)$ /2018/$1 permanent;
}
例3：
# http://www.qf.com/a/1.html ==> http://jd.com
if ( $host ~* qf.com ) {
	rewrite .*	http://jd.com permanent;
}

例4：
# http://www.qf.com/a/1.html ==> http://jd.com/a/1.html
if ( $host ~* qf.com ) {
	rewrite  .*	 http://jd.com$request_uri permanent;
}

例5: 在访问目录后添加/  (如果目录后已有/，则不加/)
# http://www.tianyun.com/test/
# $1: /a/b
# $2: c
# http://$host$1$2/
if (-d $request_filename) {
    rewrite ^(.*)([^/])$ http://$host$1$2/ permanent;
}

例6：
# http://www.tianyun.com/login/tianyun.html ==>  http://www.tianyun.com/reg/login.php?user=tianyun

location /login {
           rewrite ^/login/(.*)\.html$ /reg/login.php?user=$1;
        }

例7：
#http://www.tianyun.com/qf/11-22-33/1.html  ==>  http://www.tianyun.com/qf/11/22/33/1.html
location /qf {
            rewrite ^/qf/([0-9]+)-([0-9]+)-([0-9]+)(.*)$ /qf/$1/$2/$3$4 permanent;
        }

```

###### 2.4、set 指令

set 指令是用于定义一个变量，并且赋值

- **应用环境：**

```
server,location,if
```

- **应用示例**

```shell
例8：
#http://alice.tianyun.com ==> http://www.tianyun.com/alice
#http://jack.tianyun.com ==> http://www.tianyun.com/jack

[root@localhost html]# mkdir jack alice
[root@localhost html]# echo jack.... > jack/index.html
[root@localhost html]# echo alice... > alice/index.html

a. DNS实现泛解析
*   		IN      A			    网站IP
确保 alice.tianyun.com、jack.tianyun.com、www.tianyun.com都解析到网站ip

b. nginx Rewrite
if ($host ~* "^www.tianyun.com$" ) {
      break;
  }

if ($host ~* "^(.*)\.tianyun\.com$" ) {
      set $user $1;
      rewrite .* http://www.tianyun.com/$user permanent;
  }
```

###### 2.5、return 指令

return 指令用于返回状态码给客户端

- **应用环境：**

```
server，location，if
```

- **应用示例：**

```shell
例9：如果访问的.sh结尾的文件则返回403操作拒绝错误
location ~* \.sh$ {
	return 403;
	#return 301 http://www.tianyun.com;
}

例10：80 ======> 443
server {
        listen      80;
        server_name  www.tianyun.com tianyun.com;
        return     301  https://www.tianyun.com$request_uri;
        }
server {
        listen      443 ssl;
        server_name  www.tianyun.com;
        ssl  on; 
        ssl_certificate      /usr/local/nginx/conf/cert.pem;
        ssl_certificate_key  /usr/local/nginx/conf/cert.key;
        location / {
            root html;
            index index.html index.php;
        }
    }

[root@localhost html]# curl -I http://www.tianyun.com
HTTP/1.1 301 Moved Permanently
Server: nginx/1.10.1
Date: Tue, 26 Jul 2016 15:07:50 GMT
Content-Type: text/html
Content-Length: 185
Connection: keep-alive
Location: https://www.tianyun.com/
```

##### 3、last,break详解

![last](assets/last.png)

 ```shell
   location / {
    root /usr/share/nginx/html;
    index index.html;
}
   location /break/ {
    root /usr/share/nginx/html;
    rewrite .* /test/break.html break;
}

  location /last/ {
   root /usr/share/nginx/html;
   rewrite .* /test/last.html last;
}

  location /test/ {
   root /usr/share/nginx/html;
   rewrite  .* /test/test.html break;
}
！！！注意上一步实验 https缓存影响


[root@localhost html]# mkdir test
[root@localhost html]# echo 'break' > test/break.html
[root@localhost html]# echo 'last' > test/last.html
[root@localhost html]# echo 'test...' > test/test.html

http://192.168.10.33/break/break.html
http://192.168.10.33/last/last.html
 ```

**注意：**

- last 标记在本条 rewrite 规则执行完后，会对其所在的 server { … } 标签重新发起请求;

- break 标记则在本条规则匹配完成后，停止匹配，不再做后续的匹配；

- 使用 alias 指令时，必须使用 last；

- 使用 proxy_pass 指令时,则必须使用break。

##### 4、Nginx 的 https  ( rewrite )

```shell
 server {
        listen       80;
        server_name  *.vip9999.top vip9999.top;

        if ($host ~* "^www.vip9999.top$|^vip9999.top$" ) {
                return 301 https://www.vip9999.top$request_uri;
        }

        if ($host ~* "^(.*).vip9999.top$" ) {
                set $user $1;
                return 301 https://www.vip9999.top/$user;
        }

    }

    # Settings for a TLS enabled server.
    server {
        listen       443 ssl;
        server_name  www.vip9999.top;

        location / {
                root      /usr/share/nginx/html;
                index     index.php index.html;
        }

        #pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
        location ~ \.php$ {
            root           /usr/share/nginx/html;
            fastcgi_pass   127.0.0.1:9000;
            fastcgi_index  index.php;
            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;
            include        fastcgi_params;
        }
        ssl on;
        ssl_certificate cert/214025315060640.pem;
        ssl_certificate_key cert/214025315060640.key;
        ssl_session_cache shared:SSL:1m;
        ssl_session_timeout  10m;
        ssl_ciphers HIGH:!aNULL:!MD5;
        ssl_prefer_server_ciphers on; 
        }
```

##### 5、Apache 的 https ( rewrite )

```shell
[root@localhost ~]# yum -y install httpd mod_ssl
[root@localhost ~]# vim /etc/httpd/conf.d/vip9999.conf
```

![](assets/apache.png)

#### 13、nginx location 指令详解

Nginx 的 HTTP 配置主要包括三个区块，结构如下：

```shell
http { 						# 这个是协议级别
　　include mime.types;
　　default_type application/octet-stream;
　　keepalive_timeout 65;
　　gzip on;
　　　　server {			 # 这个是服务器级别
　　　　　　listen 80;
　　　　　　server_name localhost;
　　　　　　　　location / {  # 这个是请求级别
　　　　　　　　　　root html;
　　　　　　　　　　index index.html index.htm;
　　　　　　　　}
　　　　　　}
}
```

##### 1、**location 区段**

- location 是在 server 块中配置，根据不同的 URI 使用不同的配置，来处理不同的请求。
- location 是有顺序的，会被第一个匹配的location 处理。

- 基本语法如下：

```shell
location [=|~|~*|^~|@] pattern{……}
```

##### 2、**location 前缀含义**

```shell
=    表示精确匹配，优先级也是最高的 
^~   表示uri以某个常规字符串开头,理解为匹配url路径即可 
~    表示区分大小写的正则匹配  
~*   表示不区分大小写的正则匹配
!~   表示区分大小写不匹配的正则
!~*  表示不区分大小写不匹配的正则
/    通用匹配，任何请求都会匹配到
@    内部服务跳转
```

##### 3、location 配置示例

1、没有修饰符 表示：必须以指定模式开始

```shell
server {
　　server_name qf.com;
　　location /abc {
　　　　……
　　}
}

那么，如下是对的：
http://qf.com/abc
http://qf.com/abc?p1
http://qf.com/abc/
http://qf.com/abcde 
```

2、=表示：必须与指定的模式精确匹配

```shell
server {
server_name qf.com
　　location = /abc {
　　　　……
　　}
}
那么，如下是对的：
http://qf.com/abc
http://qf.com/abc?p1
如下是错的：
http://qf.com/abc/
http://qf.com/abcde
```

3、~ 表示：指定的正则表达式要区分大小写

```shell
server {
server_name qf.com;
　　location ~ ^/abc$ {
　　　　……
　　}
}
那么，如下是对的：
http://qf.com/abc
http://qf.com/abc?p1=11&p2=22
如下是错的：
http://qf.com/ABC
http://qf.com/abc/
http://qf.com/abcde
```

4、~* 表示：指定的正则表达式不区分大小写

```shell
server {
server_name qf.com;
location ~* ^/abc$ {
　　　　……
　　}
}
那么，如下是对的：
http://qf.com/abc
http://qf..com/ABC
http://qf..com/abc?p1=11&p2=22
如下是错的：
http://qf..com/abc/
http://qf..com/abcde
```

5、^~ ：类似于无修饰符的行为，也是以指定模式开始，不同的是，如果模式匹配，那么就停止搜索其他模式了。
6、@ ：定义命名 location 区段，这些区段客户段不能访问，只可以由内部产生的请求来访问，如try_files或error_page等

**查找顺序和优先级**

**1：带有“=“的精确匹配优先**

**2：没有修饰符的精确匹配**

**3：正则表达式按照他们在配置文件中定义的顺序**

**4：带有“^~”修饰符的，开头匹配**

**5：带有“~” 或“~\*” 修饰符的，如果正则表达式与URI匹配**

**6：没有修饰符的，如果指定字符串与URI开头匹配**

```shell
location 区段匹配示例

location = / {
　　# 只匹配 / 的查询.
　　[ configuration A ]
}
location / {
　　# 匹配任何以 / 开始的查询，但是正则表达式与一些较长的字符串将被首先匹配。
　　[ configuration B ]
}
location ^~ /images/ {
　　# 匹配任何以 /images/ 开始的查询并且停止搜索，不检查正则表达式。
　　[ configuration C ]
}
location ~* \.(gif|jpg|jpeg)$ {
　　# 匹配任何以gif, jpg, or jpeg结尾的文件，但是所有 /images/ 目录的请求将在Configuration C中处理。
　　[ configuration D ]
} 
各请求的处理如下例：
	/ → configuration A
	/documents/document.html → configuration B
	/images/1.gif → configuration C
	/documents/1.jpg → configuration D
```

##### 4、root 、alias 指令区别

```shell
location /img/ {
    alias /var/www/image/;
}
#若按照上述配置的话，则访问/img/目录里面的文件时，ningx会自动去/var/www/image/目录找文件
location /img/ {
    root /var/www/image;
}
#若按照这种配置的话，则访问/img/目录下的文件时，nginx会去/var/www/image/img/目录下找文件。] 
```

- alias 是一个目录别名的定义，

- root 则是最上层目录的定义。

- 还有一个重要的区别是alias后面必须要用“/”结束，否则会找不到文件的,而root则可有可无。

#### 14、nginx 日志配置

##### 1、nginx 日志介绍

`nginx` 有一个非常灵活的日志记录模式,每个级别的配置可以有各自独立的访问日志, 所需日志模块 `ngx_http_log_module` 的支持，日志格式通过 `log_format` 命令来定义，日志对于统计和排错是非常有利的，下面总结了 `nginx` 日志相关的配置 包括 `access_log`、`log_format`、`open_log_file_cache`、`log_not_found`、`log_subrequest`、`rewrite_log`、`error_log`。

##### 2、access_log 指令

访问日志主要记录客户端的请求。客户端向 Nginx 服务器发起的每一次请求都记录在这里。客户端IP，浏览器信息，referer，请求处理时间，请求URL等都可以在访问日志中得到。当然具体要记录哪些信息，你可以通过`log_format`指令定义。

**语法：**

```shell
# 设置访问日志
access_log path [format [buffer=size] [gzip[=level]] [flush=time] [if=condition]];
# 关闭访问日志
access_log off; 
```

- **path** 指定日志的存放位置。
- **format** 指定日志的格式。默认使用预定义的`combined`。
- **buffer** 用来指定日志写入时的缓存大小，默认是64，解决频繁打开日志文件写入的系统操作。
- **gzip** 日志写入前先进行压缩。压缩率可以指定，从1到9数值越大压缩比越高，同时压缩的速度也越慢。默认是1。
- **flush** 设置缓存的有效时间。如果超过flush指定的时间，缓存中的内容将被清空，并把数据存入文件。
- **if** 条件判断。如果指定的条件计算为0或空字符串，那么该请求不会写入日志。

**作用域：**

可以应用`access_log`指令的作用域分别有`http`，`server`，`location`，`limit_except`。也就是说，在这几个作用域外使用该指令，Nginx会报错。

**基本用法：**

```shell
access_log /var/logs/nginx-access.log
```

该例子指定日志的写入路径为`/var/logs/nginx-access.log`，日志格式使用默认的`combined`。

```shell
access_log /var/logs/nginx-access.log buffer=32k gzip flush=1m
```

该例子指定日志的写入路径为`/var/logs/nginx-access.log`，日志格式使用默认的`combined`，指定日志的缓存大小为 32k，日志写入前启用 gzip 进行压缩，压缩比使用默认值 1，缓存数据有效时间为1分钟。

##### 3、log_format 指令

Nginx 预定义了名为 `combined` 日志格式，如果没有明确指定日志格式默认使用该格式：

```shell
log_format combined '$remote_addr - $remote_user [$time_local] '
                    '"$request" $status $body_bytes_sent '
                    '"$http_referer" "$http_user_agent"';
```

如果不想使用Nginx预定义的格式，可以通过`log_format`指令来自定义。

语法

```shell
log_format name [escape=default|json] string ...;
```

- **name** 格式名称。在 access_log 指令中引用。
- **escape** 设置变量中的字符编码方式是`json`还是`default`，默认是`default`。
- **string** 要定义的日志格式内容。该参数可以有多个。参数中可以使用Nginx变量。

`log_format` 指令中常用的一些变量：

| 变量                  | 含义                                                         |
| --------------------- | ------------------------------------------------------------ |
| $bytes_sent           | 发送给客户端的总字节数                                       |
| $body_bytes_sent      | 发送给客户端的字节数，不包括响应头的大小                     |
| $connection           | 连接序列号                                                   |
| $connection_requests  | 当前通过连接发出的请求数量                                   |
| $msec                 | 日志写入时间，单位为秒，精度是毫秒                           |
| $pipe                 | 如果请求是通过http流水线发送，则其值为"p"，否则为“."         |
| $request_length       | 请求长度（包括请求行，请求头和请求体）                       |
| $request_time         | 请求处理时长，单位为秒，精度为毫秒，从读入客户端的第一个字节开始，直到把最后一个字符发送张客户端进行日志写入为止 |
| $status               | 响应状态码                                                   |
| $time_iso8601         | 标准格式的本地时间,形如“2017-05-24T18:31:27+08:00”           |
| $time_local           | 通用日志格式下的本地时间，如"24/May/2017:18:31:27 +0800"     |
| $http_referer         | 请求的referer地址。                                          |
| $http_user_agent      | 客户端浏览器信息。                                           |
| $remote_addr          | 客户端IP                                                     |
| $http_x_forwarded_for | 当前端有代理服务器时，设置web节点记录客户端地址的配置，此参数生效的前提是代理服务器也要进行相关的x_forwarded_for设置。 |
| $request              | 完整的原始请求行，如 "GET / HTTP/1.1"                        |
| $remote_user          | 客户端用户名称，针对启用了用户认证的请求                     |
| $request_uri          | 完整的请求地址，如 "https://qf.com/"                         |

自定义日志格式的使用：

```shell
access_log /var/logs/nginx/access.log main

log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                  '$status $body_bytes_sent "$http_referer" '
                  '"$http_user_agent" "$http_x_forwarded_for"';
```

使用`log_format`指令定义了一个`main`的格式，并在`access_log`指令中引用了它。假如客户端有发起请求：`https://qf.com/`，我们看一下我截取的一个请求的日志记录:

```shell
192.168.95.134 - - [20/Feb/2019:12:12:14 +0800] "GET / HTTP/1.1" 200 190 "-" "Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Mobile Safari/537.36" "-"
```

我们看到最终的日志记录中`$remote_user`、`$http_referer`、`$http_x_forwarded_for`都对应了一个`-`，这是因为这几个变量为空。

##### 5、error_log 指令

错误日志在Nginx中是通过`error_log`指令实现的。该指令记录服务器和请求处理过程中的错误信息。

**语法**

配置错误日志文件的路径和日志级别。

```shell
error_log file [level];
Default:	
error_log logs/error.log error;
```

`file` 参数指定日志的写入位置。

`level` 参数指定日志的级别。level可以是`debug`, `info`, `notice`, `warn`, `error`, `crit`, `alert`,`emerg`中的任意值。可以看到其取值范围是按紧急程度从低到高排列的。只有日志的错误级别等于或高于level指定的值才会写入错误日志中。默认值是`error`。

**基本用法**

```shell
error_log /var/logs/nginx/nginx-error.log
```

配置段：`main`， `http`,  `mail`,  `stream`,  `server`, `location`作用域。

例子中指定了错误日志的路径为：`/var/logs/nginx/nginx-error.log`，日志级别使用默认的 `error`。

##### 6、open_log_file_cache 指令

每一条日志记录的写入都是先打开文件再写入记录，然后关闭日志文件。如果你的日志文件路径中使用了变量，如  `access_log /var/logs/$host/nginx-access.log`，为提高性能，可以使用`open_log_file_cache`指令设置日志文件描述符的缓存。

**语法**

```shell
open_log_file_cache max=N [inactive=time] [min_uses=N] [valid=time];

默认值: 
open_log_file_cache off;
```

- **max** 设置缓存中最多容纳的文件描述符数量，如果被占满，采用LRU算法将描述符关闭。
- **inactive** 设置缓存存活时间，默认是10s。
- **min_uses** 在**inactive**时间段内，日志文件最少使用几次，该日志文件描述符记入缓存，默认是1次。
- **valid**：设置多久对日志文件名进行检查，看是否发生变化，默认是60s。
- **off**：不使用缓存。默认为off。

**基本用法**

```shell
open_log_file_cache max=1000 inactive=20s valid=1m min_uses=2;
```

配置段:`http`、`server`、`location`作用域中。

例子中，设置缓存最多缓存1000个日志文件描述符，20s内如果缓存中的日志文件描述符至少被被访问2次，才不会被缓存关闭。每隔1分钟检查缓存中的文件描述符的文件名是否还存在。

##### 7、log_not_found 指令

是否在`error_log`中记录未找到日志时的产生的错误。默认是on

**基本语法:** 

```shell
log_not_found on | off;
默认值: 
log_not_found on;
```

配置段: `http`, `server`, `location`作用域。

##### 8、log_subrequest 指令

是否在`access_log`中记录子请求的访问日志。默认不记录

**基本语法:** 

```shell
log_subrequest on | off;

默认值: 
log_subrequest off;
```

配置段:  `http`, ` server`, `location`作用域。

##### 9、rewrite_log 指令

由`ngx_http_rewrite_module`模块提供的。用来记录重写日志的。对于调试重写规则建议开启，启用时将在`error log`中记录`notice`级别的重写日志。
**基本语法:** 

```shell
rewrite_log on | off;

默认值: 
rewrite_log off;
```

配置段:  `http`,  `server`, `location`,  `if`作用域。

##### 10、nginx 日志配置总结

Nginx中通过`access_log`和`error_log`指令配置访问日志和错误日志，通过`log_format`我们可以自定义日志格式。如果日志文件路径中使用了变量，我们可以通过`open_log_file_cache` 指令来设置缓存，提升性能。其他的根据自己的使用场景定义。

详细的日志配置信息可以参考[Nginx官方文档](https://nginx.org/en/docs/http/ngx_http_log_module.html)

#### 15、nginx 的平滑升级(了解)

##### 1、为什么要对 nginx 平滑升级

随着 `nginx` 越来越流行，并且 `nginx` 的优势也越来越明显，`nginx` 的版本迭代也来时加速模式，1.9.0版本的nginx更新了许多新功能，例如 `stream` 四层代理功能，伴随着 `nginx` 的广泛应用，版本升级必然越来越快，线上业务不能停，此时 `nginx` 的升级就是运维的工作了

nginx 方便地帮助我们实现了平滑升级。其原理简单概括，就是：
（1）在不停掉老进程的情况下，启动新进程。
（2）老进程负责处理仍然没有处理完的请求，但不再接受处理请求。
（3）新进程接受新请求。
（4）老进程处理完所有请求，关闭所有连接后，停止。
这样就很方便地实现了平滑升级。一般有两种情况下需要升级 nginx，一种是确实要升级 nginx 的版本，另一种是要为 nginx 添加新的模块。

##### 2、nginx 平滑升级原理

**多进程模式下的请求分配方式**

nginx 默认工作在多进程模式下，即主进程（master process）启动后完成配置加载和端口绑定等动作，`fork`出指定数量的工作进程（worker process），这些子进程会持有监听端口的文件描述符（fd），并通过在该描述符上添加监听事件来接受连接（accept）。

**信号的接收和处理**

nginx 主进程在启动完成后会进入等待状态，负责响应各类系统消息，如SIGCHLD、SIGHUP、SIGUSR2等。

**Nginx信号简介**

**主进程支持的信号**

- `TERM`, `INT`: 立刻退出
- `QUIT`: 等待工作进程结束后再退出
- `KILL`: 强制终止进程
- `HUP`: 重新加载配置文件，使用新的配置启动工作进程，并逐步关闭旧进程。
- `USR1`: 重新打开日志文件
- `USR2`: 启动新的主进程，实现热升级
- `WINCH`: 逐步关闭工作进程

**工作进程支持的信号**

- `TERM`, `INT`: 立刻退出
- `QUIT`: 等待请求处理结束后再退出
- `USR1`: 重新打开日志文件

##### 3、nginx 平滑升级实战

1、查看现有的 nginx 编译参数

```shell
[root@web ~]#/usr/local/nginx/sbin/nginx -V
```

按照原来的编译参数安装 nginx 的方法进行安装，**只需要到 make，千万不要 make install**

###### 2、编译新的 nginx 源码包

编译新Nginx源码，安装路径需与旧版一致 (详细过程可参见：Nginx编译安装与配置使用)

```shell
[root@web ~]#./configure --prefix=/usr/local/nginx-1.14.0 --user=www --group=www --with-http_ssl_module --with-openssl=/path/to/openssl_src
[root@web ~]#make
```

###### 3、备份原 nginx 二进制文件

备份二进制文件和 nginx 的配置文件（期间nginx不会停止服务）

```shell
[root@web ~]#mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_$(date +%F)
```

4、复制新的nginx二进制文件，进入新的nginx源码包

```shell
[root@web ~]#cp /usr/local/nginx-1.14.0/objs/nginx /usr/local/nginx/sbin/
```

5、测试新版本的nginx是否正常

```shell
[root@web ~]#/usr/local/nginx/sbin/nginx -t
```

6、给nginx发送平滑迁移信号（若不清楚pid路径，请查看nginx配置文件）

```shell
[root@web ~]#kill -USR2 `cat /var/run/nginx.pid`
```

7、查看nginx pid，会出现一个nginx.pid.oldbin

```shell
[root@web ~]#ll /var/run/nginx.pid*
```

8、从容关闭旧的Nginx进程

```shell
[root@web ~]#kill -WINCH cat /var/run/nginx.pid.oldbin
```

9、此时不重载配置启动旧的工作进程

```shell
[root@web ~]#kill -HUP cat /var/run/nginx.pid.oldbin
```

10、结束工作进程，完成此次升级

```shell
[root@web ~]#kill -QUIT cat /var/run/nginx.pid.oldbin
```

11、验证Nginx是否升级成功

```shell
[root@web ~]#usr/local/nginx/sbin/nginx -V
```

##### 4、升级实验

###### 1、安装配置1.6版本的 nginx

```shell
[root@web ~]# yum install -y gcc gcc-c++ pcre-devel openssl-devel zlib-devel
[root@web ~]# tar zxvf nginx-1.6.0.tar.gz -C /usr/src/
[root@web ~]# cd /usr/src/nginx-1.6.0/
[root@web nginx-1.6.0]# ./configure --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_stub_status_module
[root@web nginx-1.6.0]# make 
[root@web nginx-1.6.0]# make install
[root@web nginx-1.6.0]# ln -s /usr/local/nginx/sbin/* /usr/sbin/
[root@web nginx-1.6.0]# useradd -M -s /sbin/nologin nginx 
[root@web nginx-1.6.0]# nginx 
[root@web nginx-1.6.0]# netstat -anput | grep nginx 
tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 19008/nginx: master
```

###### 2、查看 nginx 版本

```shell
[root@web nginx-1.6.0]# nginx -v
nginx version: nginx/1.6.0
```

###### 3、查看 nginx 现有安装的模块

```shell
[root@web nginx-1.6.0]# nginx -V
nginx version: nginx/1.6.0
built by gcc 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) 
configure arguments: --prefix=/usr/local/nginx --user=nginx --group=nginx --with-http_stub_status_module
```

###### 4、访问验证

```shell
[root@web nginx-1.6.0]# echo "nginx1.6.0" > /usr/local/nginx/html/index.html
[root@web nginx-1.6.0]# elinks 192.168.20.167
```

![img](assets/1166362-20170603141717539-518182202.png)

###### 5、升级 nginx

将 nginx 版本进行升级 并在不影响业务的情况下添加 SSL 和 pcre 模块

```shell
[root@web ~]# tar zxvf nginx-1.11.2.tar.gz -C /usr/src/

[root@web ~]# cd /usr/src/nginx-1.11.2/
[root@web nginx-1.11.2]# ./configure --prefix=/usr/local/nginx --user=nginx --group=ngiinx --with-http_stub_status_module --with-http_ssl_module --with-pcre

[root@web nginx-1.11.2]# make

[root@web nginx-1.11.2]# cd
[root@web ~]# mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx_old 
[root@web ~]# cp /usr/src/nginx-1.11.2/objs/nginx /usr/local/nginx/sbin/

[root@web ~]# mv /usr/local/nginx/conf/nginx.conf /usr/local/nginx/conf/nginx.conf.old
[root@Centos ~]# cp /usr/src/nginx-1.11.2/conf/nginx.conf /usr/local/nginx/conf/nginx.conf

[root@web ~]# kill -USR2 `cat /usr/local/nginx/logs/nginx.pid`
[root@web ~]# ls /usr/local/nginx/logs/
access.log error.log nginx.pid

[root@web ~]# ps aux | grep nginx 
root 19008 0.0 0.0 24324 944 ? Ss 14:07 0:00 nginx: master process nginx
nginx 19009 0.0 0.1 26832 1744 ? S 14:07 0:00 nginx: worker process
root 53194 0.0 0.0 112660 976 pts/0 R+ 14:36 0:00 grep --color=auto ngin
```

###### 6、验证 nginx 是否升级成功

![img](assets/1166362-20170603152814024-619759515.png)

#### 16、nginx 错误页面配置

nginx错误页面包括404 403 500 502 503 504等页面，只需要在server中增加以下配置即可：

```shell
                error_page  404 403 500 502 503 504  /404.html;
                location = /404.html {
                        root   /usr/local/nginx/html;
                }
```

**注意：**

/usr/local/nginx/html/ 路径下必须有404.html这个文件！！！

404.html上如果引用其他文件的png或css就会有问题，显示不出来，因为其他文件的访问也要做配置；
 为了简单，可以将css嵌入文件中，图片用base编码嵌入；如下：

```html
<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
        <title>404</title>
        <style>
            .layout-table{display:table;height:100%;width:100%;vertical-align: middle;margin-top:150px}
            .layout-table-cell{display: table-cell;vertical-align: middle;text-align:center}
            .layout-tip{font-size:28px;color:#373737;margin: 0 auto;margin-top:16px;border-bottom: 1px solid #eee;padding-bottom: 20px;width: 360px;}
            #tips{font-size:18px;color:#666666;margin-top:16px;}
        </style>
    </head>
    <body class="layui-layout-body">
        <div class="layui-layout layui-layout-admin">
            
            <div class="layui-body">
                <div class="layout-table">
                    <div class="layout-table-cell">
                        <img src="" class="layout-img">
                        <p class="layout-tip">哎呀，找不到该页面啦！</p>
                        <p id="tips">请检查您的网络连接是否正常或者输入的网址是否正确</p>
                    </div>
                </div>
            </div>
        </div>
        
    </body>
</html>
```

展示效果：

![img](https:////upload-images.jianshu.io/upload_images/10052717-4b04bbdb70e8f3c9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000/format/webp)

#### 17、nginx 流量控制

**流量限制** (rate-limiting)，是Nginx中一个非常实用，却经常被错误理解和错误配置的功能。我们可以用来限制用户在给定时间内HTTP请求的数量。请求，可以是一个简单网站首页的GET请求，也可以是登录表单的 POST 请求。流量限制可以用作安全目的，比如可以减慢暴力密码破解的速率。通过将传入请求的速率限制为真实用户的典型值，并标识目标URL地址(通过日志)，还可以用来抵御 DDOS 攻击。更常见的情况，该功能被用来保护上游应用服务器不被同时太多用户请求所压垮。

以下将会介绍Nginx的 **流量限制** 的基础知识和高级配置，”流量限制”在Nginx Plus中也适用。

##### 1、Nginx如何限流

Nginx的”流量限制”使用漏桶算法(leaky bucket algorithm)，该算法在通讯和分组交换计算机网络中广泛使用，用以处理带宽有限时的突发情况。就好比，一个桶口在倒水，桶底在漏水的水桶。如果桶口倒水的速率大于桶底的漏水速率，桶里面的水将会溢出；同样，在请求处理方面，水代表来自客户端的请求，水桶代表根据”先进先出调度算法”(FIFO)等待被处理的请求队列，桶底漏出的水代表离开缓冲区被服务器处理的请求，桶口溢出的水代表被丢弃和不被处理的请求。

![漏桶算法](https://user-gold-cdn.xitu.io/2018/10/31/166c9a2acf4d2b63?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)

##### 2、配置基本的限流 

“流量限制”配置两个主要的指令，`limit_req_zone`和`limit_req`，如下所示：

```shell
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;
server {
	location /login/ {
		limit_req zone=mylimit;
		proxy_pass http://my_upstream;
	}
}
# seq for i in `seq 20`;do curl http://10.3.139.11:80&&echo "============";done
# time for i in `seq 2000`;do curl http://10.3.139.11:80&&echo "===========";done

```

`limit_req_zone`指令定义了流量限制相关的参数，而`limit_req`指令在出现的上下文中启用流量限制(示例中，对于”/login/”的所有请求)。

`limit_req_zone`指令通常在HTTP块中定义，使其可在多个上下文中使用，它需要以下三个参数：

- **Key** - 定义应用限制的请求特性。示例中的 Nginx 变量`$binary_remote_addr`，保存客户端IP地址的二进制形式。这意味着，我们可以将每个不同的IP地址限制到，通过第三个参数设置的请求速率。(使用该变量是因为比字符串形式的客户端IP地址`$remote_addr`，占用更少的空间)
- **Zone** - 定义用于存储每个IP地址状态以及被限制请求URL访问频率的共享内存区域。保存在内存共享区域的信息，意味着可以在Nginx的worker进程之间共享。定义分为两个部分：通过`zone=keyword`标识区域的名字，以及冒号后面跟区域大小。16000个IP地址的状态信息，大约需要1MB，所以示例中区域可以存储160000个IP地址。
- **Rate** - 定义最大请求速率。在示例中，速率不能超过每秒10个请求。Nginx实际上以毫秒的粒度来跟踪请求，所以速率限制相当于每100毫秒1个请求。因为不允许”突发情况”(见下一章节)，这意味着在前一个请求100毫秒内到达的请求将被拒绝。

> 当Nginx需要添加新条目时存储空间不足，将会删除旧条目。如果释放的空间仍不够容纳新记录，Nginx将会返回 **503状态码**(Service Temporarily Unavailable)。另外，为了防止内存被耗尽，Nginx每次创建新条目时，最多删除两条60秒内未使用的条目。

`limit_req_zone`指令设置流量限制和共享内存区域的参数，但实际上并不限制请求速率。所以需要通过添加

`limit_req`指令，将流量限制应用在特定的`location`或者`server`块。在上面示例中，我们对`/login/`请求进行流量限制。

现在每个IP地址被限制为每秒只能请求10次`/login/`，更准确地说，在前一个请求的100毫秒内不能请求该URL。

##### 3、处理突发

如果我们在100毫秒内接收到2个请求，怎么办？对于第二个请求，Nginx将给客户端返回状态码503。这可能并不是我们想要的结果，因为应用本质上趋向于突发性。相反地，我们希望缓冲任何超额的请求，然后及时地处理它们。我们更新下配置，在`limit_req`中使用`burst`参数：

```shell
location /login/ {
	limit_req zone=mylimit burst=20;
	proxy_pass http://my_upstream;
}
```

`burst`参数定义了超出zone指定速率的情况下(示例中的`mylimit`区域，速率限制在每秒10个请求，或每100毫秒一个请求)，客户端还能发起多少请求。上一个请求100毫秒内到达的请求将会被放入队列，我们将队列大小设置为20。

这意味着，如果从一个给定IP地址发送21个请求，Nginx会立即将第一个请求发送到上游服务器群，然后将余下20个请求放在队列中。然后每100毫秒转发一个排队的请求，只有当传入请求使队列中排队的请求数超过20时，Nginx才会向客户端返回503。

##### 4、无延迟的排队

配置`burst`参数将会使通讯更流畅，但是可能会不太实用，因为该配置会使站点看起来很慢。在上面的示例中，队列中的第20个包需要等待2秒才能被转发，此时返回给客户端的响应可能不再有用。要解决这个情况，可以在`burst`参数后添加`nodelay`参数：

```shell
location /login/ {
	limit_req zone=mylimit burst=20 nodelay;

	proxy_pass http://my_upstream;
}
```

使用`nodelay`参数，Nginx仍将根据`burst`参数分配队列中的位置，并应用已配置的速率限制，而不是清理队列中等待转发的请求。相反地，当一个请求到达“太早”时，只要在队列中能分配位置，Nginx将立即转发这个请求。将队列中的该位置标记为”taken”(占据)，并且不会被释放以供另一个请求使用，直到一段时间后才会被释放(在这个示例中是，100毫秒后)。

假设如前所述，队列中有20个空位，从给定的IP地址发出的21个请求同时到达。Nginx会立即转发这个21个请求，并且标记队列中占据的20个位置，然后每100毫秒释放一个位置。如果是25个请求同时到达，Nginx将会立即转发其中的21个请求，标记队列中占据的20个位置，并且返回503状态码来拒绝剩下的4个请求。

现在假设，第一组请求被转发后101毫秒，另20个请求同时到达。队列中只会有一个位置被释放，所以Nginx转发一个请求并返回503状态码来拒绝其他19个请求。如果在20个新请求到达之前已经过去了501毫秒，5个位置被释放，所以Nginx立即转发5个请求并拒绝另外15个。

效果相当于每秒10个请求的“流量限制”。如果希望不限制两个请求间允许间隔的情况下实施“流量限制”，`nodelay`参数是很实用的。

**注意：** 对于大部分部署，我们建议使用`burst`和`nodelay`参数来配置`limit_req`指令。

##### 5、高级配置示例

通过将基本的“流量限制”与其他Nginx功能配合使用，我们可以实现更细粒度的流量限制。

###### 1、白名单

下面这个例子将展示，如何对任何不在白名单内的请求强制执行“流量限制”：

```shell
geo $limit {
	default 		1;
	10.0.0.0/8 		0;
	192.168.0.0/24 	0;
}

map $limit $limit_key {
	0 "";
	1 $binary_remote_addr;
}

limit_req_zone $limit_key zone=req_zone:10m rate=5r/s;

server {
	location / {
		limit_req zone=req_zone burst=10 nodelay;

		# ...
	}
}
```

这个例子同时使用了`geo`和`map`指令。`geo`块将给在白名单中的IP地址对应的`$limit`变量分配一个值0，给其它不在白名单中的分配一个值1。然后我们使用一个映射将这些值转为key，如下：

- 如果`$limit`变量的值是0，`$limit_key`变量将被赋值为空字符串
- 如果`$limit`变量的值是1，`$limit_key`变量将被赋值为客户端二进制形式的IP地址

两个指令配合使用，白名单内IP地址的`$limit_key`变量被赋值为空字符串，不在白名单内的被赋值为客户端的IP地址。当`limit_req_zone`后的第一个参数是空字符串时，不会应用“流量限制”，所以白名单内的IP地址(10.0.0.0/8和192.168.0.0/24 网段内)不会被限制。其它所有IP地址都会被限制到每秒5个请求。

`limit_req`指令将限制应用到**/**的location块，允许在配置的限制上最多超过10个数据包的突发，并且不会延迟转发。

###### 2、location 包含多`limit_req`指令

我们可以在一个location块中配置多个`limit_req`指令。符合给定请求的所有限制都被应用时，意味着将采用最严格的那个限制。例如，多个指令都制定了延迟，将采用最长的那个延迟。同样，请求受部分指令影响被拒绝，即使其他指令允许通过也无济于事。

扩展前面将“流量限制”应用到白名单内IP地址的例子：

```shell
http {
	# ...

	limit_req_zone $limit_key zone=req_zone:10m rate=5r/s;
	limit_req_zone $binary_remote_addr zone=req_zone_wl:10m rate=15r/s;

	server {
		# ...
		location / {
			limit_req zone=req_zone burst=10 nodelay;
			limit_req zone=req_zone_wl burst=20 nodelay;
			# ...
		}
	}
}
```

白名单内的IP地址不会匹配到第一个“流量限制”，而是会匹配到第二个`req_zone_wl`，并且被限制到每秒15个请求。不在白名单内的IP地址两个限制能匹配到，所以应用限制更强的那个：每秒5个请求。

##### 6、配置流量控制相关功能

###### 1、配置日志记录

默认情况下，Nginx会在日志中记录由于流量限制而延迟或丢弃的请求，如下所示：

```shell
2019/02/13 04:20:00 [error] 120315#0: *32086 limiting requests, excess: 1.000 by zone "mylimit", client: 192.168.1.2, server: nginx.com, request: "GET / HTTP/1.0", host: "nginx.com"
```

日志条目中包含的字段：

- limiting requests - 表明日志条目记录的是被“流量限制”请求
- excess - 每毫秒超过对应“流量限制”配置的请求数量
- zone - 定义实施“流量限制”的区域
- client - 发起请求的客户端IP地址
- server - 服务器IP地址或主机名
- request - 客户端发起的实际HTTP请求
- host - HTTP报头中host的值

默认情况下，Nginx以`error`级别来记录被拒绝的请求，如上面示例中的`[error]`所示(Ngin以较低级别记录延时请求，一般是`info`级别)。如要更改Nginx的日志记录级别，需要使用`limit_req_log_level`指令。这里，我们将被拒绝请求的日志记录级别设置为`warn`：

```shell
location /login/ {
	limit_req zone=mylimit burst=20 nodelay;
	limit_req_log_level warn;
	
	proxy_pass http://my_upstream;
} 
```

###### 2、发送到客户端的错误代码

一般情况下，客户端超过配置的流量限制时，Nginx响应状态码为**503(Service Temporarily Unavailable)**。可以使用`limit_req_status`指令来设置为其它状态码(例如下面的**444**状态码):

```shell
location /login/ {
	limit_req zone=mylimit burst=20 nodelay;
	limit_req_status 444;
}
```

###### 3、指定`location`拒绝所有请求

如果你想拒绝某个指定URL地址的所有请求，而不是仅仅对其限速，只需要在`location`块中配置`deny` **all**指令：

```shell
location /foo.php {
	deny all;
}
```

##### 7、nginx 流量控制总结

以上已经涵盖了Nginx和Nginx Plus提供的“流量限制”的很多功能，包括为HTTP请求的不同loation设置请求速率，给“流量限制”配置`burst`和`nodelay`参数。还涵盖了针对客户端IP地址的白名单和黑名单应用不同“流量限制”的高级配置，阐述了如何去日志记录被拒绝和延时的请求。

#### 18、nginx 访问控制

##### 1、nginx 访问控制模块

（1）基于IP的访问控制：http_access_module
（2）基于用户的信任登录：http_auth_basic_module

##### 2、基于IP的访问控制

###### 1、配置语法

```shell
Syntax：allow address | CIDR | unix: | all;
default：默认无
Context：http，server，location，limit_except

Syntax：deny address | CIDR | unix: | all;
default：默认无
Context：http，server，location，limit_except
```

###### 2、配置测试

修改`/etc/nginx/conf.d/access_mod.conf`内容如下：

```shell
    location ~ ^/admin.html {
        root   /opt/app/code;
		deny 192.168.174.1;
		allow all;
        index  index.html index.htm;
    }
```

虚拟机宿主机IP为`192.168.174.1`，虚拟机IP为`192.168.174.132`，故这里禁止宿主机访问，允许其他所有IP访问。
宿主机访问`http://192.168.174.132/admin.html`，显示`403 Forbidden`。
当然也可以反向配置，同时也可以使用IP网段的配置方式，如`allow 192.168.174.0/24;`，表示满足此网段的IP都可以访问。

###### 3、局限性

`remote_addr`只能记录上一层与服务器直接建立连接的IP地址，若中间有代理，则记录的是代理的IP地址。
`http_x_forwarded_for`可以记录每一层级的IP。
![在这里插入图片描述](assets/20181004205405831.jpg)

###### 4、解决方法

（1）采用别的HTTP头信息控制访问，如HTTP_X_FORWARD_FOR（无法避免被改写）
（2）结合geo模块
（3）通过HTTP自定义变量传递

##### 3、基于用户的信任登录

###### 1、配置语法

```shell
Syntax：auth_basic string | off;
default：auth_basic off;
Context：http，server，location，limit_except

Syntax：auth_basic_user_file file;
default：默认无
Context：http，server，location，limit_except
file：存储用户名密码信息的文件。
```

###### 2、配置示例

改名`access_mod.conf`为`auth_mod.conf`，内容如下：

```shell
    location ~ ^/admin.html {
        root   /opt/app/code;
        auth_basic "Auth access test!";
        auth_basic_user_file /etc/nginx/auth_conf;
        index  index.html index.htm;
    }
```

`auth_basic`不为`off`，开启登录验证功能，`auth_basic_user_file`加载账号密码文件。

###### 3、建立口令文件

```shell
[root@web ~]# htpasswd -cm /etc/nginx/auth_conf user10
[root@web ~]# htpasswd -m /etc/nginx/auth_conf user20
[root@web ~]# cat /etc/nginx/auth_conf 
user10:$apr1$Cw6eF/..$MNBh6rvkvsfH9gDZ/kEhg/
user20:$apr1$tb6B8...$y28sfvudhfb4V8xPlvvi//
```

###### 4、访问测试

![在这里插入图片描述](assets/20181005105818783.jpg)

###### 5、局限性

（1）用户信息依赖文件方式
（2）操作管理机械，效率低下

###### 6、解决方法

（1）Nginx结合LUA实现高效验证
（2）Nginx和LDAP打通，利用nginx-auth-ldap模块
（3）Nginx只做中间代理，具体认证交给应用。

#### 19、nginx 变量(了解)

Nginx 同 Apache 和 Lighttpd 等其他 Web 服务器的配置记法不太相同，Nginx的配置文件使用语法的就是一门微型的编程语言。可以类似写程序一般编写配置文件，可操作性很大。既然是编程语言，一般也就少不了“变量”这种东西。

##### 1、nginx变量简介

- 所有的 Nginx变量在 Nginx 配置文件中引用时都须带上 $ 前缀

- 在 Nginx 配置中，变量只能存放一种类型的值，有且也只存在一种类型，那就是字符串类型
- nginx可以使用变量简化配置与提高配置的灵活性，所有的变量值都可以通过这种方式引用：

```shell
$变量名
```

##### 2、nginx 变量的定义和使用

nginx中的变量分为两种，自定义变量与内置预定义变量

###### 1、自定义变量

**1、声明变量**
可以在sever,http,location等标签中使用set命令（非唯一）声明变量，语法如下

```shell
set $变量名 变量值
```

**注意:**

- nginx 中的变量必须都以$开头

- nginx 的配置文件中所有使用的变量都必须是声明过的，否则 nginx 会无法启动并打印相关异常日志

**2、变量的可见性**

nginx 变量的一个有趣的特性就是nginx中每一个变量都是全局可见的，而他们又不是全局变量。如下例子

```shell
       location /a {
         return 200 $a;
       }
       
       location /b {
        set $a hellonginx;
        return 200 $a;
       }

```

由于变量是全局可见的所以nginx启动不会报错，而第一个location中并不知道$a的具体值因此返回的响应结果为一个空字符串。

在不同层级的标签中声明的变量性的可见性规则如下:

- location标签中声明的变量中对这个location块可见

- server标签中声明的变量对server块以及server块中的所有子块可见

- http标签中声明的变量对http块以及http块中的所有子块可见

**3、配置 $foo=hello**

```shell
server {
    listen 8080;
    server_name  localhost;
    
    location /test {
            set $foo hello;
            echo "foo: $foo";
    }
}
```

输出

```shell
[root@localhost html]# nginx -s reload
[root@localhost html]# curl localhost/test
foo:  hello

echo模块属于第三方模块需要单独安装 echo-nginx-module-： https://www.cnblogs.com/quail2333/p/11181589.html

wget https://github.com/openresty/echo-nginx-module/archive/v0.61.tar.gz

[root@10v3v137v113 nginx]# ./configure  --group=nginx --user=nginx --prefix=/usr/local/nginx --sbin-path=/usr/sbin/nginx  --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/tmp/nginx/client_body  --http-proxy-temp-path=/tmp/nginx/proxy  --http-fastcgi-temp-path=/tmp/nginx/fastcgi --pid-path=/var/run/nginx.pid --lock-path=/var/lock/nginx  --with-http_stub_status_module --with-http_ssl_module   --with-http_gzip_static_module --with-pcre --add-module=../echo-nginx-module-0.62rc1/ 
```

**4、 输出 $ 符**

如果我们想通过 echo 指令直接输出含有“美元符”（$）的字符串，那么有没有办法把特殊的 $ 字符给转义掉呢？答案是否定的。不过幸运的是，我们可以绕过这个限制，比如通过不支持“变量插值”的模块配置指令专门构造出取值为 $ 的 Nginx 变量，然后再在 echo 中使用这个变量。看下面这个例子：

```shell
http {
    ...
    geo $dollar {
        default "$";
    }
    server {
        ...
       
        location /test-dollar {
            echo "This is a dollar sign: $dollar";
        }
    }
}
```

输出

```shell
[root@localhost html]# nginx -s reload
[root@localhost html]# curl localhost/test-dollar
This is a dollar sign: \$
```

这里用到了标准模块 ngx_geo 提供的配置指令 geo 来为变量 $dollar 赋予字符串 "$"，这样我们在下面需要使用美元符的地方，就直接引用我们的 $dollar 变量就可以了。

**5、 使用大括号插值**

在“变量插值”的上下文中，还有一种特殊情况，即当引用的变量名之后紧跟着变量名的构成字符时（比如后跟字母、数字以及下划线），我们就需要使用特别的记法来消除歧义，例如：

```shell
server {
    ...
    location /test-brace {
        set $first "hello ";
        echo "${first}world";
    }
}
```

输出

```shell
[root@localhost html]# nginx -s reload
[root@localhost html]# curl localhost/test-brace
hello world
```

这里，我们在 echo 配置指令的参数值中引用变量 first 的时候，后面紧跟着 world 这个单词，所以如果直接写作 "firstworld" 则 Nginx “变量插值”计算引擎会将之识别为引用了变量 firstworld. 为了解决这个难题，Nginx 的字符串记法支持使用花括号在  之后把变量名围起来，比如这里的 ${first}。

**6、变量作用域**

set 指令（以及前面提到的 geo 指令）不仅有赋值的功能，它还有创建 Nginx 变量的副作用，即当作为赋值对象的变量尚不存在时，它会自动创建该变量。比如在上面这个例子中，如果 $a 这个变量尚未创建，则 set 指令会自动创建 $a 这个用户变量。如果我们不创建就直接使用它的值，则会报错。
 例如

```shell
 server {
    ...
    location /bad {
        echo $foo;
    }
}
```

此时 Nginx 服务器会拒绝加载配置:

```shell
[emerg] unknown "foo" variable
```

Nginx 变量的创建和赋值操作发生在全然不同的时间阶段，Nginx 变量的创建只能发生在 Nginx 配置加载的时候，或者说 Nginx 启动的时候，而赋值操作则只会发生在请求实际处理的时候。
 这意味着不创建而直接使用变量会导致启动失败，同时也意味着我们无法在请求处理时动态地创建新的 Nginx 变量。

Nginx 变量一旦创建，其变量名的可见范围就是整个 Nginx 配置，甚至可以跨越不同虚拟主机的 server 配置块。我们来看一个例子：

```shell
server {
    listen 8080;
    
    location /foo {
        echo "foo = [$foo]";
    }
    
    location /bar {
        set $foo 32;
        echo "foo = [$foo]";
    }
}
```

输出

```shell
[root@localhost html]# curl 'http://localhost/foo'
foo = []

[root@localhost html]# curl 'http://localhost/bar'
foo = [32]

[root@localhost html]# curl 'http://localhost/foo'
foo = []
```

这里我们在 location /bar 中用 set 指令创建了变量 foo，于是在整个配置文件中这个变量都是可见的，因此我们可以在 location /foo 中直接引用这个变量而不用担心 Nginx 会报错。
 从这个例子我们可以看到，set 指令因为是在 location /bar 中使用的，所以赋值操作只会在访问 /bar 的请求中执行。而请求 /foo 接口时，我们总是得到空的 foo值，因为用户变量未赋值就输出的话，得到的便是空字符串。

从这个例子我们可以窥见的另一个重要特性是，Nginx 变量名的可见范围虽然是整个配置，但每个请求都有所有变量的独立副本，或者说都有各变量用来存放值的容器的独立副本，彼此互不干扰。比如前面我们请求了 /bar 接口后，foo 变量被赋予了值 32，但它丝毫不会影响后续对 /foo 接口的请求所对应的 foo 值（它仍然是空的！），因为各个请求都有自己独立的 $foo 变量的副本。

对于 Nginx 新手来说，最常见的错误之一，就是将 Nginx 变量理解成某种在请求之间全局共享的东西，或者说“全局变量”。而事实上，Nginx 变量的生命期是不可能跨越请求边界的。

关于 Nginx 变量的另一个常见误区是认为变量容器的生命期，是与 location 配置块绑定的。其实不然。我们来看一个涉及“内部跳转”的例子：

```shell
server {
    listen 8080;

    location /foo {
        set $a hello;
        echo_exec /bar;
    }

    location /bar {
        echo "a = [$a]";
    }
}
```

输出

```shell
[root@localhost html]# curl localhost/foo
a = [hello]
```

这 里我们在 location /foo 中，使用第三方模块 ngx_echo 提供的 echo_exec 配置指令，发起到 location /bar 的“内部跳转”。所谓“内部跳转”，就是在处理请求的过程中，于服务器内部，从一个 location 跳转到另一个 location 的过程。这不同于利用 HTTP 状态码 301 和 302 所进行的“外部跳转”，因为后者是由 HTTP 客户端配合进行跳转的，而且在客户端，用户可以通过浏览器地址栏这样的界面，看到请求的 URL 地址发生了变化。内部跳转和 Bourne Shell（或 Bash）中的 exec 命令很像，都是“有去无回”。另一个相近的例子是 C 语言中的 goto 语句。

既然是内部跳转，当前正在处理的请求就还是原来那个，只是当前的 location 发生了变化，所以还是原来的那一套 Nginx 变量的容器副本。对应到上例，如果我们请求的是 /foo 这个接口，那么整个工作流程是这样的：先在 location /foo 中通过 set 指令将 a 变量的值赋为字符串 hello，然后通过 echo_exec 指令发起内部跳转，又进入到 location /bar 中，再输出 a 变量的值。因为 a 还是原来的 a，所以我们可以期望得到 hello 这行输出。测试证实了这一点：

但如果我们从客户端直接访问 /bar 接口，就会得到空的 a 变量的值，因为它依赖于 location /foo 来对 a 进行初始化。

从上面这个例子我们看到，一个请求在其处理过程中，即使经历多个不同的 location 配置块，它使用的还是同一套 Nginx 变量的副本。这里，我们也首次涉及到了“内部跳转”这个概念。值得一提的是，标准 ngx_rewrite 模块的 rewrite 配置指令其实也可以发起“内部跳转”，例如上面那个例子用 rewrite 配置指令可以改写成下面这样的形式：

```shell
server {

    listen 8080;

    location /foo {
        set $a hello;
        rewrite ^ /bar;
    }

    location /bar {
        echo "a = [$a]";
    }
}
```

从上面这个例子我们看到，Nginx 变量值容器的生命期是与当前正在处理的请求绑定的，而与 location 无关。

###### 2、内置预定义变量

内置预定义变量即无需声明就可以使用的变量，通常包括一个http请求或响应中一部分内容的值，以下为一些常用的内置预定义变量

| **变量名**          | **定义**                                                     |
| ------------------- | ------------------------------------------------------------ |
| $arg_PARAMETER      | GET请求中变量名PARAMETER参数的值。                           |
| $args               | 这个变量等于GET请求中的参数。例如，foo=123&bar=blahblah;这个变量只可以被修改 |
| $binary_remote_addr | 二进制码形式的客户端地址。                                   |
| $body_bytes_sent    | 传送页面的字节数                                             |
| $content_length     | 请求头中的Content-length字段。                               |
| $content_type       | 请求头中的Content-Type字段。                                 |
| $cookie_COOKIE      | cookie COOKIE的值。                                          |
| $document_root      | 当前请求在root指令中指定的值。                               |
| $document_uri       | 与$uri相同。                                                 |
| $host               | 请求中的主机头(Host)字段，如果请求中的主机头不可用或者空，则为处理请求的server名称(处理请求的server的server_name指令的值)。值为小写，不包含端口。 |
| $hostname           | 机器名使用 gethostname系统调用的值                           |
| $http_HEADER        | HTTP请求头中的内容，HEADER为HTTP请求中的内容转为小写，-变为_(破折号变为下划线)，例如：$http_user_agent(Uaer-Agent的值); |
| $sent_http_HEADER   | HTTP响应头中的内容，HEADER为HTTP响应中的内容转为小写，-变为_(破折号变为下划线)，例如： $sent_http_cache_control, $sent_http_content_type…; |
| $is_args            | 如果$args设置，值为"?"，否则为""。                           |
| $limit_rate         | 这个变量可以限制连接速率。                                   |
| $nginx_version      | 当前运行的nginx版本号。                                      |
| $query_string       | 与$args相同。                                                |
| $remote_addr        | 客户端的IP地址。                                             |
| $remote_port        | 客户端的端口。                                               |
| $remote_user        | 已经经过Auth Basic Module验证的用户名。                      |
| $request_filename   | 当前连接请求的文件路径，由root或alias指令与URI请求生成。     |
| $request_body       | 这个变量（0.7.58+）包含请求的主要信息。在使用proxy_pass或fastcgi_pass指令的location中比较有意义。 |
| $request_body_file  | 客户端请求主体信息的临时文件名。                             |
| $request_completion | 如果请求成功，设为"OK"；如果请求未完成或者不是一系列请求中最后一部分则设为空。 |
| $request_method     | 这个变量是客户端请求的动作，通常为GET或POST。包括0.8.20及之前的版本中，这个变量总为main request中的动作，如果当前请求是一个子请求，并不使用这个当前请求的动作。 |
| $request_uri        | 这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI。 |
| $scheme             | 所用的协议，比如http或者是https，比如rewrite ^(.+)$ $scheme://example.com$1 redirect; |
| $server_addr        | 服务器地址，在完成一次系统调用后可以确定这个值，如果要绕开系统调用，则必须在listen中指定地址并且使用bind参数。 |
| $server_name        | 服务器名称。                                                 |
| $server_port        | 请求到达服务器的端口号。                                     |
| $server_protocol    | 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。                   |
| $uri                | 请求中的当前URI(不带请求参数，参数位于args)，不同于浏览器传递的args)，不同于浏览器传递的args)，不同于浏览器传递的request_uri的值，它可以通过内部重定向，或者使用index指令进行修改。不包括协议和主机名，例如/foo/bar.html |

Nginx 内建变量最常见的用途就是获取关于请求或响应的各种信息。

**1、uri  vs request_uri**

由 ngx_http_core 模块提供的内建变量 uri，可以用来获取当前请求的 URI（经过解码，并且不含请求参数），
而 request_uri 则用来获取请求最原始的 URI （未经解码，并且包含请求参数）。

```shell
location /test-uri {
    echo "uri = $uri";
    echo "request_uri = $request_uri";
}


location /test-uri {
    return "uri = $uri \n request_uri = $request_uri \n";
}
```

输出

```shell
[root@localhost html]# nginx -s reload
[root@localhost html]# curl localhost/test-uri
uri = /test-uri
request_uri = /test-uri

[root@localhost html]# curl "localhost/test-uri?a=3&b=4"
uri = /test-uri
request_uri = /test-uri?a=3&b=4

[root@localhost html]# curl "localhost/test-uri/hello%20world?a=3&b=4"
uri = /test-uri/hello world
request_uri = /test-uri/hello%20world?a=3&b=4
```

**2、$arg_XXX**

另一个特别常用的内建变量其实并不是单独一个变量，而是有无限多变种的一群变量，即名字以 arg_ 开头的所有变量，我们估且称之为 arg_XXX 变量群。
 一个例子是 arg_name，这个变量的值是当前请求中名为 name 的参数的值，而且还是未解码的原始形式的值。

```shell
location /test-arg {
    echo "name: $arg_name";
    echo "class: $arg_class";
}

   location /test-arg  {
    return 200 "name: $arg_name \n class: $arg_class \n";
   }
```

输出

```shell
[root@localhost html]# nginx -s reload
[root@localhost html]# curl localhost/test-arg
name: 
class:

[root@localhost html]# curl "localhost/test-arg?name=Tom&class=3"
name: Tom
class: 3

[root@localhost html]# curl "localhost/test-arg?name=hello%20world&class=9"
name: hello%20world
class: 9
```

**3、$arg_XXX 不区分大小写**

其实 $arg_name 不仅可以匹配 name 参数，也可以匹配 NAME 参数，抑或是 Name，Nginx 会在匹配参数名之前，自动把原始请求中的参数名调整为全部小写的形式。

```shell
[root@localhost html]# curl "localhost/test-arg?NAME=Marry"
name: Marry
class:

[root@localhost html]# curl "localhost/test-arg?Name=Jimmy"
name: Jimmy
class:
 
```

**4、对 uri 解码**

如果你想对 URI 参数值中的 %XX 这样的编码序列进行解码，可以使用第三方 ngx_set_misc 模块提供的

```shell
location /test-unescape-uri {
    set_unescape_uri $name $arg_name;
    set_unescape_uri $class $arg_class;
    echo "name: $name";
    echo "class: $class";
}
```

现在我们再看一下效果：

```shell
[root@localhost html]# curl "localhost/test-arg?name=hello%20world&class=9"
name: hello world
class: 9
```

从这个例子我们同时可以看到，这个 set_unescape_uri 指令也像 set 指令那样，拥有自动创建 Nginx 变量的功能。后面我们还会专门介绍到 ngx_set_misc 模块。

像 $arg_XXX 这种类型的变量拥有无穷无尽种可能的名字，所以它们并不对应任何存放值的容器。而且这种变量在 Nginx 核心中是经过特别处理的，第三方 Nginx 模块是不能提供这样充满魔法的内建变量的。

类 似 arg_XXX 的内建变量还有不少，比如用来取 cookie 值的 cookie_XXX 变量群，用来取请求头的 http_XXX 变量群，以及用来取响应头的 sent_http_XXX 变量群。这里就不一一介绍了，感兴趣的读者可以参考 ngx_http_core 模块的官方文档。

#### 20、nginx 监控									

##### 1、nginx的基础监控

- 进程监控

- 端口监控

注意： 这两个是必须要加在zabbix监控，加触发器有问题及时告警。

web 服务器 nginx 以其高性能与抗并发能力越来越多的被用户使用

作为一款服务器产品，其运行状态是运维密切关注的，因此，对 nginx 的实时监控就必须要关注的了

nginx 提供了 ngx_http_stub_status_module，ngx_http_reqstat_module模块，这个模块提供了基本的监控功能

作为官方企业版的 nginx plus 通过 ngx_http_status_module 提供了更加完善的监控功能: http://demo.nginx.com/status.html

##### 2、监控的主要指标

我们需要对以下主要的指标进行监控：

###### 1、基本活跃指标

Accepts（接受）、Handled（已处理）、Requests（请求数）是一直在增加的计数器。Active（活跃）、Waiting（等待）、Reading（读）、Writing（写）随着请求量而增减。

| 名称                        | 描述                          | 指标类型     |
| --------------------------- | ----------------------------- | ------------ |
| Accepts（接受）             | NGINX 所接受的客户端连接数    | 资源: 功能   |
| Handled（已处理）           | 成功的客户端连接数            | 资源: 功能   |
| Dropped（已丢弃，计算得出） | 丢弃的连接数（接受 - 已处理） | 工作：错误*  |
| Requests（请求数）          | 客户端请求数                  | 工作：吞吐量 |

NGINX worker 进程接受 OS 的连接请求时 Accepts 计数器增加，而Handled 是当实际的请求得到连接时（通过建立一个新的连接或重新使用一个空闲的）。这两个计数器的值通常都是相同的，如果它们有差别则表明连接被Dropped，往往这是由于资源限制，比如已经达到 NGINX 的worker_connections的限制。

###### 2、每秒请求数 -- QPS

按照固定时间间隔采样请求数据，计算出单位时间的请求量可以看到你的 web 服务器的请求情况

通过持续的 QPS 监控，可以立刻发现是否被恶意攻击或对服务的可用性进行评估

虽然当问题发生时，通过 QPS 不能定位到确切问题的位置，但是他却可以在第一时间提醒你环境可能出问题了

###### 3、服务器错误率

通过监控固定时间间隔内的错误代码（4XX代码表示客户端错误，5XX代码表示服务器端错误），可以了解到客户端收到的结果是否是正确的错误率突然的飙升很可能是你的网站漏洞发出的信号

 如果你希望通过 access log 分析错误率，那么你需要配置 nginx 的日志模块，让 nginx 将响应码写入访问日志

###### 4、请求处理时间

请求处理时间也可以被记录在 access log 中，通过分析 access log，统计请求的平均响应时间，通过持续观察，可以发现上游服务器的问题 

##### 3、指标的收集

介绍了这么多的监控指标，事实上，上面介绍的仅仅是基本的监控指标，针对实际的情况，还有很多指标十分具有监控的必要

那么，怎么去收集这些指标进行监控呢？

通过在编译时加入 `nginx` 的 `ngx_http_stub_status_module` 模块我们可以实时监控以下基本的指标：

###### 1、nginx Stub Status 监控模块安装

　先使用命令查看是否已经安装这个模块：

```
# -V大写会显示版本号和模块等信息、v小写仅显示版本信息
[root@nginx]#./nginx -V 

# 或用此使用看：
[root@nginx]#nginx -V 2>&1 | grep -o with-http_stub_status_module　

```

如果已经安装，会在显示的信息中包含 `--with-http_stub_status_module`信息。如果没有此模块，需要重新安装，编译命令如下：

```
./configure –with-http_stub_status_module
```

具体的使用方法是在执行 ./configure 时，指定 --with-http_stub_status_module，然后通过配置：

```
location /nginx-status {
            stub_status            on;
            access_log             on;
        　  allow 127.0.0.1;
            deny all;
            #auth_basic              "nginxstatus";
            #auth_basic_user_file  conf/nginxstaus;
}
```

此处默认只有本地访问，如果远程查看需要加相关的IP或者干脆去掉Deny all即可。加密文件可以使用#htpasswd -c /usr/nginx/conf hxb 命令来创建。配置完成后需要重启Nginx服务。状态配置只能是针对某个Nginx服务。目前Nginx还无法做到针对单个站点进行监控。

###### 2、nginx 状态查看

配置完成后在浏览器中输入http://127.0.0.1/nginx-status 查看（或者用 `curl localhost/nginx_status`），显示信息如下：

```
Active connections: 100 
server accepts handled requests
 1075 1064 6253 
Reading: 0 Writing: 5 Waiting: 95 
```

Accepts（接受）、Handled（已处理）、Requests（请求数）是一直在增加的计数器。Active（活跃）、Waiting（等待）、Reading（读）、Writing（写）随着请求量而增减。

| 名称                        | 描述                          | 指标类型     |
| --------------------------- | ----------------------------- | ------------ |
| Accepts（接受）             | NGINX 所接受的客户端连接数    | 资源: 功能   |
| Handled（已处理）           | 成功的客户端连接数            | 资源: 功能   |
| Dropped（已丢弃，计算得出） | 丢弃的连接数（接受 - 已处理） | 工作：错误*  |
| Requests（请求数）          | 客户端请求数                  | 工作：吞吐量 |

###### 4、Stub Status 参数说明

　　active connections – 活跃的连接数量

　　server accepts handled requests — 总共处理了1075个连接 , 成功创建1064次握手, 总共处理了6253个请求

　　每个连接有三种状态waiting、reading、writing

　　reading —读取客户端的Header信息数.这个操作只是读取头部信息，读取完后马上进入writing状态，因此时间很短。

　　writing — 响应数据到客户端的Header信息数.这个操作不仅读取头部，还要等待服务响应，因此时间比较长。

　　waiting — 开启keep-alive后等候下一次请求指令的驻留连接.

　　正常情况下waiting数量是比较多的，并不能说明性能差。反而如果reading+writing数量比较多说明服务并发有问题。

![img](assets/430613-20170929094324825-146276623.png)

| **名称**           | **描述**                                                     | **是否累加历史数据** |
| ------------------ | :----------------------------------------------------------- | -------------------- |
| Accepts（接受）    | NGINX 接受的客户端连接数（包括 Handled + Dropped + Waiting） | 是                   |
| Handled（已处理）  | 成功处理的客户端连接数（包含 Waiting 状态连接）              | 是                   |
| Active（活跃）     | 当前活跃的客户端连接数                                       | 否                   |
| Dropped（已丢弃）  | 已丢弃连接数（出错）                                         | 是                   |
| Requests（请求数） | 客户端请求数                                                 | 是                   |
| Waiting（等待）    | 正在等待的连接数                                             | 否                   |
| Reading（读）      | 正在执行读操作的连接数                                       | 否                   |
| Writing（写）      | 正在执行写操作的连接数                                       | 否                   |

当用户请求连接Nginx服务器时，accepts计数器会加一。且当服务器处理该连接请求时，handled计数器同样会加一。一般而言，两者的值是相等的，除非达到了某些资源极限（如worker_connection的限制）。

用户连接请求被处理，就会进入 active 状态。如果该连接没有其他 request，则进入 waiting 的子状态；如果有 request，nginx 会读取 request 的 header，计数器 request 加一，进入 reading 的子状态。 reading 状态持续时间非常短，header 被读取后就会进入 writing 状态。事实上，直到服务器将响应结果返回给用户之前，该连接会一直保持 writing 状态。所以说，writing 状态一般会被长时间占用。

一旦 NGINX 成功处理一个连接时，连接会移动到Active状态，在这里对客户端请求进行处理：

**Active状态**

> **Waiting**: 活跃的连接也可以处于 Waiting 子状态，如果有在此刻没有活跃请求的话。新连接可以绕过这个状态并直接变为到 Reading 状态，最常见的是在使用“accept filter（接受过滤器）” 和 “deferred accept（延迟接受）”时，在这种情况下，NGINX 不会接收 worker 进程的通知，直到它具有足够的数据才开始响应。如果连接设置为 keep-alive ，那么它在发送响应后将处于等待状态。
> **Reading**: 当接收到请求时，连接离开 Waiting 状态，并且该请求本身使 Reading 状态计数增加。在这种状态下 NGINX 会读取客户端请求首部。请求首部是比较小的，因此这通常是一个快速的操作。
> **Writing**: 请求被读取之后，其使 Writing 状态计数增加，并保持在该状态，直到响应返回给客户端。这意味着，该请求在 Writing 状态时， 一方面 NGINX 等待来自上游系统的结果（系统放在 NGINX “后面”），另外一方面，NGINX 也在同时响应。请求往往会在 Writing 状态花费大量的时间。

通常，一个连接在同一时间只接受一个请求。在这种情况下，Active 连接的数目 == Waiting 的连接 + Reading 请求 + Writing 。

**怎么利用这些参数？**

开源的 Nginx 提供的原始参数中，实时性的会比较有用，如 Active connections、Reading、Writing 以及 Waiting。这些数据能够反映当前 Nginx 的负载情况，方便在服务器出现问题时及时发现问题。而另一些数据由于不是状态量，Nginx 无法计算当前的量值而改做其统计数，如 accepts、handled 和 requests。

对于维护网站人员，accepts、handled 和 requests 的统计值用处是不大的，值得参考的是短时间内这三者数值的增量。这个短时间可以是一秒，如 accepts_per_second、handled_per_second 和 requests_per_second。一个简单的做法就是每秒都去读取这些参数，返回一个和上一秒的差值就行。当然，handled_per_second 替换成 dropped_per_second=accepts_per_second-handled_per_second 就更完美了。

通过这七个参数，就可以从连接到请求全方位的监控起 Nginx 的运行状态。为了方便检测，对每次获取的参数保留下来，然后按时间展现出来。下图展示了 Nginx 在运行时的参考数据。

![670102-601974e319b158ea](assets/670102-601974e319b158ea.png)

nginx折线图

###### 5、Reqstat 模块监控

**描述**

- ngx_http_reqstat_module 模块

- 这个模块计算定义的变量，根据变量值分别统计 nginx 的运行状况。
- 可以监视的运行状况有：连接数、请求数、各种响应码范围的请求数、输入输出流量、rt、upstream访问等。
- 可以指定获取所有监控结果或者一部分监控结果。
- 利用变量添加自定义监控状态。总的监控状态最大个数为50个。
- 回收过期的监控数据。
- 设置输出格式
- 跟踪请求，不受内部跳转的影响
- 不要使用与响应相关的变量作为条件，比如"$status"

**编译**

默认编入Tengine，可通过 --without-http_reqstat_module 不编译此模块，或通过--with-http_reqstat_module=shared 编译为so模块。

使用so模块加载的话，请确保其顺序在"ngx_http_lua_module"之后。可以借助"nginx -m"来确认。

**例子**

```
http {
    req_status_zone server "$host,$server_addr:$server_port" 10M;
    req_status_zone_add_indicator server $limit;
    
    server {
        location /us {
            req_status_show;
            req_status_show_field req_total $limit;
        }

        set $limit 0;

        if ($arg_limit = '1') {
            set $limit 1;
        }

        req_status server;
    }
}
```

- 以上例，通过访问/us得到统计结果
- 每行对应一个server
- 每行的默认格式

```
kv,bytes_in,bytes_out,conn_total,req_total,http_2xx,http_3xx,http_4xx,http_5xx,http_other_status,rt,ups_req,ups_rt,ups_tries,http_200,http_206,http_302,http_304,http_403,http_404,http_416,http_499,http_500,http_502,http_503,http_504,http_508,http_other_detail_status,http_ups_4xx,http_ups_5xx
```

- kv 计算得到的req_status_zone指令定义变量的值，最大长度可配置，默认104B，超长的部分截断
- bytes_in 从客户端接收流量总和
- bytes_out 发送到客户端流量总和
- conn_total 处理过的连接总数
- req_total 处理过的总请求数
- http_2xx 2xx请求的总数
- http_3xx 3xx请求的总数
- http_4xx 4xx请求的总数
- http_5xx 5xx请求的总数
- http_other_status 其他请求的总数
- rt rt的总数
- ups_req 需要访问upstream的请求总数
- ups_rt 访问upstream的总rt
- ups_tries upstram总访问次数
- http_200 200请求的总数
- http_206 206请求的总数
- http_302 302请求的总数
- http_304 304请求的总数
- http_403 403请求的总数
- http_404 404请求的总数
- http_416 416请求的总数
- http_499 499请求的总数
- http_500 500请求的总数
- http_502 502请求的总数
- http_503 503请求的总数
- http_504 504请求的总数
- http_508 508请求的总数
- http_other_detail_status 非以上13种status code的请求总数
- http_ups_4xx upstream返回4xx响应的请求总数
- http_ups_5xx upstream返回5xx响应的请求总数
- 可以用"req_status_show_field"指令定义输出格式。左侧栏是字段的名字。
- 注，后续会清理这些状态，因为已经支持了自定义状态。
- tsar可解析输出结果，具体见<https://github.com/alibaba/tsar>

**指令**

> **Syntax**: _req_status_zone zone_name value size_
> **Default**: *none*
> **Context**: *main*

创建统计使用的共享内存。zone_name是共享内存的名称，value用于定义key，支持变量。size是共享内存的大小。

例子：

```
req_status_zone server "$host,$server_addr:$server_port" 10M;
```

创建名为“server”的共享内存，大小10M，使用“$host,$server_addr:$server_port”计算key。

- 注意，如果希望用tsar来监控的话，key的定义中请不要使用逗号。

------

> **Syntax**: _req_status zone_name1 [zone_name2 [zone_name3 [...]]]_
> **Default**: *none*
> **Context**: *http、srv、loc*

开启统计，可以指定同时统计多个目标，每一个zone_name对应一个目标。

------

> **Syntax**: _req_status_show [zone_name1 [zone_name2 [...]]]_
> **Default**: *所有建立的共享内存目标*
> **Context**: *loc*

按格式返回统计结果。可指定返回部分目标的统计结果。

------

> **Syntax**: _req_status_show_field field_name1 [field_name2 [field_name3 [...]]]_
> **Default**: *all the fields, including user defined fields*
> **Context**: *loc*

定义输出格式。可以使用的字段：内置字段，以上面的名字来表示；自定义字段，用变量表示。
'kv'总是每行的第一个字段。

------

> **Syntax**: _req_status_zone_add_indecator zone_name $var1 [$var2 [...]]_
> **Default**: *none*
> **Context**: *http*

通过变量增加自定义字段，新增加的字段目前会展现在每行的末尾。

------

> **Syntax**: _req_status_zone_key_length zone_name length_
> **Default**: *none*
> **Context**: *http*

定义某个共享内存块中key的最大长度，默认值104。key中超出的部分会被截断。

------

> **Syntax**: _req_status_zone_recycle zone_name times seconds_
> **Default**: *none*
> **Context**: *http*

定义某个共享内存块过期数据的回收。回收在共享内存耗尽时自动开启。只会回收访问频率低于设置值的监控数据。
频率定义为 times / seconds，默认值为10r/min，即

```
req_status_zone_recycle demo_zone 10 60;
```

```
tengine官方说req-statu模块默认安装。但是并没有。而且tengine的req-status模块不能分upstream监控，从github引入第三方模块解决该问题

1. 安装
# cd /usr/local/src/
 # wget "http://nginx.org/download/nginx-1.4.2.tar.gz"
 # tar -xzvf nginx-1.4.2.tar.gz
 # wget https://github.com/zls0424/ngx_req_status/archive/master.zip -O ngx_req_status.zip
 # unzip ngx_req_status.zip
 # cd nginx-1.4.2/
 # patch -p1 < ../ngx_req_status-master/write_filter.patch
 # yum -y install pcre pcre-devel openssl openssl-devel gcc gcc-c++   zlib zlib-devel
 # ./configure --prefix=/usr/local/nginx-1.4.2 --add-module=../ngx_req_status-master
 # make -j2
 # make install
 # useradd nginx    passwd nginx
2. 配置
http {
 req_status_zone server_name $server_name 256k;
 req_status_zone server_addr $server_addr 256k;
 req_status_zone server_url  $server_name$uri 256k;
req_status server_name server_addr server_url;
server {
 server_name www.1000status.com;
 location /req-status {
 req_status_show on;
 }
 }
 }
 
 指令介绍
 req_status_zone
语法: req_status_zone name string size
默认值: None
配置块: http
定义请求状态ZONE,请求按照string分组来排列，例如：
req_status_zone server_url  $server_name$uri 256k;
域名+uri将会形成一条数据，可以看到所有url的带宽，流量，访问数

req_status
语法: req_status zone1[ zone2]
默认值: None
配置块: http, server, location
在location中启用请求状态，你可以指定更多zones。

req_status_show
语法: req_status_show on
默认值: None
配置块: location



./configure --prefix=/usr/local/nginx-1.4.2 --add-module=../ngx_req_status-master --sbin-path=/usr/sbin/nginx  --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/tmp/nginx/client_body  --http-proxy-temp-path=/tmp/nginx/proxy  --http-fastcgi-temp-path=/tmp/nginx/fastcgi --pid-path=/var/run/nginx.pid --lock-path=/var/lock/nginx  --with-http_stub_status_module --with-http_ssl_module   --with-http_gzip_static_module --with-pcre  --group=nginx --user=nginx
```



###### 6、补充：

查看Nginx并发进程数：ps -ef | grep nginx | wc -l

查看Web服务器TCP连接状态：netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'

商业版的 nginx plus 通过他的 ngx_http_status_module 提供了比 nginx 更多的监控指标，可以参看 http://demo.nginx.com/status.html

##### 4、nginx  access log 分析

nginx 的 access log 中可以记录很多有价值的信息，通过分析 access log，可以收集到很多指标

python 编写的 linux 工具 ngxtop 就实现了对 access log 的分析功能

## 三、HTTPS 基本原理

### 1、https 介绍

HTTPS（全称：HyperText Transfer Protocol over   Socket Layer），其实 HTTPS 并不是一个新鲜协议，Google 很早就开始启用了，初衷是为了保证数据安全。 近些年，Google、Baidu、Facebook 等这样的互联网巨头，不谋而合地开始大力推行 HTTPS， 国内外的大型互联网公司很多也都已经启用了全站 HTTPS，这也是未来互联网发展的趋势。

为鼓励全球网站的 HTTPS 实现，一些互联网公司都提出了自己的要求：

1. Google 已调整搜索引擎算法，让采用 HTTPS 的网站在搜索中排名更靠前；
2. 从 2017 年开始，Chrome 浏览器已把采用 HTTP 协议的网站标记为不安全网站；
3. 苹果要求 2017 年App Store 中的所有应用都必须使用 HTTPS 加密连接；
4. 当前国内炒的很火热的微信小程序也要求必须使用 HTTPS 协议；
5. 新一代的 HTTP/2 协议的支持需以 HTTPS 为基础。

等等，因此想必在不久的将来，全网 HTTPS 势在必行。

### 1、HTTPS 协议介绍

- HTTP 协议（HyperText Transfer Protocol，超文本传输协议）：是客户端浏览器或其他程序与Web服务器之间的应用层通信协议 。

- HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：可以理解为HTTP+SSL/TLS， 即 HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL，用于安全的 HTTP 数据传输。

  ![https通信模型](assets/20180315171037158.jpg)

  如上图所示 HTTPS 相比 HTTP 多了一层 SSL/TLS

  - SSL（Secure Socket Layer，安全套接字层）：1994年为 Netscape 所研发，SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。
  - TLS（Transport Layer Security，传输层安全）：其前身是 SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从 3.1 开始被 IETF 标准化并改名，发展至今已经有 TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。TLS 1.3 改动会比较大，目前还在草案阶段，目前使用最广泛的是TLS 1.1、TLS 1.2。

### 2、加密算法

据记载，公元前400年，古希腊人就发明了置换密码；在第二次世界大战期间，德国军方启用了“恩尼格玛”密码机，所以密码学在社会发展中有着广泛的用途。

1. 对称加密 
   有流式、分组两种，加密和解密都是使用的同一个密钥。 
   例如：DES、AES-GCM、ChaCha20-Poly1305等

2. 非对称加密 
   加密使用的密钥和解密使用的密钥是不相同的，分别称为：公钥、私钥，公钥和算法都是公开的，私钥是保密的。非对称加密算法性能较低，但是安全性超强，由于其加密特性，非对称加密算法能加密的数据长度也是有限的。

   例如：RSA、DSA、ECDSA、 DH、ECDHE

3. 哈希算法 
   将任意长度的信息转换为较短的固定长度的值，通常其长度要比信息小得多，且算法不可逆。

   例如：MD5、SHA-1、SHA-2、SHA-256 等  

4. 数字签名 
   签名就是在信息的后面再加上一段内容（信息经过hash后的值），可以证明信息没有被修改过。hash值一般都会加密后（也就是签名）再和信息一起发送，以保证这个hash值不被修改。

### 3、HTTPS 原理

#### 1、HTTP 访问过程

![HTTP访问过程](assets/20180315172027310.jpg)

抓包如下： 
![http抓包](assets/20180315173440895.png)

如上图所示，HTTP请求过程中，客户端与服务器之间没有任何身份确认的过程，数据全部明文传输，“裸奔”在互联网上，所以很容易遭到黑客的攻击，如下：

![请求拦截](assets/20180315173521936.jpg)

可以看到，客户端发出的请求很容易被黑客截获，如果此时黑客冒充服务器，则其可返回任意信息给客户端，而不被客户端察觉，所以我们经常会听到一词“劫持”，现象如下：

下面两图中，浏览器中填入的是相同的URL，左边是正确响应，而右边则是被劫持后的响应（从貌美如花变成如花。。。）

![如花](assets/20180315173614623.jpg)

所以 HTTP 传输面临的风险有：

- 窃听风险：黑客可以获知通信内容。
- 篡改风险：黑客可以修改通信内容。
- 冒充风险：黑客可以冒充他人身份参与通信。

#### 2、HTTP 向 HTTPS 演化的过程

第一步：为了防止上述现象的发生，人们想到一个办法：对传输的信息加密（即使黑客截获，也无法破解）

![内容加密](assets/20180315173848849.jpg)

如上图所示，此种方式属于对称加密，双方拥有相同的密钥，信息得到安全传输，但此种方式的缺点是：

（1）不同的客户端、服务器数量庞大，所以双方都需要维护大量的密钥，维护成本很高

（2）因每个客户端、服务器的安全级别不同，密钥极易泄露

第二步：既然使用对称加密时，密钥维护这么繁琐，那我们就用非对称加密试试

![非对称加密](assets/20180315173957150.jpg)

如上图所示，客户端用公钥对请求内容加密，服务器使用私钥对内容解密，反之亦然，但上述过程也存在缺点：

（1）公钥是公开的（也就是黑客也会有公钥），所以第 ④ 步私钥加密的信息，如果被黑客截获，其可以使用公钥进行解密，获取其中的内容

第三步：非对称加密既然也有缺陷，那我们就将对称加密，非对称加密两者结合起来，取其精华、去其糟粕，发挥两者的各自的优势

![对称加密与非对称加密](assets/20180315174319365.jpg)

如上图所示

（1）第 ③ 步时，客户端说：（咱们后续回话采用对称加密吧，这是对称加密的算法和对称密钥）这段话用公钥进行加密，然后传给服务器

（2）服务器收到信息后，用私钥解密，提取出对称加密算法和对称密钥后，服务器说：（好的）对称密钥加密

（3）后续两者之间信息的传输就可以使用对称加密的方式了

遇到的问题：

（1）客户端如何获得公钥

（2）如何确认服务器是真实的而不是黑客

第四步：获取公钥与确认服务器身份

![这里写图片描述](assets/20180315174512605.png)

1、获取公钥

（1）提供一个下载公钥的地址，回话前让客户端去下载。（缺点：下载地址有可能是假的；客户端每次在回话前都先去下载公钥也很麻烦）

（2）回话开始时，服务器把公钥发给客户端（缺点：黑客冒充服务器，发送给客户端假的公钥）

2、那有木有一种方式既可以安全的获取公钥，又能防止黑客冒充呢？ 那就需要用到终极武器了：SSL 证书（申购）

![ssl证书](assets/20180315174553025.jpg)

如上图所示，在第 ② 步时服务器发送了一个SSL证书给客户端，SSL 证书中包含的具体内容有：

（1）证书的发布机构CA

（2）证书的有效期

（3）公钥

（4）证书所有者

（5）签名

………

3、客户端在接受到服务端发来的SSL证书时，会对证书的真伪进行校验，以浏览器为例说明如下：

（1）首先浏览器读取证书中的证书所有者、有效期等信息进行一一校验

（2）浏览器开始查找操作系统中已内置的受信任的证书发布机构CA，与服务器发来的证书中的颁发者CA比对，用于校验证书是否为合法机构颁发

（3）如果找不到，浏览器就会报错，说明服务器发来的证书是不可信任的。

（4）如果找到，那么浏览器就会从操作系统中取出 颁发者CA 的公钥，然后对服务器发来的证书里面的签名进行解密

（5）浏览器使用相同的hash算法计算出服务器发来的证书的hash值，将这个计算的hash值与证书中签名做对比

（6）对比结果一致，则证明服务器发来的证书合法，没有被冒充

（7）此时浏览器就可以读取证书中的公钥，用于后续加密了

4、所以通过发送SSL证书的形式，既解决了公钥获取问题，又解决了黑客冒充问题，一箭双雕，HTTPS加密过程也就此形成

所以相比HTTP，HTTPS 传输更加安全

（1） 所有信息都是加密传播，黑客无法窃听。

（2） 具有校验机制，一旦被篡改，通信双方会立刻发现。

（3） 配备身份证书，防止身份被冒充。

#### 3、HTTPS 总结

综上所述，相比 HTTP 协议，HTTPS 协议增加了很多握手、加密解密等流程，虽然过程很复杂，但其可以保证数据传输的安全。所以在这个互联网膨胀的时代，其中隐藏着各种看不见的危机，为了保证数据的安全，维护网络稳定，建议大家多多推广HTTPS。

HTTPS 缺点：

1. SSL 证书费用很高，以及其在服务器上的部署、更新维护非常繁琐
2. HTTPS 降低用户访问速度（多次握手）
3. 网站改用HTTPS 以后，由HTTP 跳转到 HTTPS 的方式增加了用户访问耗时（多数网站采用302跳转）
4. HTTPS 涉及到的安全算法会消耗 CPU 资源，需要增加大量机器（https访问过程需要加解密）





### 4、构建私有的 CA 机构

#### 1、CA 介绍

CA（Certificate Authority）证书颁发机构主要负责证书的颁发、管理以及归档和吊销。证书内包含了拥有证书者的姓名、地址、电子邮件帐号、公钥、证书有效期、发放证书的CA、CA的数字签名等信息。证书主要有三大功能：加密、签名、身份验证。

#### 2、构建私有 CA

##### 1、检查安装 openssl

```
rpm -qa openssl
```

如果未安装，安装 openssl

```
yum install openssl openssl-devel
```

##### 2、查看配置文件

openssl 配置`/etc/pki/tls/openssl.cnf`有关CA的配置。如果服务器为证书签署者的身份那么就会用到此配置文件，此配置文件对于证书申请者是无作用的。

```
####################################################################
[ ca ]
default_ca      = CA_default            # 默认的CA配置；CA_default指向下面配置块

####################################################################
[ CA_default ]

dir             = /etc/pki/CA           # CA的默认工作目录
certs           = $dir/certs            # 认证证书的目录
crl_dir         = $dir/crl              # 证书吊销列表的路径
database        = $dir/index.txt        # 数据库的索引文件


new_certs_dir   = $dir/newcerts         # 新颁发证书的默认路径

certificate     = $dir/cacert.pem       # 此服务认证证书，如果此服务器为根CA那么这里为自颁发证书
serial          = $dir/serial           # 下一个证书的证书编号
crlnumber       = $dir/crlnumber        # 下一个吊销的证书编号
                                        
crl             = $dir/crl.pem          # The current CRL
private_key     = $dir/private/cakey.pem# CA的私钥
RANDFILE        = $dir/private/.rand    # 随机数文件

x509_extensions = usr_cert              # The extentions to add to the cert

name_opt        = ca_default            # 命名方式，以ca_default定义为准
cert_opt        = ca_default            # 证书参数，以ca_default定义为准


default_days    = 365                   # 证书默认有效期
default_crl_days= 30                    # CRl的有效期
default_md      = sha256                # 加密算法
preserve        = no                    # keep passed DN ordering


policy          = policy_match          #policy_match策略生效

# For the CA policy
[ policy_match ]
countryName             = match         #国家；match表示申请者的申请信息必须与此一致
stateOrProvinceName     = match         #州、省
organizationName        = match         #组织名、公司名
organizationalUnitName  = optional      #部门名称；optional表示申请者可以的信息与此可以不一致
commonName              = supplied
emailAddress            = optional

# For the 'anything' policy
# At this point in time, you must list all acceptable 'object'
# types.
[ policy_anything ]                     #由于定义了policy_match策略生效，所以此策略暂未生效
countryName             = optional
stateOrProvinceName     = optional
localityName            = optional
organizationName        = optional
organizationalUnitName  = optional
commonName              = supplied
emailAddress            = optional
```

##### 3、根证书服务器目录

根CA服务器：因为只有 CA 服务器的角色，所以用到的目录只有/etc/pki/CA

网站服务器：只是证书申请者的角色，所以用到的目录只有`/etc/pki/tls`

##### 4、创建所需要的文件

```
[root@server ~]# cd /etc/pki/CA/
[root@server CA]# ls
certs  crl  newcerts  private
[root@server CA]# touch index.txt        #生成证书索引数据库文件
[root@server CA]# ls
certs  crl  index.txt  newcerts  private
[root@server CA]# echo 01 > serial       #指定第一个颁发证书的序列号
[root@server CA]# ls
certs  crl  index.txt  newcerts  private  serial
```

##### 5、创建密钥

在根CA服务器上创建密钥，密钥的位置必须为`/etc/pki/CA/private/cakey.pem`，这个是openssl.cnf中中指定的路径，只要与配置文件中指定的匹配即可。

```
[root@server CA]# (umask 066; openssl genrsa -out private/cakey.pem 2048)
Generating RSA private key, 2048 bit long modulus
........................................................+++
.........................+++
e is 65537 (0x10001)
```

##### 6、生成自签名证书

根CA自签名证书，根CA是最顶级的认证机构，没有人能够认证他，所以只能自己认证自己生成自签名证书。

```shell
[root@server CA]# openssl req -new -x509 -key /etc/pki/CA/private/cakey.pem -days 7300 -out /etc/pki/CA/cacert.pem -days 7300
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN   
State or Province Name (full name) []:BEIJING      
Locality Name (eg, city) [Default City]:BEIJING
Organization Name (eg, company) [Default Company Ltd]:CA
Organizational Unit Name (eg, section) []:OPT
Common Name (eg, your name or your server's hostname) []:ca.qf.com
Email Address []:
[root@server CA]# ls
cacert.pem  certs  crl  index.txt  newcerts  private  serial
```

````shell
-new: 	生成新证书签署请求
-x509: 	专用于CA生成自签证书
-key: 	生成请求时用到的私钥文件
-days n：	证书的有效期限
-out /PATH/TO/SOMECERTFILE: 	证书的保存路径
````

##### 7、下载安装证书

`/etc/pki/CA/cacert.pem`就是生成的自签名证书文件，使用 `SZ/xftp `工具将他导出到窗口机器中。然后双击安装此证书到受信任的根证书颁发机构

![6852280-6bb4319ac06298f4](assets/6852280-6bb4319ac06298f4.png)

#### 3、CA 证书申请及签名

##### 1、检查安装 openssl

```
rpm -qa openssl
```

如果未安装，安装 openssl

```
yum install openssl openssl-devel
```

##### 2、客户端生成私钥文件

```
[root@node1 ~]# (umask 066; openssl genrsa -out /etc/pki/tls/private/www.qf.com.key 2048)
Generating RSA private key, 2048 bit long modulus
......................+++
....................................................................................+++
e is 65537 (0x10001)
[root@node1 ~]# cd /etc/pki/tls/private
[root@node1 private]# ls
www.qf.com.key
```

##### 3、客户端用私钥加密生成证书请求

```
[root@node1 private]# ls ../
cert.pem  certs  misc  openssl.cnf  private  
[root@node1 private]# openssl req -new -key /etc/pki/tls/private/www.qf.com.key -days 365 -out /etc/pki/tls/www.qf.com.csr
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [XX]:CN
State or Province Name (full name) []:BEIJING
Locality Name (eg, city) [Default City]:BEIJING
Organization Name (eg, company) [Default Company Ltd]:QF
Organizational Unit Name (eg, section) []:OPT
Common Name (eg, your name or your server's hostname) []:www.qf.com
Email Address []:

Please enter the following 'extra' attributes
to be sent with your certificate request
A challenge password []:
An optional company name []:
[root@node1 private]# cd ../
[root@node1 tls]# ls
cert.pem  certs  misc  openssl.cnf  private  www.qf.com.csr
```

CSR(Certificate Signing Request)包含了公钥和名字信息。通常以.csr为后缀，是网站向CA发起认证请求的文件，是中间文件。

在这一命令执行的过程中，系统会要求填写如下信息：

| **要求添写的内容**                          |                                                              |
| ------------------------------------------- | ------------------------------------------------------------ |
| Country Name (2 letter code)                | 使用国际标准组织(ISO)国码格式，填写2个字母的国家代号。中国请填写CN |
| State or Province Name (full name)          | 省份，比如填写BeiJing                                        |
| Locality Name (eg, city)                    | 城市，比如填写BeiJing                                        |
| Organization Name (eg, company)             | 组织单位，比如填写公司名称的拼音                             |
| Organizational Unit Name (eg, section)      | 比如填写IT Dept                                              |
| Common Name (eg, your websites domain name) | 城市，比如填写BeiJing                                        |
| Email Address                               | 邮件地址，可以不填                                           |
| A challenge password                        | 可以不填                                                     |
| An optional company name                    | 可以不填                                                     |
|                                             |                                                              |

最后把生成的请求文件（`/etc/pki/tls/www.qf.com.csr`）传输给CA ,这里我使用scp命令，通过ssh协议，将该文件传输到CA下的`/etc/pki/CA/private/`目录

```
root@node1 tls]# scp www.qf.com.csr 192.168.95.134:/etc/pki/CA/private/
root@192.168.95.134's password: 
www.qf.com.csr                          100%  997   777.2KB/s   00:00    
```

##### 4、CA 签署证书

```shell
[root@server ~]# openssl ca -in /etc/pki/CA/private/www.qf.com.csr -out /etc/pki/CA/certs/www.qf.com.ctr -days 365
Using configuration from /etc/pki/tls/openssl.cnf
Check that the request matches the signature
Signature ok
Certificate Details:
        Serial Number: 1 (0x1)
        Validity
            Not Before: Mar 14 13:45:02 2019 GMT
            Not After : Mar 13 13:45:02 2020 GMT
        Subject:
            countryName               = CN
            stateOrProvinceName       = BEIJING
            organizationName          = QF
            organizationalUnitName    = OPT
            commonName                = www.qf.com
        X509v3 extensions:
            X509v3 Basic Constraints: 
                CA:FALSE
            Netscape Comment: 
                OpenSSL Generated Certificate
            X509v3 Subject Key Identifier: 
                08:65:70:98:2B:0B:15:D0:74:FE:69:58:05:B8:02:BC:45:D8:23:9B
            X509v3 Authority Key Identifier: 
                keyid:60:6B:BC:F1:A1:01:BF:72:FD:7D:02:A8:BD:15:BE:9C:3B:3E:03:30

Certificate is to be certified until Mar 13 13:45:02 2020 GMT (365 days)
Sign the certificate? [y/n]:y


1 out of 1 certificate requests certified, commit? [y/n]y
Write out database with 1 new entries
Data Base Updated

```

证书通常以.crt为后缀，表示证书文件

###### 1、可能遇到的问题

```shell
[root@server ~]# openssl openssl ca -in /etc/pki/CA/private/www.qf.com.csr -out /etc/pki/CA/certs/www.qf.com.ctr -days 365
Using configuration from /etc/pki/tls/openssl.cnf
Check that the request matches the signature
Signature ok
The organizationName field needed to be the same in the
CA certificate (CA) and the request (QF)
```

 因为默认使用/etc/pki/tls/openssl.cnf，里面要求其一致，修改organizationName=supplied

修改 /etc/pki/tls/openssl.cnf

```shell
# For the CA policy
[ policy_match ]
countryName             = match
stateOrProvinceName     = match
organizationName        = supplied
organizationalUnitName  = optional
commonName              = supplied
emailAddress            = optional
```

###### 2、查看生成的证书的信息

```shell
[root@server ~]# openssl x509 -in /etc/pki/CA/certs/www.qf.com.ctr -noout -subject
subject= /C=CN/ST=BEIJING/O=QF/OU=OPT/CN=www.qf.com
```

###### 3、将生成的证书发放给请求客户端

```shell
[root@server ~]# scp www.qf.com.ctr root@192.168.95.135:/etc/pki/CA/certs/
root@192.168.95.135's password: 
www.qf.com.ctr                            100% 4422     1.3MB/s   00:00  
```

#### 4、CA吊销证书

##### 1、知道客户端吊销的证书的serial

```shell
[root@server ~]#openssl x509 -in /PATH/FROM/CERT_FILE -noout -serial -subject
```

##### 2、吊销证书

先根据客户提交的serial与subject信息，对比检验是否与index.txt文件中的信息一致；然后

```shell
[root@server ~]#openssl ca -revoke /etc/pki/CA/newcerts/SERIAL.pem
```

##### 3、生成吊销证书的编号

第一次吊销一个证书时才需要执行

```shell
[root@server ~]#echo 01 > /etc/pki/CA/crlnumber
```

##### 4、更新证书吊销列表

```shell
[root@server ~]#openssl ca -gencrl -out thisca.crl
```

##### 5、查看证书吊销列表

```shell
[root@server ~]#openssl crl -in /PATH/FROM/CRL_FILE.crl -noout -text
```

### 5、nginx HTTPS 部署实战

1. 申请证书与认证
2. 证书下载与配置
3. 问题分析与总结

#### 1、申请证书与认证

要搭建https服务首先需有SSL证书，证书通常是在第三方申请，在阿里云的安全服务中有SSL证书这一项，可以在里面申请免费的证书；

> 也可以在自己电脑中生成，虽然也能完成加密，但是浏览器是不认可的，因此最好还是去第三方申请

##### 1、证书申请

阿里云提供免费的证书，不需要人工审核，用来做测试是非常不错的选择，申请地址如下URL。

```
https://common-buy.aliyun.com/?spm=5176.2020520163.cas.1.1aa12b7aWWn20O&commodityCode=cas#/buy

新的地址包
https://common-buy.aliyun.com/?spm=5176.13785142.commonbuy2container.9.5516778btlfsOZ&commodityCode=cas_dv_public_cn&request=%7B%22ord_time%22:%221:Year%22,%22order_num%22:1,%22product%22:%22free_product%22,%22certCount%22:%2220%22%7D
```

免费型的证书隐藏的比较深，想要申请免费证书需要先选择 1个域名->Symantec->免费型  ,所以读者这里需要注意一下，如下图参考。



![6598643-5b29948ff76173bc](assets/6598643-5b29948ff76173bc.png)

选择之后，一直点击下一步，便可购买完成，免费购买证书之后笔者需要回到证书控制台，在控制台有一个补全信息的链接地址，需要通过此地址补充申请人的联系信息，参考下图填写

![6598643-c0eb3d7857ff3b92](assets/6598643-c0eb3d7857ff3b92.png)

##### 2、域名验证

补全个人信息之后，还需要给阿里云验证当前域名是属于本人的，验证方式有两种，第一种是通过dns解析认证，第二种是通过上传验证文件认证，这里采用的是验证文件认证，首先需要下载文件，如下图

![6598643-a1bbf991b8e8a936](assets/6598643-a1bbf991b8e8a936.png)

在下载验证文件完成之后，笔者需要把文件放到服务器中去，这里提供一条复制命令

```
[root@web ~]#scp ~/Downloads/fileauth.txt  root@192.168.43.34:~/
```

将验证文件复制到服务器之后，还需要将验证文件放到站点对应目录，参考命令如下：

```
[root@web ~]#mkdir -p /website/.well-known/pki-validation  &&  cp  fileauth.txt  /website/.well-known/pki-validation/
```

现在要验证文件放置的位置是否正确，通过两种方式进行了验证，分别是手动验证，和阿里云验证。

###### 1、手动验证

手动验证的目的是首先确保文件位置放置是否正确，可以通过访问站点的url是否成功进行判断，比如笔者可以访问如下URL，如果返回如果页面能够正常打开，并且可以看到某些值，则代表配置成功。

```
http://www.qf.com/.well-known/pki-validation/fileauth.txt
```

###### 2、通过阿里云来验证

在确保文件放置正确之后，关键的是能让阿里云能访问到，阿里云这里提供了一个检查配置的功能，在下载验证文件页面，有一个检测配置的链接，单击之后便可进行检查，如下图。

![6598643-1a5df2dc183233ee](assets/6598643-1a5df2dc183233ee.png)

当点击 检查配置 之后，如果阿里云能够正常访问，则会在左侧给出提示，现在可以返回证书列表，在列表中可以看到当前状态为审核中，如下图

![6598643-066ec1c866aa2673](assets/6598643-066ec1c866aa2673.png)

审核因为不需要人为干预，所以很快就能下发证书，下发证书的时间大约是2分钟左右。

#### 2、证书下载与配置

##### 1、证书下载

证书签发之后，可以在列表中可以看到状态栏中为 已签发 ，同时操作栏可以下载以及查看详情等，如下图所示

![6598643-14e38b61e170ca7c](assets/6598643-14e38b61e170ca7c.png)

点击下载后，会跳转到下载详情页面，在下载详情页可以选择自己相对应的web服务，比如使用nginx，当选择nginx之后，下方还会很贴心的提示如何配置，下载nginx配置文件。

下载配置文件之后，需要将其解压，解压之后可以看见里面包含了两个证书文件

xxx.key

xxx.pem

接着需要把这两个证书文件给复制到服务器当中去，首先需要在服务器创建对应的文件夹，参考命令如下

```
[root@web ~]#cd  /usr/local/nginx/conf/  &&  mkdir cert    #此命令在服务器执行
```

在服务器创建完成对应文件夹之后，执行命令将证书文件复制到服务器中，参考命令如下：

```
[root@web ~]#scp ~/Downloads/214905423420461/*  root@192.168.43.34:/usr/local/nginx/conf/cert
```

##### 2、证书配置

证书复制完成之后，可以对nginx配置文件进行更改，使用vim命令编辑nginx配置文件，参考命令如下：

```
[root@web ~]#vim /usr/local/nginx/conf/nginx.conf
```

在vim界面把之前http的配置部分复制一份，复制之后修改监听的端口(listen)为443，并在其后面添加ssl的信息，参考配置如下：

```
server {
        listen   80;
        server_name www.tigerfive.cn;
      
       location / {
         rewrite ^(.*)$ https://$host$1;
         }
}

server {
    listen 443 ssl;
    server_name www.tigerfive.cn;
    root html;
    index index.html index.htm;
    ssl_certificate www.tigerfive.cn.pem;
    ssl_certificate_key www.tigerfive.cn.key;
    ssl_session_timeout 5m;
    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_prefer_server_ciphers on;
    location / {
        root /usr/local/nginx/html;
        index index.html index.htm;
    }
}
```

##### 3、重启Nginx

修改配置文件之后，需要测试nginx配置文件是否正确

```
[root@web ~]#nginx -t 
```

当nginx如果没有出现error相关信息，基本配置没有问题，下面是我的nginx返回结果：

```
nginx: the configuration file /usr/local/etc/nginx/nginx.conf syntax is ok
nginx: configuration file /usr/local/etc/nginx/nginx.conf test is successful
```

nginx 配置没有问题之后，笔者需要重启nginx让其生效，参考命令如下

```
[root@web ~]#nginx -s reload
```

##### 4、检验效果

现在所有该做的工作都做好了，笔者可以通过浏览器来访问可以正常访问，打开如下URL。

```
https://www.xxx.com
```

浏览器地址栏显示如下图所示

![6598643-806f221850e2359d](assets/6598643-806f221850e2359d.png)

如果看到浏览器，展示安全，并且显示绿色就说明大功告成了

### 6、nginx 性能优化

当我需要进行性能优化时，说明我们服务器无法满足日益增长的业务。性能优化是一个比较大的课题，需要从以下几个方面进行探讨

- 当前系统结构瓶颈
- 了解业务模式
- 性能与安全

#### 1、当前系统结构瓶颈

首先需要了解的是当前系统瓶颈，用的是什么，跑的是什么业务。里面的服务是什么样子，每个服务最大支持多少并发。比如针对nginx而言，我们处理静态资源效率最高的瓶颈是多大？能支持多少qps访问请求？怎么得出系统当前的结构瓶颈？

可以通过查看当前cpu负荷，内存使用率，进程使用率来做简单判断。还可以通过操作系统的一些工具来判断当前系统性能瓶颈，如分析对应的日志，查看请求数量。也可以通过nginx http_stub_status_module模块来查看对应的连接数，总握手次数，总请求数。也可以对线上进行压力测试，来了解当前的系统能性能，并发数，做好性能评估。

#### 2、了解业务模式

虽然我们是在做性能优化，但还是要熟悉业务，最终目的都是为业务服务的。我们要了解每一个接口业务类型是什么样的业务，比如电子商务抢购模式，这种情况平时流量会很小，但是到了抢购时间，流量一下子就会猛涨。也要了解系统层级结构，每一层在中间层做的是代理还是动静分离，还是后台进行直接服务。需要我们对业务接入层和系统层次要有一个梳理

#### 3、性能与安全

性能与安全也是一个需要考虑的因素，往往大家注重性能忽略安全或注重安全又忽略性能。比如说我们在设计防火墙时，如果规则过于全面肯定会对性能方面有影响。如果对性能过于注重在安全方面肯定会留下很大隐患。所以大家要评估好两者的关系，把握好两者的孰重孰轻，以及整体的相关性。权衡好对应的点。

#### 4、系统与nginx性能优化

大家对相关的系统瓶颈及现状有了一定的了解之后，就可以根据影响性能方面做一个全体的评估和优化。

- 网络（网络流量、是否有丢包，网络的稳定性都会影响用户请求）
- 系统（系统负载、饱和、内存使用率、系统的稳定性、硬件磁盘是否有损坏）
- 服务（连接优化、内核性能优化、http服务请求优化都可以在nginx中根据业务来进行设置）
- 程序（接口性能、处理请求速度、每个程序的执行效率）
- 数据库、底层服务

上面列举出来每一级都会有关联，也会影响整体性能，这里主要关注的是nginx服务这一层。

##### 1、文件句柄

在linux/unix操作系统中一切皆文件，我们的设备是文件，文件是文件，文件夹也是文件。当我们用户每发起一次请求，就会产生一个文件句柄。文件句柄可以简单的理解为`文件句柄就是一个索引`。文件句柄就会随着请求量的增多,进程调用频繁增加，那么产生的文件句柄也就会越多。

系统默认对文件句柄是有限制的，不可能会让一个进程无限制的调用句柄。因为系统资源是有限的，所以我们需要限制每一个服务能够使用多大的文件句柄。操作系统默认使用的文件句柄是1024个句柄。

##### 2、设置方式

- 系统全局性修改
- 用户局部性修改
- 进程局部性修改

##### 3、系统全局性修该和用户局部性修改

```shell
[root@server ~]#vim /etc/security/limits.conf
```

在文件最下面找到

```shell
#*               soft    core            0
#*               hard    rss             10000
#@student        hard    nproc           20
#@faculty        soft    nproc           20
#@faculty        hard    nproc           50
#ftp             hard    nproc           0
#@student        -       maxlogins       4

#root只是针对root这个用户来限制，soft只是发提醒，操作系统不会强制限制,一般的站点设置为一万左右就ok了
root soft nofile 65535
root hard nofile 65535
# *代表通配符 所有的用户
*    soft nofile 25535
*    hard nofile 25535
```

可以看到`root`和`*`，root代表是root用户，*代表的是所有用户，后面的数字就是文件句柄大小。大家可以根据个人业务来进行设置。

##### 4、进程局部性修改

```shell
[root@server ~]#vim /etc/nginx/nginx.conf
user  nginx;
worker_processes  1;  

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;

worker_rlimit_nofile 65535; #进程限制

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$http_user_agent' '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for" '
                      '"$args" "$request_uri"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on; 
    #tcp_nopush     on; 

    keepalive_timeout  65; 

    #gzip  on; 

    include /etc/nginx/conf.d/*.conf;
}
```

`worker_rlimit_nofile` 是在进程上面进行限制。

##### 5、cpu的亲和配置

cpu的亲和能够使nginx对于不同的work工作进程绑定到不同的cpu上面去。就能够减少在work间不断切换cpu，把进程通常不会在处理器之间频繁迁移，进程迁移的频率小，来减少性能损耗。[nginx 亲和配置](https://nginx.org/en/docs/ngx_core_module.html#worker_cpu_affinity)

查看物理cpu

```shell
[root@server ~]#cat /proc/cpuinfo|grep "physical id"|sort |uniq|wc -l
```

查看cpu核心数

```shell
[root@server ~]#cat /proc/cpuinfo|grep "cpu cores"|uniq
```

查看cpu使用率

```shell
[root@server ~]#top  回车后按 1
```

##### 6、配置worker_processes

```shell
[root@server ~]#vim /etc/nginx/nginx.conf
```

将刚才查看到自己cpu * cpu核心就是`worker_processes`

```shell
worker_processes 2; #根据自己cpu核心数配置
```

##### 7、cpu亲和配置

假如小菜的配置是2cpu，每个cpu是8核。配置如下

```shell
worker_processes 16;
  1010101010101010 0101010101010101;
```

配置完成后可以通过下面命令查看nginx进程配置在哪个核上

```shell
[root@server ~]#ps -eo pid,args,psr |grep [n]ginx
```

在nginx 1.9版本之后，就帮我们自动绑定了cpu;

```shell
worker_cpu_affinity auto;
```

#### 5、nginx通用配置优化

```shell
[root@server ~]#vim /etc/nginx/nginx.conf
#将nginx进程设置为普通用户，为了安全考虑
user nginx; 

#当前启动的worker进程，官方建议是与系统核心数一直
worker_processes 2;
#方式一， 第一个work进程绑定第一个cpu核心，第二个work进程绑定到第二个cpu核心，依次内推 直到弟16个
#wokrer_cpu_affinity 0000000000000000 0000000000000001 0000000000000010 0000000000000100 ... 1000000000000000

#方式二，当 worker_processes 2 时，表明 第一work进程可以绑定第 2 4 6 8 10 12 14 16 核心，那么第二work进程就绑定 奇数核心
#worker_cpu_affinity 1010101010101010 0101010101010101;

#方式三，就是自动分配绑定
worker_cpu_affinity auto;

#日志配置成warn
error_log /var/log/nginx/error.log warn; 
pid /var/run/nginx.pid;

#针对 nginx 句柄的文件限制
worker_rlimit_nofile 35535;
#事件模型
events {
    #使用epoll内核模型
    use epoll;
    #每一个进程可以处理多少个连接，如果是多核可以将连接数调高 worker_processes * 1024
    worker_connections 10240;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    charset utf-8;  #设置字符集

    #设置日志输出格式，根据自己的情况设置
    log_format  main  '$http_user_agent' '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for" '
                      '"$args" "$request_uri"';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;   #对静态资源的处理比较有效
    #tcp_nopush     on;   #如果做静态资源服务器可以打开
    #tcp_nodeny     on;   #当nginx做动态的服务时可以选择打开

    keepalive_timeout  65; 

    ########
    #Gzip module
    gzip  on;    #文件压缩默认可以打开
    gzip_disable "MSIE [1-6]\."; #对于有些浏览器不能识别压缩，需要过滤如ie6
    gzip_http_version 1.1;

    include /etc/nginx/conf.d/*.conf;
}
```

````shell
#查看 核心绑定的nginx work进程
[root@server ~]#ps -eo pid,args,psr | grep [n]ginx
````

#### 6、ab接口压力测试工具

ab是Apache超文本传输协议(HTTP)的性能测试工具。其设计意图是描绘当前所安装的Apache的执行性能，主要是显示你安装的Apache每秒可以处理多少个请求。

```shell
# 安装工具
[root@server ~]#yum install httpd-tools

# 使用
[root@server ~]#ab -n 2000 -c 2 http://127.0.0.1/index.html
-n 总的请求数
-c 并发数
-k 是否开启长连接
```

##### 1、参数选项

```linux
-n：即requests，用于指定压力测试总共的执行次数
-c：即concurrency，用于指定的并发数
-t：即timelimit，等待响应的最大时间(单位：秒)
-b：即windowsize，TCP发送/接收的缓冲大小(单位：字节)
-p：即postfile，发送POST请求时需要上传的文件，此外还必须设置-T参数
-u：即putfile，发送PUT请求时需要上传的文件，此外还必须设置-T参数
-T：即content-type，用于设置Content-Type请求头信息，例如：application/x-www-form-urlencoded，默认值为text/plain
-v：即verbosity，指定打印帮助信息的冗余级别
-w：以HTML表格形式打印结果
-i：使用HEAD请求代替GET请求
-x：插入字符串作为table标签的属性
-y：插入字符串作为tr标签的属性
-z：插入字符串作为td标签的属性
-C：添加cookie信息，例如："Apache=1234"(可以重复该参数选项以添加多个)
-H：添加任意的请求头，例如："Accept-Encoding: gzip"，请求头将会添加在现有的多个请求头之后(可以重复该参数选项以添加多个)
-A：添加一个基本的网络认证信息，用户名和密码之间用英文冒号隔开
-P：添加一个基本的代理认证信息，用户名和密码之间用英文冒号隔开
-X：指定使用的和端口号，例如:"126.10.10.3:88"
-V：打印版本号并退出
-k：使用HTTP的KeepAlive特性
-d：不显示百分比
-S：不显示预估和警告信息
-g：输出结果信息到gnuplot格式的文件中
-e：输出结果信息到CSV格式的文件中
-r：指定接收到错误信息时不退出程序
-H：显示用法信息，其实就是ab -help
```

##### 2、内容解释

```linux
Server Software:        nginx/1.10.2 (服务器软件名称及版本信息)
Server Hostname:        192.168.1.106(服务器主机名)
Server Port:            80 (服务器端口)

Document Path:          /index1.html. (供测试的URL路径)
Document Length:        3721 bytes (供测试的URL返回的文档大小)

Concurrency Level:      1000 (并发数)
Time taken for tests:   2.327 seconds (压力测试消耗的总时间)
Complete requests:      5000 (的总次数)
Failed requests:        688 (失败的请求数)
Write errors:           0 (网络连接写入错误数)
Total transferred:      17402975 bytes (传输的总数据量)
HTML transferred:       16275725 bytes (HTML文档的总数据量)
Requests per second:    2148.98 [#/sec] (mean) (平均每秒的请求数) 这个是非常重要的参数数值，服务器的吞吐量 
Time per request:       465.338 [ms] (mean) (所有并发用户(这里是1000)都请求一次的平均时间)
Time  request:       	0.247 [ms] (mean, across all concurrent requests) (单个用户请求一次的平均时间)
Transfer rate:          7304.41 [Kbytes/sec] received 每秒获取的数据长度 (传输速率，单位：KB/s)
...
Percentage of the requests served within a certain time (ms)
  50%    347  ## 50%的请求在347ms内返回 
  66%    401  ## 60%的请求在401ms内返回 
  75%    431
  80%    516
  90%    600
  95%    846
  98%   1571
  99%   1593
 100%   1619 (longest request)
```

##### 3、示例演示

```
[root@server ~]#ab -n 50 -c 20 http://walidream.com/sub_module
```

输出内容

```linux
Server Software:        nginx/1.14.1
Server Hostname:        walidream.com
Server Port:            80

Document Path:          /sub_module
Document Length:        169 bytes

Concurrency Level:      20
Time taken for tests:   0.005 seconds
Complete requests:      50
Failed requests:        0
Write errors:           0
Non-2xx responses:      50
Total transferred:      14900 bytes
HTML transferred:       8450 bytes
Requests per second:    9746.59 [#/sec] (mean)
Time per request:       2.052 [ms] (mean)
Time per request:       0.103 [ms] (mean, across all concurrent requests)
Transfer rate:          2836.41 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.1      0       1
Processing:     1    1   0.3      1       2
Waiting:        0    1   0.2      1       1
Total:          1    2   0.3      2       2

Percentage of the requests served within a certain time (ms)
  50%      2
  66%      2
  75%      2
  80%      2
  90%      2
  95%      2
  98%      2
  99%      2
 100%      2 (longest request)
```

##### 5、注意事项

● 测试机与被测试机要分开

● 不要对线上的服务器做压力测试

● 观察测试工具ab所在机器，以及被测试的前端机的CPU、内存、网络等都不超过最高限度的75%

##### 6、ab性能指标

###### 1、吞吐率（Requests per second）

服务器并发处理能力的量化描述，单位是reqs/s，指的是在某个并发用户数下单位时间内处理的请求数。某个并发用户数下单位时间内能处理的最大请求数，称之为最大吞吐率。记住：吞吐率是基于并发用户数的。这句话代表了两个含义：

```
● 吞吐率和并发用户数相关

● 不同的并发用户数下，吞吐率一般是不同的
```

计算公式：总请求数/处理完成这些请求数所花费的时间，即

```
Request per second=Complete requests/Time taken for tests
```

必须要说明的是，这个数值表示当前机器的整体性能，值越大越好

###### 2、并发连接数（The number of concurrent connections）

并发连接数指的是某个时刻服务器所接受的请求数目，简单的讲，就是一个会话。

###### 3、并发用户数（Concurrency Level）

要注意区分这个概念和并发连接数之间的区别，一个用户可能同时会产生多个会话，也即连接数。在HTTP/1.1下，IE7支持两个并发连接，IE8支持6个并发连接，FireFox3支持4个并发连接，所以相应的，我们的并发用户数就得除以这个基数。

###### 4.用户平均请求等待时间（Time per request）

计算公式：处理完成所有请求数所花费的时间/（总请求数/并发用户数），即：

```
Time per request=Time taken for tests/（Complete requests/Concurrency Level）
```

###### 5.服务器平均请求等待时间（Time per request:across all concurrent requests）

计算公式：处理完成所有请求数所花费的时间/总请求数，即：

```
Time taken for/testsComplete requests
```

可以看到，它是吞吐率的倒数。同时，它也等于用户平均请求等待时间/并发用户数，即

```
Time per request/Concurrency Level
```

### 7、cfssl 部署 (了解)

#### 1、下载cfssl工具

```shell

[root@server ~]#wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64
[root@server ~]#chmod +x cfssl_linux-amd64
[root@server ~]#sudo mv cfssl_linux-amd64 /root/local/bin/cfssl
 
[root@server ~]#wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64
[root@server ~]#chmod +x cfssljson_linux-amd64
[root@server ~]#sudo mv cfssljson_linux-amd64 /root/local/bin/cfssljson
 
[root@server ~]#wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64
[root@server ~]#chmod +x cfssl-certinfo_linux-amd64
[root@server ~]#sudo mv cfssl-certinfo_linux-amd64 /root/local/bin/cfssl-certinfo
 
[root@server ~]#export PATH=/root/local/bin:$PATH

```

#### 2、生成默认的配置文件和证书签名请求文件

```shell
[root@server ~]#cfssl print-defaults config > ca-config.json
[root@server ~]#cfssl print-defaults csr > ca-csr.json
```

##### 1、查看并修改CA 配置文件

```shell
[root@server ~]#cat ca-config.json 
{
    "signing": {
        "default": {
            "expiry": "9999h"
        },
        "profiles": {
            "www": {
                "expiry": "9999h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "server auth"
                ]
            },
            "client": {
                "expiry": "9999h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "client auth"
                ]
            }
        }
    }
}
```

+ `ca-config.json`：可以定义多个 profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个 profile；

+ `signing`：表示该证书可用于签名其它证书；生成的 ca.pem 证书中 `CA=TRUE`；

+ `server auth`：表示 client 可以用该 CA 对 server 提供的证书进行验证；

+ `client auth`：表示 server 可以用该 CA 对 client 提供的证书进行验证；

##### 2、查看并修改 CA 证书签名请求

```shell
{
  "CN": "registry.test.com",
  "hosts": [
    "127.0.0.1",
    "172.16.160.38",
    "registry.test.com"
  ],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}
```

+ "CN"：`Common Name`，kube-apiserver 从证书中提取该字段作为请求的用户名 (User Name)；浏览器使用该字段验证网站是否合法；

+ "O"：`Organization`，kube-apiserver 从证书中提取该字段作为请求用户所属的组 (Group)；

##### 3、生成 CA 证书和私钥

```shell
[root@server ~]#cfssl gencert -initca ca-csr.json | cfssljson -bare ca    #重新执行
[root@server ~]#ls ca*
ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem
```

##### 4、分发证书

#### 3、校验证书

##### 1、使用 `openssl` 命令校验证书

```shell
[root@server ~]#openssl x509  -noout -text -in  kubernetes.pem
...
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=CN, ST=BeiJing, L=BeiJing, O=k8s, OU=System, CN=Kubernetes
        Validity
            Not Before: Apr  5 05:36:00 2017 GMT
            Not After : Apr  5 05:36:00 2018 GMT
        Subject: C=CN, ST=BeiJing, L=BeiJing, O=k8s, OU=System, CN=kubernetes
...
        X509v3 extensions:
            X509v3 Key Usage: critical
                Digital Signature, Key Encipherment
            X509v3 Extended Key Usage:
                TLS Web Server Authentication, TLS Web Client Authentication
            X509v3 Basic Constraints: critical
                CA:FALSE
            X509v3 Subject Key Identifier:
                DD:52:04:43:10:13:A9:29:24:17:3A:0E:D7:14:DB:36:F8:6C:E0:E0
            X509v3 Authority Key Identifier:
                keyid:44:04:3B:60:BD:69:78:14:68:AF:A0:41:13:F6:17:07:13:63:58:CD
 
            X509v3 Subject Alternative Name:
                DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster, DNS:kubernetes.default.svc.cluster.local, IP Address:127.0.0.1, IP Address:10.64.3.7, IP Address:10.254.0.1
...
 
 
+ 确认 `Issuer` 字段的内容和 `ca-csr.json` 一致；
+ 确认 `Subject` 字段的内容和 `kubernetes-csr.json` 一致；
+ 确认 `X509v3 Subject Alternative Name` 字段的内容和 `kubernetes-csr.json` 一致；
+ 确认 `X509v3 Key Usage、Extended Key Usage` 字段的内容和 `ca-config.json` 中 `kubernetes` profile 一致；
```

##### 2、使用 `cfssl-certinfo` 命令校验证书

```shell
[root@server ~]#cfssl-certinfo -cert kubernetes.pem
...
{
  "subject": {
    "common_name": "kubernetes",
    "country": "CN",
    "organization": "k8s",
    "organizational_unit": "System",
    "locality": "BeiJing",
    "province": "BeiJing",
    "names": [
      "CN",
      "BeiJing",
      "BeiJing",
      "k8s",
      "System",
      "kubernetes"
    ]
  },
  "issuer": {
    "common_name": "Kubernetes",
    "country": "CN",
    "organization": "k8s",
    "organizational_unit": "System",
    "locality": "BeiJing",
    "province": "BeiJing",
    "names": [
      "CN",
      "BeiJing",
      "BeiJing",
      "k8s",
      "System",
      "Kubernetes"
    ]
  },
  "serial_number": "174360492872423263473151971632292895707129022309",
  "sans": [
    "kubernetes",
    "kubernetes.default",
    "kubernetes.default.svc",
    "kubernetes.default.svc.cluster",
    "kubernetes.default.svc.cluster.local",
    "127.0.0.1",
    "10.64.3.7",
    "10.64.3.8",
    "10.66.3.86",
    "10.254.0.1"
  ],
  "not_before": "2017-04-05T05:36:00Z",
  "not_after": "2018-04-05T05:36:00Z",
  "sigalg": "SHA256WithRSA",
...
```

##### 3、使用浏览器验证

导入证书

​    ca.pem改名为ca.crt。将正式导入浏览器。

构建https服务

```shell
[root@server ~]#cd /root/ssl_test
[root@server ~]#cat > http-server.js <<EOF
var https = require('https');
var fs = require('fs');
 
var options = {
    key: fs.readFileSync('./keys/app-key.pem'),
    cert: fs.readFileSync('./keys/app.pem')
};
 
https.createServer(options, function (req, res) {
    res.writeHead(200);
    res.end('hello world');
}).listen(8000);
EOF
 
[root@server ~]#yum install nodejs -y
[root@server ~]#npm install https -g
[root@server ~]#node http-server.js
```

修改hosts文件添加

```shell
172.16.160.28 www.test.com
```

在浏览器访问https://www.test.com:8000 发现网站显示为安全

##### 4、附加内容

数字证书中主题(Subject)中字段的含义

- 一般的数字证书产品的主题通常含有如下字段：

| **字段名**                   | **字段值**                                                   |
| ---------------------------- | ------------------------------------------------------------ |
| 公用名称 (Common Name)       | 简称：CN 字段，对于 SSL 证书，一般为网站域名；而对于代码签名证书则为申请单位名称；而对于客户端证书则为证书申请者的姓名； |
| 单位名称 (Organization Name) | 简称：O 字段，对于 SSL 证书，一般为网站域名；而对于代码签名证书则为申请单位名称；而对于客户端单位证书则为证书申请者所在单位名称； |

- 证书申请单位所在地

| **字段名**               | **字段值**                                   |
| ------------------------ | -------------------------------------------- |
| 所在城市 (Locality)      | 简称：L 字段                                 |
| 所在省份 (State/Provice) | 简称：S 字段                                 |
| 所在国家 (Country)       | 简称：C 字段，只能是国家字母缩写，如中国：CN |

- 其他一些字段

| **字段名**       | **字段值**                                                   |
| ---------------- | ------------------------------------------------------------ |
| 电子邮件 (Email) | 简称：E 字段                                                 |
| 多个姓名字段     | 简称：G 字段                                                 |
| 介绍             | Description 字段                                             |
| 电话号码：       | Phone 字段，格式要求 + 国家区号 城市区号 电话号码，如： +86 732 88888888 |
| 地址：           | STREET 字段                                                  |
| 邮政编码:        | PostalCode 字段                                              |
| 显示其他内容     | 简称:OU 字段                                                 |

例子：

```shell
[root@server ca]#cat ca-config.json 
{
    "signing": {
        "default": {
            "expiry": "9999h"
        },
        "profiles": {
            "www": {
                "expiry": "9999h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "server auth"
                ]
            },
            "client": {
                "expiry": "9999h",
                "usages": [
                    "signing",
                    "key encipherment",
                    "client auth"
                ]
            }
        }
    }
}
 
[root@server ca]#cat ca-csr.json 
{
  "CN": "registry.test.com",
  "hosts": [
    "127.0.0.1",
    "172.16.160.38",
    "registry.test.com"
  ],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "ST": "BeiJing",
      "L": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}
 
[root@server ca]#ll
总用量 8
-rw-r--r-- 1 root root 568 11月 14 15:59 ca-config.json
-rw-r--r-- 1 root root 289 11月 14 16:02 ca-csr.json
 
[root@dev ca]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca
2018/11/14 16:05:01 [INFO] generating a new CA key and certificate from CSR
2018/11/14 16:05:01 [INFO] generate received request
2018/11/14 16:05:01 [INFO] received CSR
2018/11/14 16:05:01 [INFO] generating key: rsa-2048
2018/11/14 16:05:01 [INFO] encoded CSR
2018/11/14 16:05:01 [INFO] signed certificate with serial number 303515642193399207794287652931621857332460556169
 
[root@server ca]#ll
总用量 20
-rw-r--r-- 1 root root  568 11月 14 15:59 ca-config.json
-rw-r--r-- 1 root root 1082 11月 14 16:05 ca.csr
-rw-r--r-- 1 root root  289 11月 14 16:02 ca-csr.json
-rw------- 1 root root 1679 11月 14 16:05 ca-key.pem
-rw-r--r-- 1 root root 1379 11月 14 16:05 ca.pem
 
 
[root@server ~]#openssl x509  -noout -text -in ca.pem
Certificate:
    Data:
        Version: 3 (0x2)
        Serial Number:
            35:2a:1c:b2:f6:1a:f3:82:38:50:05:8c:fb:65:ef:9e:89:74:8f:89
    Signature Algorithm: sha256WithRSAEncryption
        Issuer: C=CN, ST=BeiJing, L=BeiJing, O=k8s, OU=System, CN=harbor
        Validity
            Not Before: Nov 14 08:00:00 2018 GMT
            Not After : Nov 13 08:00:00 2023 GMT
        Subject: C=CN, ST=BeiJing, L=BeiJing, O=k8s, OU=System, CN=harbor
        Subject Public Key Info:
            Public Key Algorithm: rsaEncryption
                Public-Key: (2048 bit)
                Modulus:
                    00:b7:2e:6a:52:f4:d2:34:8b:5e:3f:95:5d:c8:b0:
                    85:9a:1b:ef:c5:0f:1b:94:b9:94:12:fe:fa:66:0d:
                    8c:67:b8:9e:82:30:fc:e1:42:94:6e:00:fb:c0:fd:
                    84:be:65:2c:e4:8f:f1:f1:93:e5:ae:8e:5b:74:7a:
                    d5:94:25:9c:01:76:f9:96:4e:02:b9:27:a2:44:e0:
                    da:b3:f3:09:82:5c:9f:26:a6:26:54:35:15:e6:a6:
                    7a:4b:14:99:07:9d:e3:c3:b8:bd:3f:b6:76:53:05:
                    82:02:bb:e2:61:21:23:5b:3b:23:4c:08:eb:a7:51:
                    00:fb:01:5f:b7:f8:b9:67:5b:a1:99:19:23:42:7a:
                    d2:22:0a:11:01:1d:75:34:9e:25:9c:c8:9f:31:d7:
                    f5:f3:98:14:b8:c4:07:f3:5a:a1:fa:96:bd:0f:b3:
                    dc:13:5b:8e:03:e8:66:3b:b5:bd:8d:08:ee:61:c2:
                    4f:78:dc:9a:ee:37:f8:87:6b:5f:e3:87:ae:91:b0:
                    8c:c9:40:51:44:cb:57:47:23:f1:2d:34:af:0f:5f:
                    42:89:14:ac:de:73:d4:32:54:c2:de:99:38:96:d4:
                    b8:de:f3:df:5c:a5:55:54:8f:a1:b7:fa:42:8b:d9:
                    fe:2d:14:1f:d5:62:d9:c7:c1:4d:55:41:3b:a9:d3:
                    0d:2d
                Exponent: 65537 (0x10001)
        X509v3 extensions:
            X509v3 Key Usage: critical
                Certificate Sign, CRL Sign
            X509v3 Basic Constraints: critical
                CA:TRUE, pathlen:2
            X509v3 Subject Key Identifier: 
                15:1F:81:A2:AC:41:18:DA:DD:19:36:03:61:18:7B:EF:3D:94:10:AE
            X509v3 Authority Key Identifier: 
                keyid:15:1F:81:A2:AC:41:18:DA:DD:19:36:03:61:18:7B:EF:3D:94:10:AE
 
            X509v3 Subject Alternative Name: 
                IP Address:127.0.0.1, IP Address:172.16.160.38
    Signature Algorithm: sha256WithRSAEncryption
         62:41:3c:40:6d:91:29:d2:0b:6d:ce:08:a1:e4:47:64:0a:66:
         0e:c0:55:eb:c4:6b:30:6d:79:51:b4:97:8c:02:1e:15:ba:0f:
         84:ce:2a:3c:c7:86:29:3c:1f:55:35:a1:da:df:70:5d:58:93:
         45:24:c4:20:4d:c1:c7:bb:83:8d:52:0c:7d:43:e2:7c:5b:00:
         5d:57:5a:b5:bf:d0:56:5a:57:32:ca:fc:29:59:23:ab:5e:1e:
         0e:9b:f9:f6:8d:e8:e4:c6:cb:e6:fe:9f:e3:cd:55:2e:7b:35:
         1e:bc:80:0f:ba:d8:66:ae:43:19:bf:d1:bb:81:17:d6:4a:3b:
         01:ba:d4:28:da:3f:19:63:82:72:6f:df:7a:b4:bc:d4:cf:a9:
         b1:fc:a6:c7:c1:5d:9b:09:2e:72:2a:d4:18:ed:f4:3d:97:1e:
         e6:43:81:5c:eb:40:2c:f9:aa:6f:90:16:70:46:77:52:09:64:
         43:83:00:0c:44:59:de:17:65:7b:7e:3d:51:df:54:6e:bb:80:
         cb:22:13:e2:20:80:91:f8:3f:5e:83:70:32:68:ad:ad:7e:4a:
         15:32:45:a7:a5:c4:ed:1c:d4:e4:cc:38:ac:8a:9d:d1:bb:4e:
         1c:21:17:56:a2:a0:f9:39:f3:73:e4:96:00:ac:98:93:f3:80:
         96:9d:b5:97
[root@dev ca]#
```

如果出现

```shell
[root@server ~]#docker login registry.test.com
Username (admin): admin
Password: 
Error response from daemon: Get https://registry.mayocase.com/v1/users/: x509: certificate signed by unknown authority
```

检查下目录/etc/docker/certs.d/registry.test.com下是否有ca.crt文件，可能需要重启docker

```shell
[root@server ~]#cp ca.pem /etc/docker/certs.d/registry.test.com/ca.crt
[root@server ~]#systemctl restart docker
```

修改harbor证书后操作：

```shell
[root@server ~]#cd /data/harbor    #一定要在此目录下运行以下命令。
[root@server ~]#ll
总用量 878344
drwxr-xr-x 4 root root        35 7月  31 2017 common
-rw-r--r-- 1 root root      1988 7月  31 2017 docker-compose.notary.yml
-rw-r--r-- 1 root root      3155 7月  31 2017 docker-compose.yml
-rw-r--r-- 1 root root      4304 7月  31 2017 harbor_1_1_0_template
-rw-r--r-- 1 root root      4178 7月  31 2017 harbor.cfg
-rw-r--r-- 1 root root      1082 7月  31 2017 harbor.csr
-rw-r--r-- 1 root root       288 7月  31 2017 harbor-csr.json
-rw-r--r-- 1 root root 448963966 7月  31 2017 harbor.v1.1.1.tar.gz
-rw-r--r-- 1 root root 450041094 7月  31 2017 harbor.v1.1.2.tar.gz
-rwxr-xr-x 1 root root      5169 7月  31 2017 install.sh
-rw-r--r-- 1 root root    337600 7月  31 2017 LICENSE
-rw-r--r-- 1 root root       472 7月  31 2017 NOTICE
-rwxr-xr-x 1 root root     16522 7月  31 2017 prepare
-rwxr-xr-x 1 root root      4550 7月  31 2017 upgrade 
# 停止 harbor
[root@server harbor]# docker-compose down -v        #多运行几次直到所有docker都删除
# 修改配置
[root@server harbor]# vim harbor.cfg
# 更修改的配置更新到 docker-compose.yml 文件
[root@server harbor]# ./prepare
# 启动 harbor
[root@server harbor]#  docker-compose up -d
```

### 8、特例： https 为什么慢，把nginx 跑到 qat 卡上

Intel QAT 助力 Nginx 压缩处理

#### 1、什么是Intel® QAT？

Intel® QuickAssist Technology是Intel®公司提供的一种高性能数据安全和压缩的加速方案。该方案利用QAT芯片分担对称/非对称加密计算,DEFLATE无损压缩等大计算量的任务，来降低CPU使用率并提高整体平台性能。该方案可以主板芯片，独立的PCI-E加速卡或者SOC三种方式部署。

QAT支持硬件加速Deflate无损压缩算法，在处理海量数据时，QAT在不增加CPU开销的前提下，通过压缩来减少需要传输和存盘的数据量，从而减少了网络带宽和磁盘读写的开销，最终提高了整体的系统性能。 例如，在Web Serer上使用QAT硬件加速压缩处理，可将CPU从繁重的压缩计算中解放出来，以处理更多的连接请求。

#### 2、什么是Nginx Web Server

Nginx（发音同engine x）是一款使用异步框架的高性能Web服务器，相较于Apache、lighttpd等其他Web Server，Nginx具有占有内存少，稳定性高等优势。根据Netcraft 2018年一月的Web Server市场调查报告， Nginx的装机率达25.39%，位列Web Server市场第三，并在持续增长中[1]。

Nginx中的GZIP模块实现了对HTTP压缩的支持，该模块通过调用Zlib库实现对网页内容进行Deflate压缩。由于使用软件实现无损压缩，需要消耗大量CPU运算时间进行压缩运算。

然而，在大并发流量的网站接入层的Nginx需要处理相当多的业务，包括https连接建立，安防攻击，流量镜像，链路追踪等等。使得CPU进行HTTP压缩处理成为Web Server最主要的CPU开销，进而限制了网站支持最大并发连接数。根据客户提供的接入层流量模型分析来看， GZIP 单个模块 CPU 消耗占比达到 15%-20% 左右，且占比呈上升趋势。所以，若能使用加速Nginx的网页压缩处理，可以极大的提高网站性能。

![img](assets/1-1.jpg)

#### 3、Zlib-SHIM API

Zlib作为广泛部署的软件压缩库，提供Deflate压缩的软件实现，被包括Nginx在内的广大应用程序所采用。Intel® QuickAssist Technology提供了与Zlib类似接口的Zlib-SHIM 软件库来适配上层应用，减少了应用迁移的开发量。该库提供了与Zlib一致的Deflate API，只需对源代码做少量修改，并将原有应用与Zlib-SHIM编译链接，就能使用QuickAssit提供的硬件加速功能。

Zlib-SHIM库实现了DeflateInit，DeflateInit2，Deflate，DeflateEnd等常用API并支持Stateful和Stateless压缩，可以替代Zlib的绝大部分功能。

Zlib-SHIM提供了Deflate API同步模式接口（调用程序阻塞在Deflate API上，直到压缩任务完成），而其内部实现调用了异步模式API，即在CPU上运行的QAT驱动程序向QAT协处理器提交了一个数据压缩请求后即返回，期间使用Polling 接口定期检查压缩请求是否完成，等到QAT硬件完成压缩处理后通过回调函数通知CPU端的应用程序进行下一步操作。这样的设计, 在不影响上层应用程序原有设计的前提下，实现了高并发场景中CPU和QAT的协同工作：CPU专注于网络链接处理而QAT处理复杂的压缩计算, 各司其职，最终提高了系统整体性能。

![img](assets/2-1552557277602.png)Zlib-SHIM 层次图

#### 4、Zlib-SHIM工作原理

采用这种异步模式API实现对外的同步接口，在实现上有三种方法：Direct Polling，Indirect Polling Spinning和Indirect Polling Semaphore模式。

使用Direct Polling模式时，Deflate调用者会在当前线程直接调用Polling接口，若压缩结果还没有返回则休眠一段时间后再检查，直到压缩成功后Deflate 调用才返回。Direct Polling模式下CPU开销小，但是单个Request从发出到返回结果延迟较长，只有在多进程多线程高并发模式下才能充分发挥QAT的压缩性能。

![img](assets/3.png)Direct polling 模式流程图

Indirect Polling模式，是通过创建一个轮询线程定期调用Polling接口来检查压缩请求在QAT 协处理器中的执行状态，轮询线程一旦发现有请求执行完毕就通过回调函数（Callback Function）通知CPU端程序进行后续处理。

![img](assets/4-1.png)

Indirect pooling模式时序图

根据回调通知方式的不同，Indirect Polling模式又可细分为Spinning模式和Semaphore模式：

Spinning模式中，Deflate函数调用线程定期轮询与回调函数共享的任务完成标志，若尚未完成则主动休眠，若已完成则进行后续处理。

Semaphore模式中，Deflate调用线程通过互斥锁来隔离与轮询线程共享的任务完成标志的访问操作，若任务尚未完成则Deflate调用线程休眠，一旦任务完成，轮询线程中的回调函数会通过信号量唤醒调用线程进行后续处理。

采用Indirect Polling模式无论Deflate调用数目多少都需要启动轮询线程，在压缩请求数不大的情况下增加了CPU的Polling开销，但是当压缩任务作为CPU的主要任务时可以减少不必要的Polling调用，提高CPU的使用率。

Nginx为了实现高性能的高并发处理能采用了单进程单线程异步工作模式，如果使用Indirect Polling模式，就需要在每个Nginx Worker进程中创建一个轮询线程 (Polling Thread), 从而增加了线程间切换的开销和共享数据的互斥的操作, 所以在Nginx和Zlib-SHIM集成中，我们使用了Direct Polling Mode。

#### 5、USDM优化

USDM是QAT为了优化内存使用效率而提供的用户态内存管理工具。由于QAT和CPU之前需要频繁高速的交换数据，使用传统的Memory Copy方式不仅效率低而且消耗CPU资源，所以QAT支持DMA方式进行数据传输，CPU只需分配好拥有物理连续内存的输入地址和输出地址，QAT会自动完成的从该地址的输入读取或输出写回的操作。QAT Driver中的USDM模块，利用了Linux 内核提供的Huge-Page特性来获得物理地址连续内存并使用SLAB算法进行内存管理。

对于每一个新分配的Huge-Page，USDM会对应地在Devfs中新建一个临时文件，并通过mmap将临时文件描述符与新申请到的Huge-Page关联上，当USDM发现该Huge-Page上所有内存块均已释放，并不需将其留作缓存时，就关闭该临时文件以释放Huge-Page。当Zlib-SHIM运行过程中需要使用连续的内存时，就使用USDM Alloc接口从内存池中申请连续物理地址的内存, 并在发送压缩请求时将申请到的连续内存地址作为参数传递给QAT。

![img](assets/5-1.jpg)USDM DMA传输

#### 6、测试结果

基于以上设计的Zlib-SHIM可以很方便的替换原有Zlib库，使得调用者可以方便的利用QAT进行压缩加速。 在实际应用中， 客户就是将Zlib-SHIM与基于Nginx定制的Web Server进行集成，在接入层的性能优化上取得了理想的效果。

客户的Web Server运行在Intel® Xeon® CPU上（CPU型号：Intel® Xeon® CPU E5-2650 v2 @ 2.60GHz 32核 内核：2.6.32 Zlib版本：zlib-1.2.8 QAT驱动版本：intel-qatOOT40052 ），在相同网络流量条件下，未开启QAT加速的CPU平均使用率为48%左右，而开启QAT加速后CPU平均使用率为41%左右。

![img](assets/6-1.jpg)CPU使用率对比[2]

相同条件下，开启QAT加速后系统load平均值为12.09，关闭QAT加速时系统load平均值为14.22，如下图所示：
![img](assets/7-1.jpg)系统load对比[2]

综合以上数据，Web Server在QPS 10K的压力下，使用QAT加速后可以节省CPU 15%左右，且Gzip基本上完全卸载、随着其占比变高，优化效果将越好。

#### 7、总结

拥有和Zlib相同API接口的Zlib-SHIM可以很方便的与上层应用集成，利用QAT的硬件加速性能。此外，为了最大限度的发挥QAT的新能，Intel还提供了使用专有API的QATzip软件库，相应的Nginx module也在开发中，相信不久的将来集成QATzip的Web Server能够提供更好的性能。

> 性能测试中使用的软件和工作负荷可能仅在英特尔微处理器上进行了性能优化。诸如SYSmark和MobileMark等测试均系基于特定计算机系统、硬件、软件、操作系统及功能。上述任何要素的变动都有可能导致测试结果的变化。请参考其他信息及性能测试（包括结合其他产品使用时的运行性能）以对目标产品进行全面评估。

## 四、Tomcat 运维实战

### 1、JVM 虚拟机常识

   **两个常识问题**

  作为了解JVM 虚拟机的开始。我们很有必要弄明白以下两个问题。

#### **1、什么是JAVA虚拟机**

```
所谓虚拟机，就是一台虚拟的计算机。他是一款软件，用来执行一系列虚拟计算机指令。大体上，虚拟机可以分为系统虚拟机和程序虚拟机。大名鼎鼎的VisualBox、VMware就属于系统虚拟机。他们完全是对物理计算机的仿真。提供了一个可以运行完整操作系统的软件平台。
程序虚拟机的典型代表就是Java虚拟机，它专门为执行单个计算机程序而设计，在Java虚拟机中执行的指令我们称为Java字节码指令。无论是系统虚拟机还是程序虚拟机，在上面运行的软件都呗限制于虚拟机提供的资源中。
```

#### **2、JAVA 如何做到跨平台**

```
同一个JAVA程序(JAVA字节码的集合)，通过JAVA虚拟机(JVM)运行于各大主流操作系统平台
比如Windows、CentOS、Ubuntu等。程序以虚拟机为中介，来实现跨平台。
```

![15183384816869](assets/15183384816869.jpg)

#### 3、虚拟机基本结构

我们要对JVM虚拟机的结构有一个感性的认知。毕竟我们不是编程人员，认知程度达不到那么深入。

![15183438448846](assets/15183438448846.jpg)

```
1、类加载子系统
负责从文件系统或者网络中加载Class信息，加载的类信息存放于一块称为方法区的内存空间。除了类信息外，方法区中可能还会存放运行时常量池信息，包括字符串字面量和数字量。

2、Java堆
在虚拟机启动的时候建立，它是Java程序最主要的内存工作区域。几乎所有的Java对象实例都放Java堆中。堆空间是所有线程共享的，这是一块与Java应用密切相关的内存区间。

3、Java的NIO库(直接内存)
允许Java程序使用直接内存。直接内存是在Java堆外的、直接向系统申请的内存区间。通常访问直接内存的速度会优于Java堆。因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。由于直接内存在Java堆外，因此它的大小不会受限于Xmx指定的最大堆大小。但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。

4、垃圾回收系统
垃圾回收系统是Java虚拟机的重要组成部分，垃圾回收器可以对方法区、Java堆和直接内存进行回收。

5、Java栈
每一个Java虚拟机线程都有一个私有的Java栈。一个线程的Java栈在线程创建的时候被创建。Java保存着帧信息，Java栈中保存着局部变量、方法参数，同时和Java方法的调用、返回密切相关。

6、本地方法
与Java栈非常类似，最大的不同在于Java栈用于Java方法的调用，而本地方法栈用于本地方法调用。作为Java虚拟机的重要扩展，Java虚拟机运行Java程序直接调用本地方法（通常使用C编写）。

7、PC寄存器
每个线程私有的空间，Java虚拟机会为每一个Java线程创建PC寄存器。在任意时刻，一个Java线程总是在执行一个方法，这个正在被执行的方法称为当前方法。如果当前方法不是本地方法，PC寄存器就会指向当前正在被执行的指令。如果当前方法是本地方法，那么PC寄存的值就是undefined.

8、执行引擎
是Java虚拟机最核心组件之一，它负责执行虚拟机的字节码。现代虚拟机为了提高执行效率。会使用即时编译技术将方法编译成机器码后再执行。
```



#### 4、虚拟机堆内存结构

![15188561840733](assets/15188561840733.jpg)

JVM中堆空间可以分成三个大区，年轻代、老年代、永久代(方法区)。

##### 1、年轻代

```
所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。年轻代分为三个区域：EDEN、Survivor0(简称S0,也通常称为from区)、Survivor1(简称S1，也通常称为to区)。其中S0与S1的大小是相同等大的，三者所占年轻代的比例大致为8:1:1，S0与S1就像"孪生兄弟"一样，我们大家不必去纠结此比例(可以通过修改JVM某些动态参数来调整)的大小.只需谨记三点就好：
1.S0与S1相同大小。
2.EDEN区远比S(S0+S1)区大,EDEN占了整个年轻代的大致70%至80%左右。 
3.年轻代分为2个区(EDEN区、Survivor区)、3个板块(EDEN、S0、S1)。
```

##### 2、老年代

```
在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为老年代中存放的都是一些生命周期较长的对象。
那一个对象到底要经过多少次垃圾回收才能从年轻代进入老年代呢?
我们通常认为在新生代中的对象，每经历过一次GC,如果它没有被回收，它的年龄就会被加1， 虚拟机提供了一个参数来可控制新生代对象的最大年龄:MaxTenuringThreshold。默认情况下，这个参数是15。 也就是说，在新生代的对象最多经历15次GC，就可以进入老年代。
假如存在一种这样的情况，一个新生代对象，占用新生代空间特别大。在GC时若不回收，新生代空间将不足。但是若要回收，程序还没有使用完。此时就不会依据这个对象的 MaxTenuringThreshold 参数。而是直接晋升到老年代。所以说
MaxTenuringThreshold 参数是晋升老年代的充分非必要条件。
```

##### 3、永久代(方法区)

```
也通常被叫做方法区。是一块所有线程共享的内存区域。用于保存系统的类信息，比如类的字段、方法、常量池。
```

#### 5、常用虚拟机参数

JVM 虚拟机提供了三种类型参数

##### 1、标准参数

```
标准参数中包括功能和输出的参数都是很稳定的，很可能在将来的JVM版本中不会改变。你可以用 java 命令（或者是用 java -help）检索出所有标准参数。
```

##### 2、X  类型参数

```
非标准化的参数，在将来的版本中可能会改变。所有的这类参数都以 -X 开始，并且可以用 java -X 来检索。
注意，不能保证所有参数都可以被检索出来，其中就没有 -Xcomp 。
```

##### 3、XX  类型参数

```
非标准化的参数（到目前为止最多的），它们同样不是标准的，甚至很长一段时间内不被列出来。然而，在实际情况中 X 参数和 XX 参数并没有什么不同。X 参数的功能是十分稳定的，然而很多 XX 参数仍在实验当中（主要是 JVM 的开发者用于 debugging 和调优 JVM 自身的实现）。

用一句话来说明 XX 参数的语法。所有的 XX 参数都以"-XX:"开始，但是随后的语法不同，取决于参数的类型：
1）对于布尔类型的参数，我们有"+"或"-"，然后才设置 JVM 选项的实际名称。
   例如，-XX:+ 用于激活选项，而 -XX:- 用于注销选项。
   Example:
   开启GC日志的参数: -XX:+PrintGC
2) 对于需要非布尔值的参数，如 string 或者 integer，我们先写参数的名称，后面加上"="，最后赋值。
   例如: -XX:MaxPermSize=2048m
```

#### 6、常用的JVM参数

以上介绍完了JVM的三类参数类型，接下来我们主要聊聊常用的JVM参数。

##### 1、跟踪JAVA虚拟机的垃圾回收

JVM 的 GC的日志是以替换的方式(>)写入的，而不是追加(>>)，如果下次写入到同一个文件中的话，以前的GC内容会被清空。这导致我们重启了JAVA服务后，历史的GC日志将会丢失。

```
-XX:+PrintGC 
-XX:+PrintGCDetails
-XX:+PrintGCTimeStamps
-Xloggc:filename
```

Example

此种写法，会导致JAVA服务重启后，GC日志丢失

```shell
-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:/data0/logs/gc.log
```

在这里GC 日志支持 %p 和 %t 两个参数:

- %p 将会被替换为对应的进程PID
- %t 将会被替代为时间字符串，格式为: YYYY-MM-DD_HH-MM-SS

此种写法，不管怎么重启，GC历史日志将不会丢失

```shell
-XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/data0/logs/gc-%t.log"
```

##### 2、配置JAVA虚拟机的堆空间

```
-Xms:初始堆大小
-Xmx:最大堆大小
实际生产环境中， 我们通常将初始化堆(-Xms) 和 最大堆(-Xmx) 设置为一样大。以避免程序频繁的申请堆空间。

-Xmn: 设置年轻代大小
-XX:NewRatio=老年代/新生代 //设置年轻代和年老代的比值
-XX:SurvivorRatio=eden/from=eden/to //年轻代中Eden区与两个Survivor区的比值
```

Example：

```shell
-Xmn1m -XX:SurvivorRatio=2
// 这里的eden 于from(to) 的比值为2:1 ，因此在新生代为1m的区间里， eden 区为 512KB, from 和 to 分别为 256KB. 而新生代总大小为 512KB + 256KB + 256KB = 1MB
```

```shell
-Xms20M -Xmx20M -XX:NewRatio=2
// 这里 老年代和新生代的比值为2:1 ， 因此在堆大小为20MB的区间里， 新生代大小为: 20MB * 1/3 = 6MB左右
// 老年代为 13MB 左右。
```

##### 3、配置JAVA虚拟机的永久区(方法区)

```
-XX:PermSize=n    //设置初始化值
-XX:MaxPermSize=n //设置持久代大小
```

##### 4、配置JAVA虚拟机的栈

```
-Xss128k 设置每个线程的堆栈大小
```

```
一个常用的JAVA服务启动参数:
      nohup /usr/java/$SERVER/bin/java
      -Dspring.cloud.config.profile=$ENV  -jar /app/$SERVER/$SERVER.jar --log.path=/log/$SERVER/all/ --log.level=info  2>&1  >/dev/null &
      
 nohup /usr/java/$SERVER/bin/java -Xmx2048m -Xms2048m -Xmn512M -XX:MetaspaceSize=2048M -XX:MaxMetaspaceSize=2048M  -Deureka.client.serviceUrl.defaultZone=$REGISTER_ADDR_1/,$REGISTER_ADDR_2/ -Dspring.cloud.config.profile=$ENV  -jar /app/$SERVER/$SERVER.jar --log.path=/log/$SERVER/all/ --log.level=info  2>&1  >/dev/null &
-Xmx:最大堆大小
-Xms:初始堆大小
-Xmn: 设置年轻代大小
-XX:MetaspaceSize  初始空间大小，达到该值就会触发垃圾收集进行类型卸载（metadata元数据）
-XX:MaxMetaspaceSize  最大空间，默认是没有限制的
```



#### 7、常用垃圾回收算法

##### 1、引用计数法

```
引用计数法是最经典的一种垃圾回收算法。其实现很简单，对于一个A对象，只要有任何一个对象引用了A，则A的引用计算器就加1，当引用失效时，引用计数器减1.只要A的引用计数器值为0，则对象A就不可能再被使用。
       
虽然其思想实现都很简单（为每一个对象配备一个整型的计数器），但是该算法却存在两个严重的问题：
1）无法处理循环引用的问题，因此在Java的垃圾回收器中，没有使用该算法。
2）引用计数器要求在每次因引用产生和消除的时候，需要伴随一个加法操作和减法操作，对系统性能会有一定的影响。

一个简单的循环引用问题描述:
对象A和对象B，对象A中含有对象B的引用，对象B中含有对象A的引用。此时对象A和B的引用计数器都不为0，但是系统中却不存在任何第三个对象引用A和B。也就是说A和B是应该被回收的垃圾对象，但由于垃圾对象间的互相引用使得垃圾回收器无法识别，从而引起内存泄漏（由于某种原因不能回收垃圾对象占用的内存空间）。

如下图：不可达对象出现循环引用，它的引用计数器不为0
```

![15191742429671](assets/15191742429671.jpg)

```
注意：由于引用计数器算法存在循环引用以及性能的问题，java虚拟机并未使用此算法作为垃圾回收算法。
【可达对象】通过根对象的进行引用搜索，最终可以到达的对象。
【不可达对象】通过根对象进行引用搜索，最终没有被引用到的对象。
```

#####  2、标记清除法

```
标记-清除算法是现代垃圾回收算法的思想基础。标记-清除算法将垃圾回收分为两个阶段：标记阶段和清除阶段。一种可行的实现是，在标记阶段，首先通过根节点，标记所有从根节点开始的可达对象。因此，未被标记的对象就是未被引用的垃圾对象。然后，在清除阶段，清除所有未被标记的对象。
缺陷:
①.效率问题：标记清除过程效率都不高。 
②.空间问题：标记清除之后会产生大量的不连续的内存碎片
```

![15191745225772](assets/15191745225772.jpg)       

##### 3、 标记压缩法

```
标记-压缩算法适合用于存活对象较多的场合，如老年代。它在标记-清除算法的基础上做了一些优化。和标记-清除算法一样，标记-压缩算法也首先需要从根节点开始，对所有可达对象做一次标记。但之后，它并不简单的清理未标记的对象，而是将所有的存活对象压缩到内存的一端。之后，清理边界外所有的空间。
标记-压缩算法的最终效果等同于标记-清除算法执行完成之后，再进行一次内存碎片的整理。基于此，这种算法也解决了内存碎片问题。
```

![15191745826108](assets/15191745826108.jpg)     

#####  4、复制算法

```
与标记-清除算法相比，复制算法是一种相对高效的回收方法。但不适用于存活对象较多的场合，如老年代。它将原有的内存空间分为两块，每次只使用其中一块，在垃圾回收时，将正在使用的内存中的存活对象复制到未使用的内存块中，之后，清除正在使用的内存块中的所有对象，交换两个内存的角色，完成垃圾回收
缺陷： 
空间浪费，浪费了50%的内存空间。
```

![15191755567605](assets/15191755567605.jpg)

```
我们前文介绍的JVM 的新生代，分为Eden 及 S0 和 S1 ， 其中S0 和 S1 是两个容量相等的区域。其实在JVM 的垃圾回收中, S0 和 S1 就使用了复制算法作为它们的垃圾回收算法。
```

```shell
# 使用JDK 自带的jmap 工具，打印一个JVM 虚拟机的堆信息. 
# 其中 187136 为JVM 的PID

[root@java00 ~]# jmap -heap 187136
Attaching to process ID 187136, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 24.80-b11

using parallel threads in the new generation.
using thread-local object allocation.
Concurrent Mark-Sweep GC

Heap Configuration:
   MinHeapFreeRatio = 40
   MaxHeapFreeRatio = 70
   MaxHeapSize      = 4294967296 (4096.0MB)
   NewSize          = 1431633920 (1365.3125MB)
   MaxNewSize       = 1431633920 (1365.3125MB)
   OldSize          = 2863267840 (2730.625MB)
   NewRatio         = 2
   SurvivorRatio    = 8
   PermSize         = 1073741824 (1024.0MB)
   MaxPermSize      = 2147483648 (2048.0MB)
   G1HeapRegionSize = 0 (0.0MB)

Heap Usage:
New Generation (Eden + 1 Survivor Space):
   capacity = 1288503296 (1228.8125MB)
   used     = 570069688 (543.6608200073242MB)
   free     = 718433608 (685.1516799926758MB)
   44.242780734027704% used
Eden Space:
   capacity = 1145372672 (1092.3125MB)
   used     = 561190696 (535.1931533813477MB)
   free     = 584181976 (557.1193466186523MB)
   48.99634064256773% used
From Space:
   capacity = 143130624 (136.5MB)
   used     = 8878992 (8.467666625976562MB)
   free     = 134251632 (128.03233337402344MB)
   6.2034187736092035% used
To Space:
   capacity = 143130624 (136.5MB)
   used     = 0 (0.0MB)
   free     = 143130624 (136.5MB)
   0.0% used
concurrent mark-sweep generation:
   capacity = 2863333376 (2730.6875MB)
   used     = 46529976 (44.37444305419922MB)
   free     = 2816803400 (2686.313056945801MB)
   1.6250282412102892% used
Perm Generation:
   capacity = 1073741824 (1024.0MB)
   used     = 47940496 (45.71961975097656MB)
   free     = 1025801328 (978.2803802490234MB)
   4.464806616306305% used

20796 interned Strings occupying 2411488 bytes.
```

```
# 截取部分信息如下: From(S0) 和 To(S1) 区间采用了复制算法，不论什么时候执行jmap 区间，都会发现
# 有一个区间的使用用于都是 0.0% used
From Space:
   capacity = 143130624 (136.5MB)
   used     = 8878992 (8.467666625976562MB)
   free     = 134251632 (128.03233337402344MB)
   6.2034187736092035% used
To Space:
   capacity = 143130624 (136.5MB)
   used     = 0 (0.0MB)
   free     = 143130624 (136.5MB)
   0.0% used
```

##### 5、分代算法

```
    前文介绍了复制、标记清除、标记压缩等垃圾回收算法。在所有的算法中，并没有一种算法可以完全取代其他算法，它们都具有自己独特的优势和特点。因此，根据垃圾回收对象的特性，使用合适的算法回收，才是明智的选择。分代算法就是基于这种思想，它将内存区间根据对象的特点分成几块，根据每块内存区间的特点，使用不同的回收算法，以提高垃圾回收的效率。
    一般来说，Java虚拟机会将所有的新建对象都放到称为新生代的区域中，新生代的特点是对象朝生夕灭，大约90%的新建对象会被回收，因此新生代比较适合使用复制算法。当一个对象经过几次回收后依然存活，对象就会被放到称为老年代的内存空间。在老年代中，几乎所有对象都经过几次垃圾回收后依然得以存活的。因此可以认为对象在一段时期内，甚至在应用程序的整个生命周期中，将是常驻内存的。
    在极端情况下，老年代对象的存活率可以达到100%。如果依然使用复制算法回收老年代，将需要复制大量对象。再加上老年代的回收性价比也要低于新生代，因此这种做法是不可取的。根据分代的思想，可以对老年代的回收使用与新生代不通的标记压缩或者标记清除算法，以提高垃圾回收效率。
```

![15191765022657](assets/15191765022657.jpg)



### 2、JVM 运维实用排障工具

#### 1、jps

```
用来查看Java进程的具体状态, 包括进程ID，进程启动的路径及启动参数等等，与unix上的ps类似，只不过jps是用来显示java进程，可以把jps理解为ps的一个子集。
常用参数如下:
-q：忽略输出的类名、Jar名以及传递给main方法的参数，只输出pid
-m：输出传递给main方法的参数，如果是内嵌的JVM则输出为null
-l：输出完全的包名，应用主类名，jar的完全路径名
-v：输出传给jvm的参数

注意: 使用jps 时的运行账户要和JVM 虚拟机启动的账户一致。若启动JVM虚拟机是运行的账户为www，那使用jps指令时，也要使用www 用户去指定。 sudo -u www jps
```

Example

```shell
// 查看已经运行的JVM 进程的实际启动参数
[root@mouse03 bin]# jps  -v
38372 Jps -Dapplication.home=/usr/local/jdk -Xms8m
38360 Bootstrap -Djava.util.logging.config.file=/data0/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms4096m -Xmx4096m -XX:PermSize=1024m -XX:MaxPermSize=2048m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dignore.endorsed.dirs= -Dcatalina.base=/data0/tomcat -Dcatalina.home=/data0/tomcat -Djava.io.tmpdir=/data0/tomcat/temp
```

#### 2、jstack

```
jstack用于打印出给定的java进程ID或core file或远程调试服务的Java堆栈信息。如果现在运行的java程序呈现hung的状态，jstack是非常有用的。此信息通常在运维的过程中被保存起来(保存故障现场)，以供RD们去分析故障。
常用参数如下:
jstack <pid>
jstack [-l] <pid> //长列表. 打印关于锁的附加信息
jstack [-F] <pid> //当’jstack [-l] pid’没有响应的时候强制打印栈信息
```

Example

```shell
// 打印JVM 的堆栈信息，以供问题排查
[root@mouse03 ~]# jstack -F 38360 > /tmp/jstack.log
```

#### 3、jinfo

```
可以查看或修改运行时的JVM进程的参数。
常用参数:
jinfo [option] pid
    
where <option> is one of:
    -flag <name>         to print the value of the named VM flag
    -flag [+|-]<name>    to enable or disable the named VM flag
    -flag <name>=<value> to set the named VM flag to the given value
    -flags               to print VM flags
```

Example

```shell
// 根据 PID 查看目前分配的最大堆栈
[root@mouse03 ~]# jinfo -flag MaxHeapSize 38360
-XX:MaxHeapSize=4294967296
// 动态更改 JVM 的最大堆栈值
[root@mouse03 ~]# jinfo -flag MaxHeapSize=4294967296  38360
Exception in thread "main" com.sun.tools.attach.AttachOperationFailedException: flag 'MaxHeapSize' cannot be changed

	at sun.tools.attach.LinuxVirtualMachine.execute(LinuxVirtualMachine.java:229)
	at sun.tools.attach.HotSpotVirtualMachine.executeCommand(HotSpotVirtualMachine.java:261)
	at sun.tools.attach.HotSpotVirtualMachine.setFlag(HotSpotVirtualMachine.java:234)
	at sun.tools.jinfo.JInfo.flag(JInfo.java:134)
	at sun.tools.jinfo.JInfo.main(JInfo.java:81)

// jinfo 并不能动态的改变所有的JVM 参数。 那到底有哪些参数能够被动态的改变呢?
// java -XX:+PrintFlagsFinal -version 答应JVM 的所有参数
// java -XX:+PrintFlagsFinal -version | grep manageable

[root@mouse03 ~]# java -XX:+PrintFlagsFinal -version | grep manageable
     intx CMSAbortablePrecleanWaitMillis            = 100                                 {manageable}
     intx CMSTriggerInterval                        = -1                                  {manageable}
     intx CMSWaitDuration                           = 2000                                {manageable}
     bool HeapDumpAfterFullGC                       = false                               {manageable}
     bool HeapDumpBeforeFullGC                      = false                               {manageable}
     bool HeapDumpOnOutOfMemoryError                = false                               {manageable}
    ccstr HeapDumpPath                              =                                     {manageable}
    uintx MaxHeapFreeRatio                          = 70                                  {manageable}
    uintx MinHeapFreeRatio                          = 40                                  {manageable}
     bool PrintClassHistogram                       = false                               {manageable}
     bool PrintClassHistogramAfterFullGC            = false                               {manageable}
     bool PrintClassHistogramBeforeFullGC           = false                               {manageable}
     bool PrintConcurrentLocks                      = false                               {manageable}
     bool PrintGC                                   = false                               {manageable}
     bool PrintGCDateStamps                         = false                               {manageable}
     bool PrintGCDetails                            = false                               {manageable}
     bool PrintGCID                                 = false                               {manageable}
     bool PrintGCTimeStamps                         = false                               {manageable}
     
// 也只有以上这些值才能够动态的被改变
[root@mouse03 ~]# jinfo -flag CMSWaitDuration=1900  38360
# 查看， jinfo -flags 查看 JVM 的 flags 
[root@mouse03 ~]# jinfo -flags 38360
Attaching to process ID 38360, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 25.91-b14
Non-default VM flags: -XX:CICompilerCount=2 -XX:CMSWaitDuration=1900 -XX:InitialHeapSize=4294967296 -XX:MaxHeapSize=4294967296 -XX:MaxNewSize=1431633920 -XX:MinHeapDeltaBytes=196608 -XX:NewSize=1431633920 -XX:OldSize=2863333376 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps
Command line:  -Djava.util.logging.config.file=/data0/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Xms4096m -Xmx4096m -XX:PermSize=1024m -XX:MaxPermSize=2048m -Djdk.tls.ephemeralDHKeySize=2048 -Djava.protocol.handler.pkgs=org.apache.catalina.webresources -Dignore.endorsed.dirs= -Dcatalina.base=/data0/tomcat -Dcatalina.home=/data0/tomcat -Djava.io.tmpdir=/data0/tomcat/temp
```

#### 4、jstat

```shell
// 监控JVM 的状态，常用指令:
# jstat -gc 113059 1000 10 // 打印PID 为 113059 JVM 状态，一共打印10次，每次间隔时间为1s(1000ms)
// 注 jstat 的用法超级强大， 我们这里只是列举出列其中一个简单的应用。
```

Example

```shell
# jstat -gc 113059 1000 10
 S0C    S1C    S0U    S1U      EC       EU        OC         OU       PC     PU    YGC     YGCT    FGC    FGCT     GCT
195904.0 195904.0  0.0   21610.3 1567680.0 1516721.9 8526272.0  3557507.8  1048576.0 163148.4   2577   92.033   0      0.000   92.033
195904.0 195904.0 23600.9  0.0   1567680.0 142541.6 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0 23600.9  0.0   1567680.0 266338.1 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0 23600.9  0.0   1567680.0 413941.8 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0 23600.9  0.0   1567680.0 642390.6 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0 23600.9  0.0   1567680.0 813957.3 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0 23600.9  0.0   1567680.0 984223.2 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0 23600.9  0.0   1567680.0 1155472.7 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0 23600.9  0.0   1567680.0 1399228.5 8526272.0  3558435.8  1048576.0 163148.4   2578   92.060   0      0.000   92.060
195904.0 195904.0  0.0   23866.6 1567680.0 38005.6  8526272.0  3559196.7  1048576.0 163148.4   2579   92.092   0      0.000   92.092
```

**字段意义如下**

| 列名 | 说明                                                         |
| ---- | ------------------------------------------------------------ |
| S0C  | 新生代中Survivor space中S0当前容量的大小（KB）               |
| S1C  | 新生代中Survivor space中S1当前容量的大小（KB）               |
| S0U  | 新生代中Survivor space中S0容量使用的大小（KB）               |
| S1U  | 新生代中Survivor space中S1容量使用的大小（KB）               |
| EC   | Eden space当前容量的大小（KB）                               |
| EU   | Eden space容量使用的大小（KB）                               |
| OC   | Old space当前容量的大小（KB）                                |
| OU   | Old space使用容量的大小（KB）                                |
| PC   | Permanent space当前容量的大小（KB）                          |
| PU   | Permanent space使用容量的大小（KB）                          |
| YGC  | 从应用程序启动到采样时发生 Young GC 的次数                   |
| YGCT | 从应用程序启动到采样时 Young GC 所用的时间(秒)               |
| FGC  | 从应用程序启动到采样时发生 Full GC 的次数                    |
| FGCT | 从应用程序启动到采样时 Full GC 所用的时间(秒)                |
| GCT  | T从应用程序启动到采样时用于垃圾回收的总时间(单位秒)，它的值等于YGC+FGC |
| MC   | 方法区大小                                                   |
| MU   | 方法区使用大小                                               |
| CCSC | 压缩类空间大小                                               |
| CCSU | 压缩类空间使用大小                                           |

#### 5、jvmtop

```
以上介绍的jps、jstack、jinfo等都是安装JDK 时自带的系统分析工具，而jvmtop是一款开源的JVM工具。
它的下载地址如下: https://github.com/patric-r/jvmtop
顾名思义，它是一个只针对JVM的工具，展示的方式和unix的top命令相似.
jvmtop 提供了两个视图，一个是概览视图，可以展示出当前机器的所有的 JVM 的情况. 还有一个视图是详情视图，展示一个 JVM 的详细情况.
[https://github.com/patric-r/jvmtop/releases/download/0.8.0/jvmtop-0.8.0.tar.gz]
```

**概览视图**

```
jvmtop.sh
```

![](https://i.loli.net/2019/04/29/5cc679312313b.jpg)

```
其中，各个字段的意义分别如下：
PID：进程 ID
MAIN-CLASS：main 类的名字
HPCUR：当前被使用的 heap 的大小
HPMAX：最大可用的 heap 的大小
NHCUR：当前被使用的非 heap 大小（比如：perm gen）
NHMAX：最大可用的非 heap 大小
CPU：CPU 的使用情况
GC：消耗在 GC 上的时间比例
VM：JVM 的提供者，大版本号，小版本号，图中的意思是 Apple 提供的 JDK 6U51 版本。
USERNAME：当前的用户名
#T：线程数量
DL：是否有线程发生死锁
```

**详情视图**

```
jvmtop.sh <pid>
```

![15191835567998](assets/15191835567998.jpg)

```
其中，各个字段的意义如下：
TID：线程 ID
NAME：线程名
STATE：线程状态
CPU：线程当前的 CPU 占用情况
TOTALCPU：从线程被创建开始总体的 CPU 占用情况
BLOCKBY：阻塞这个线程的线程 ID
```

### 3、JVM 运维实用监控工具(了解)

#### 1、VirtualVM

```
VisualVM 是一款免费的性能分析工具。它通过 jvmstat、JMX、SA（Serviceability Agent）以及 Attach API 等多种方式从程序运行时获得实时数据，从而进行动态的性能分析。同时，它能自动选择更快更轻量级的技术尽量减少性能分析对应用程序造成的影响，提高性能分析的精度。
```

##### 1、安装 VisualVM

```
到官网下载相应操作系统对应的软件.
官网地址: http://visualvm.github.io/
```

##### 2、安装 VisualVM插件

```
VisualVM 插件中心提供很多插件以供安装。可以通过 VisualVM 应用程序安装，或者从 VisualVM 插件中心手动下载插件，然后离线安装。
    
    从 VisualVM 插件中心安装插件步骤:
    * 从主菜单中选择“工具”>“插件”。
    * 在“可用插件”标签中，选中该插件的“安装”复选框。单击”安装“。
    * 逐步完成插件安装程序。
    
    离线安装插件步骤:
    * 到插件中心官网: http://visualvm.github.io/pluginscenters.html 下载对应的VisualVM版本的插件
    * 从主菜单中选择“工具”>“插件”。
    * 在“已下载”标签中,点击"添加插件"按钮,选择已下载的插件文件 (以.nbm结尾) 打开。
    * 选中要打开的插件文件，并单击"安装"按钮，逐步完成插件安装程序。
```

##### 3、如何监控JVM

```
那如何通过VisualVM 去分析远程的JVM虚拟机里的信息呢?
首先要在JVM中开启相关配置，以供VisualVM能够从中获取JVM的信息，如何配置JVM呢？ 这里以Tomcat为例:

在Tomcat的 catalina.sh 或者是setenv.sh 脚本中加上如下参数
 -Dcom.sun.management.jmxremote 
 -Dcom.sun.management.jmxremote.port=一个监听端口 
 -Dcom.sun.management.jmxremote.authenticate=false 
 -Dcom.sun.management.jmxremote.ssl=false 
 -Djava.rmi.server.hostname=可解析的主机名称

具体测试参数如下:
 -Dcom.sun.management.jmxremote 
 -Dcom.sun.management.jmxremote.port=11412 
 -Dcom.sun.management.jmxremote.authenticate=false 
 -Dcom.sun.management.jmxremote.ssl=false 
 -Djava.rmi.server.hostname=java01.qfedu.com

 注意这里的java01.qfedu.com 必须是DNS可解析的主机名，11412 为监听端口

 其次在VisualVM 中配置连接到上面配置的服务器加端口的地址上去:
 * 在VisualVM中选择"远程"
 * 在弹出的窗口中选择"添加远程主机"
 * 此时会在远程中，多出一台主机。此时点击多出来的主机
 * 添加连接JVM相关的信息
```

**VisualVM如何监控JVM具体操作截图**

![15190945946474](assets/15190945946474.jpg)



![15190944033374](assets/15190944033374.jpg)



![15190944599288](assets/15190944599288.jpg)



![15190947653319](assets/15190947653319.jpg)



![15190949589854](assets/15190949589854.jpg)

#### 2、JmxTrans

JmxTrans 是一个可以实时通过JMX查询JVM 虚拟机状态的工具，它可以将通过JMX查询到的信息实时的录入到Ganglia、Graphite、Zabbix 等。

![QQ20180228-154459@2x](assets/QQ20180228-154459@2x.png)

##### 1、安装JmxTrans

```shell
// 下载 RPM 包，下载地址: http://central.maven.org/maven2/org/jmxtrans/jmxtrans/
// 这里下载的RPM包为: http://central.maven.org/maven2/org/jmxtrans/jmxtrans/266/jmxtrans-266.rpm
# yum -y install java // 由于jmxtrans 打包的原因，安全前必须依赖java软件包。所以安装。
# rpm -ivh jmxtrans-266.rpm // 若无法正常运行，可以试试其他版本
// 安装完成后，
// 有关 jmxtrans 程序安装在 /usr/share/jmxtrans 目录中
// 有关 jmxtrans 程序的启动脚本 /etc/init.d/jmxtrans
// 有关 jmxtrans 程序抓取JMX 的配置存放在 /var/lib/jmxtrans, 且是json文件的格式
// 有关 jmxtrans 程序的配置文件 /etc/jmxtrans/wrapper.conf
// 有关 jmxtrans 程序启动是的错误信息存储在 /var/log/jmxtrans/jmxtrans.log 
```

##### 2、使用JmxTrans 采集数据

在 /var/lib/jmxtrans 目录下，创建 test.json 文件。 软后重启 jmxtrans 服务。 

由于是测试，我们将收集到的JVM 信息保存到了本地的/tmp/output.txt 文件中

```json
{
  "servers": [
    {
      "numQueryThreads": 3,
      "host": "10.200.16.228", //换成JVM 所在的服务器
      "port": 11415,       // 换成JMX 端口
      "queries": [
        {
          "outputWriters": [
            {
              "@class" : "com.googlecode.jmxtrans.model.output.KeyOutWriter",
              "outputFile" : "/tmp/output.txt"
            }
          ],
          "resultAlias": "heap",
          "obj": "java.lang:type=Memory",
          "attr": [
            "HeapMemoryUsage",
            "NonHeapMemoryUsage"
          ]
        },
        {
          "outputWriters": [
            {
              "@class" : "com.googlecode.jmxtrans.model.output.KeyOutWriter",
              "outputFile" : "/tmp/output.txt"
           }
          ],
          "resultAlias": "thread",
          "obj": "java.lang:type=Threading",
          "attr": [
            "ThreadCount",
            "PeakThreadCount",
            "DaemonThreadCount",
            "CurrentThreadCpuTime",
            "CurrentThreadUserTime",
            "TotalStartedThreadCount"
          ]
        },
        {
          "outputWriters": [
            {
              "@class" : "com.googlecode.jmxtrans.model.output.KeyOutWriter",
              "outputFile" : "/tmp/output.txt"
            }
          ],
          "resultAlias": "operatingsystem",
          "obj": "java.lang:type=OperatingSystem",
          "attr": [
            "ProcessCpuTime",
            "ProcessCpuLoad",
            "SystemCpuLoad",
            "SystemLoadAverage",
            "FreeSwapSpaceSize",
            "TotalSwapSpaceSize",
            "TotalPhysicalMemorySize",
            "CommittedVirtualMemorySize",
            "OpenFileDescriptorCount",
            "AvailableProcessors",
            "MaxFileDescriptorCount",
            "FreePhysicalMemorySize"
          ]
        }
      ]
    }
  ]
}
```

参考输出结果:

```shell
[root@mouse03 jmxtrans]# cat /tmp/output.txt
10_200_16_228_11415.thread.ThreadCount	418	1518065577329
10_200_16_228_11415.thread.PeakThreadCount	445	1518065577329
10_200_16_228_11415.thread.DaemonThreadCount	417	1518065577329
10_200_16_228_11415.thread.CurrentThreadCpuTime	4065386	1518065577329
10_200_16_228_11415.thread.CurrentThreadUserTime	0	1518065577329
10_200_16_228_11415.thread.TotalStartedThreadCount	53766	1518065577329
10_200_16_228_11415.heap.HeapMemoryUsage_init	4294967296	1518065577343
10_200_16_228_11415.heap.HeapMemoryUsage_committed	4151836672	1518065577343
10_200_16_228_11415.heap.HeapMemoryUsage_max	4151836672	1518065577343
10_200_16_228_11415.heap.HeapMemoryUsage_used	1066173744	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_init	1076297728	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_committed	1087897600	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_max	2197815296	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_used	99018384	1518065577343
10_200_16_228_11415.operatingsystem.ProcessCpuTime	30701230000000	1518065577381
10_200_16_228_11415.operatingsystem.ProcessCpuLoad	3.976670201484624E-4	1518065577381
10_200_16_228_11415.operatingsystem.SystemCpuLoad	0.060445387062566275	1518065577381
10_200_16_228_11415.operatingsystem.SystemLoadAverage	2.06	1518065577381
10_200_16_228_11415.operatingsystem.FreeSwapSpaceSize	6357475328	1518065577381
10_200_16_228_11415.operatingsystem.TotalSwapSpaceSize	8565813248	1518065577381
10_200_16_228_11415.operatingsystem.TotalPhysicalMemorySize	67266252800	1518065577381
10_200_16_228_11415.operatingsystem.CommittedVirtualMemorySize	25674649600	1518065577381
10_200_16_228_11415.operatingsystem.OpenFileDescriptorCount	1102	1518065577381
10_200_16_228_11415.operatingsystem.AvailableProcessors	32	1518065577381
10_200_16_228_11415.operatingsystem.MaxFileDescriptorCount	65535	1518065577381
10_200_16_228_11415.operatingsystem.FreePhysicalMemorySize	700805120	1518065577381
```

##### 3、JmxTrans 的配置json 文件是怎么写出来的

这里就要结合上一节提到的 VirtualVM + MBeans 插件了，我们所有通过JmxTrans 获取到的JVM 里的信息，

在 JVM 里被叫做Mbeans。这里我们以获取堆栈和非堆栈信息来举例

```json
        {
          "outputWriters": [
            {
              "@class" : "com.googlecode.jmxtrans.model.output.KeyOutWriter",
              "outputFile" : "/tmp/output.txt"
            }
          ],
          "resultAlias": "heap",
          "obj": "java.lang:type=Memory",
          "attr": [
            "HeapMemoryUsage",
            "NonHeapMemoryUsage"
          ]
        }
```

```json
          "outputWriters": [
            {
              "@class" : "com.googlecode.jmxtrans.model.output.KeyOutWriter",
              "outputFile" : "/tmp/output.txt"
            }
          ]
//这部分信息标示，采集到的信息存储到哪里，我们这里存储到了本地文件 /tmp/output.txt 中
"resultAlias": "heap",
// 给采集到的堆栈信息和非堆栈信息加了一个类似metric 的前缀，所以我们在输出文件中看到了一下这些内容
10_200_16_228_11415.heap.HeapMemoryUsage_init	4294967296	1518065577343
10_200_16_228_11415.heap.HeapMemoryUsage_committed	4151836672	1518065577343
10_200_16_228_11415.heap.HeapMemoryUsage_max	4151836672	1518065577343
10_200_16_228_11415.heap.HeapMemoryUsage_used	1066173744	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_init	1076297728	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_committed	1087897600	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_max	2197815296	1518065577343
10_200_16_228_11415.heap.NonHeapMemoryUsage_used	99018384	1518065577343
```



```json
"obj": "java.lang:type=Memory",
// 这一部分的信息获取， 就要结合 VirtualVM + MBeans 了。 找到ObjName ,将里面的Value 原样复制过来就好
// 这是来告诉 JmxTrans 收集 Memory 信息，那到底收集内存里的一些什么东西呢？ 我们继续看下面的解释。
```

![QQ20180228-172146@2x](assets/QQ20180228-172146@2x.png)



```json
          "attr": [
            "HeapMemoryUsage",
            "NonHeapMemoryUsage"
          ]
// 告诉JmxTrans ， 收集内存里的 HeapMemoryUsage 和  NonHeapMemoryUsage 这两个属性。那 Memory 里
// 都有啥属性，怎么去查看呢？ 这里还是离不开  VirtualVM + MBeans 的帮助。同样，我们将属性名字原样粘
// 贴过来就好
```

![QQ20180228-172738@2x](assets/QQ20180228-172738@2x.png)



其实 JmxTrans 的使用不是很复杂，主要是如何去表达要获取到的属性。我们这里只是列举了最基本、也是最常见的方法。要想详细的了解JmxTrans 的使用。可以学习它的官方文档: https://github.com/jmxtrans/jmxtrans/wiki

### 3、部署 Tomcat + Jenkins

```
既然Tomcat是一个WEB应用服务器，这个服务器中运行的程序是什么语言的呢? PHP、PYTHON、JAVA还是ASP等呢？
Tomcat 服务器在生产环境中主要作为JAVA程序的WEB服务器。我们这里以Tomcat + jenkins 的部署为例来运行 jenkins 服。
   1、安装JDK8、并配置JAVA_HOME 等相关信息(新版本jenkins只有jdk8支持)
   JAVA_HOME="/usr/local/jdk"
   CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
   PATH=$PATH:"$JAVA_HOME/bin"
   2、安装Tomcat,启动Tomcat 并访问http://127.0.0.1:8080(这是使用了tomcat8 做测试)
   3、下载jenkins的war包程序
      http://mirrors.shu.edu.cn/jenkins/war/2.108/jenkins.war
      wget http://updates.jenkins-ci.org/download/war/2.129/jenkins.war
   4、将jenksins.war 放到解压后的tomcat 的webapps 目录中
   5、重启tomcat,并访问 http://127.0.0.1/jenkins
```

#### 1、日志格式配置

```xml
server.xml
<Valve className="org.apache.catalina.valves.AccessLogValve" directory="/data0/www/logs"
               prefix="jenkins-" suffix="-access_log"
               pattern="%{X-Real-IP}i - %v %t &quot;%r&quot; - %s %b %T &quot;%{Referer}i&quot; &quot;%{User-Agent}i&quot; %a &quot;-&quot; &quot;-&quot;" >
```

#### 2、JVM 参数优化

```shell
catalina.sh
JAVA_OPTS="$JAVA_OPTS -Xms4096m -Xmx4096m -XX:PermSize=1024m -XX:MaxPermSize=2048m"
```

#### 3、开启GC日志

```shell
catalina.sh
JAVA_OPTS="$JAVA_OPTS -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:/data0/logs/gc-%t.log"
```

#### 4、开启JMX端口便于监控

```shell
catalina.sh
CATALINA_OPTS="$CATALINA_OPTS -Dcom.sun.management.jmxremote 
-Dcom.sun.management.jmxremote.port=10028 
-Dcom.sun.management.jmxremote.authenticate=false 
-Dcom.sun.management.jmxremote.ssl=false 
-Djava.rmi.server.hostname=java69-matrix.zeus.lianjia.com"
```

#### 5、取消JVM 的默认DNS缓存时间

不缓存DNS记录，避免DNS解析更改后要重启JVM虚拟机

```shell
catalina.sh
CATALINA_OPTS="$CATALINA_OPTS -Dsun.net.inetaddr.ttl=0 -Dsun.net.inetaddr.negative.ttl=0“
```

### 4、企业 Tomcat 运维

#### **1、Tomcat 简介**

Tomcat是Apache软件基金会（Apache Software Foundation）的Jakarta 项目中的一个核心项目，由Apache、Sun和其他一些公司及个人共同开发而成。

Tomcat服务器是一个免费的开放源代码的Web应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试JSP程序的首选。

Tomcat和Nginx、Apache(httpd)、lighttpd等Web服务器一样，具有处理HTML页面的功能，另外它还是一个Servlet和JSP容器，独立的Servlet容器是Tomcat的默认模式。不过，Tomcat处理静态HTML的能力不如Nginx/Apache服务器。

目前Tomcat最新版本为10.1。Java容器还有resin、weblogic等。

**Tomcat****官网：** [http://tomcat.apache.org](http://tomcat.apache.org/)

##### 1、Tomcat好帮手---JDK  

JDK是 Java 语言的软件开发工具包，主要用于移动设备、嵌入式设备上的java应用程序。JDK是整个java开发的核心，它包含了JAVA的运行环境（JVM+Java系统类库）和JAVA工具。

**JDK****包含了一批用于Java****开发的组件，其中包括：**

```
javac：编译器，将后缀名为.java的源代码编译成后缀名为“.class”的字节码
java：运行工具，运行.class的字节码
jar：打包工具，将相关的类文件打包成一个文件
javadoc：文档生成器，从源码注释中提取文档，注释需匹配规范
jdb debugger：调试工具
jps：显示当前java程序运行的进程状态
javap：反编译程序
appletviewer：运行和调试applet程序的工具，不需要使用浏览器
javah：从Java类生成C头文件和C源文件。这些文件提供了连接胶合，使Java和C代码可进行交互。
javaws：运行JNLP程序
extcheck：一个检测jar包冲突的工具
apt：注释处理工具 
jhat：java堆分析工具
jstack：栈跟踪程序
jstat：JVM检测统计工具
jstatd：jstat守护进程
jinfo：获取正在运行或崩溃的java程序配置信息
jmap：获取java进程内存映射信息
idlj：IDL-to-Java编译器。将IDL语言转化为java文件 
policytool：一个GUI的策略文件创建和管理工具
jrunscript：命令行脚本运行
```

JDK中还包括完整的JRE（Java Runtime Environment），Java运行环境，也被称为private runtime。包括了用于产品环境的各种库类，如基础类库rt.jar，以及给开发人员使用的补充库，如国际化与本地化的类库、IDL库等等。

JDK中还包括各种样例程序，用以展示Java API中的各部分。

**JDK****下载面页：**

<http://www.oracle.com/technetwork/java/javase/downloads/index.html>

##### 2、安装Tomcat & JDK

安装时候选择tomcat软件版本要与程序开发使用的版本一致。jdk版本要进行与tomcat保持一致。

###### 1、系统环境说明

```
[root@web03 ~]# cat /etc/redhat-release 
CentOS Linux release 7.4.1708 (Core) 
[root@web03 ~]# uname -a 
Linux web03 3.10.0-693.el7.x86_64 #1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
[root@web03 ~]# getenforce 
Disabled
[root@web03 ~]# systemctl status firewalld.service
● firewalld.service - firewalld - dynamic firewall daemon
   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled)
   Active: inactive (dead)
     Docs: man:firewalld(1)
```

###### 2 、安装JDK

命令集：

```
tar xf jdk-8u60-linux-x64.tar.gz -C /application/
ln -s /application/jdk1.8.0_60 /application/jdk
# 设置环境变量
sed -i.ori '$a export JAVA_HOME=/application/jdk\nexport PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$PATH\nexport CLASSPATH=.:$JAVA_HOME/lib:$JAVA_HOME/jre/lib:$JAVA_HOME/lib/tools.jar' /etc/profile
source /etc/profile
```

测试jdk是否安装成功↓

```
[root@web03 ~]# java -version
java version "1.8.0_60"
Java(TM) SE Runtime Environment (build 1.8.0_60-b27)
Java HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)
```

###### 3、安装Tomcat

命令集：

```
tar xf apache-tomcat-8.0.27.tar.gz -C /application/
ln -s /application/apache-tomcat-8.0.27 /application/tomcat
# 设置环境变量
echo 'export TOMCAT_HOME=/application/tomcat'>>/etc/profile
source /etc/profile
# 注意授权，统一权限
chown -R root.root /application/jdk/ /application/tomcat/
```

检查tomcat是否安装成功

```
[root@web03 ~]# /application/tomcat/bin/version.sh
Using CATALINA_BASE:   /application/tomcat
Using CATALINA_HOME:   /application/tomcat
Using CATALINA_TMPDIR: /application/tomcat/temp
Using JRE_HOME:        /application/jdk
Using CLASSPATH:       /application/tomcat/bin/bootstrap.jar:/application/tomcat/bin/tomcat-juli.jar
Server version: Apache Tomcat/8.0.27
Server built:   Sep 28 2015 08:17:25 UTC
Server number:  8.0.27.0
OS Name:        Linux
OS Version:     3.10.0-693.el7.x86_64
Architecture:   amd64
JVM Version:    1.8.0_60-b27
JVM Vendor:     Oracle Corporation
```

#### 2、Tomcat目录介绍

##### 1、tomcat主目录介绍

```
[root@web03 ~]# cd /application/tomcat/
[root@web03 tomcat]# tree -L 1
.
├── bin              #存放tomcat管理脚本
├── conf             # tomcat 配置文件存放目录
├── lib              # web应用调用的jar包存放路径
├── LICENSE
├── logs             # tomcat 日志存放目录，catalina.out 为主要输出日志
├── NOTICE
├── RELEASE-NOTES
├── RUNNING.txt
├── temp             # 存放临时文件
├── webapps         # web程序存放目录
└── work             # 存放编译产生的.java 与 .class文件

7 directories, 4 files
```

##### 2、webapps目录介绍

```
[root@web03 tomcat]# cd webapps/
[root@web03 webapps]# tree -L 1
.
├── docs            # tomcat 帮助文档
├── examples       # web应用实例
├── host-manager  # 主机管理
├── manager         # 管理
└── ROOT             # 默认站点根目录

5 directories, 0 files
```

##### 3、Tomcat配置文件目录介绍（conf）

```
[root@web03 conf]# tree -L 1
.
├── Catalina
├── catalina.policy
├── catalina.properties
├── context.xml
├── logging.properties
├── logs
├── server.xml           # tomcat 主配置文件
├── server.xml.bak
├── server.xml.bak2
├── tomcat-users.xml    # tomcat 管理用户配置文件
├── tomcat-users.xsd
└── web.xml

2 directories, 10 files
```

##### 4、Tomcat的管理

```
#  启动程序/application/tomcat/bin/startup.sh
#  关闭程序/application/tomcat/bin/shutdown.sh
```

启动停止

```
[root@web03 ~]# /application/tomcat/bin/shutdown.sh 
Using CATALINA_BASE:   /application/tomcat
Using CATALINA_HOME:   /application/tomcat
Using CATALINA_TMPDIR: /application/tomcat/temp
Using JRE_HOME:        /application/jdk
Using CLASSPATH:       /application/tomcat/bin/bootstrap.jar:/application/tomcat/bin/tomcat-juli.jar
[root@web03 ~]# /application/tomcat/bin/startup.sh 
Using CATALINA_BASE:   /application/tomcat
Using CATALINA_HOME:   /application/tomcat
Using CATALINA_TMPDIR: /application/tomcat/temp
Using JRE_HOME:        /application/jdk
Using CLASSPATH:       /application/tomcat/bin/bootstrap.jar:/application/tomcat/bin/tomcat-juli.jar
Tomcat started.
```

​         注意：tomcat未启动的情况下使用shutdown脚本，会有大量的输出信息。

检查tomcat是否启动正常

```
[root@web03 ~]# netstat -lntup  |grep java
tcp6       0      0 :::8080         :::*                   LISTEN      30560/java          
tcp6       0      0 127.0.0.1:8005          :::*          LISTEN      30560/java          
tcp6       0      0 :::8009                 :::*           LISTEN      30560/java      
```

**说明：**所有与java相关的，服务启动都是java命名的进程

启动完成浏览器进行访问

http://10.0.0.17:8080/

![](https://i.loli.net/2019/04/29/5cc707f50cbd3.jpg)

#### 3、Tomcat日志说明

##### 1、查看日志

```
[root@web03 ~]# tailf /application/tomcat/logs/catalina.out
24-Nov-2017 15:09:51.654 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["http-nio-8080"]
24-Nov-2017 15:09:51.665 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler ["ajp-nio-8009"]
24-Nov-2017 15:09:51.670 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in 60037 ms
```

​         发现启动时间较长，其中有一项的启动时间占据了绝大多数

```
24-Nov-2017 15:09:50.629 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployWAR Deployment of web application archive /application/apache-tomcat-8.0.27/webapps/memtest.war has finished in 58,892 ms
```

​         发现耗时在这里：是session引起的随机数问题导致的。Tocmat的Session ID是通过SHA1算法计算得到的，计算Session ID的时候必须有一个密钥。为了提高安全性Tomcat在启动的时候会通过随机生成一个密钥。

##### 2、解决Tomcat启动慢的方法

Tomcat启动慢主要原因是生成随机数的时候卡住了,导致tomcat启动不了。

是否有足够的熵来用于产生随机数，可以通过如下命令来查看

```
[root@web03 ~]# cat /proc/sys/kernel/random/entropy_avail
6
```

为了加速/dev/random提供随机数的速度，你可以通过操作设备的外设，让其产生大量的中断，网络传输数据，按键，移动鼠标，在命令行敲几个不同的命令，俗称聚气。

cat /dev/random 会消耗能量

**方法1****：**

```
vim $JAVA_HOME/jre/lib/security/java.security
securerandom.source=file:/dev/random
```

改为

```
securerandom.source=file:/dev/urandom
```

**方法2****：**

```
vim $TOMCAT_HOME/bin/catalina.sh
if [[ "$JAVA_OPTS" != *-Djava.security.egd=* ]]; then
    JAVA_OPTS="$JAVA_OPTS -Djava.security.egd=file:/dev/urandom"
fi
```

这个系统属性egd表示熵收集守护进程(entropy gathering daemon)

**方法3****：（推荐）**

```
yum install rng-tools # 安装rngd服务（熵服务，增大熵池）
systemctl start rngd  # 启动服务
```

#### 4、Tomcat管理功能使用

**注意：测试功能，生产环境不要用**

Tomcat管理功能用于对Tomcat自身以及部署在Tomcat上的应用进行管理的web应用。在默认情况下是处于禁用状态的。如果需要开启这个功能，就需要配置管理用户，即配置tomcat-users.xml 文件。

```
[root@web03 ~]# vim /application/tomcat/conf/tomcat-users.xml
……
39 <role rolename="manager-gui"/>
 40 <role rolename="admin-gui"/>
 41 <user username="tomcat" password="tomcat" roles="manager-gui,admin-gui"/>
 42 </tomcat-users>   # 在此行前加入上面三行
 
 
 找到webapps/manager/META-INF/context.xml，将以下内容注释掉，这样就能远程访问web manager了：
 <Context antiResourceLocking="false" privileged="true" >
<!-- 
 <Valve className="org.apache.catalina.valves.RemoteAddrValve"
         allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1" />
  <Manager sessionAttributeValueClassNameFilter="java\.lang\.(?:Boolean|Integer|Long|Number|String)|org\.apache\.catalina\.filters\.CsrfPreventionFilter\$LruCache(?:\$1)?|java\.util\.(?:Linked)?HashMap"/>
-->
</Context>


找到webapps/host-manager/META-INF/context.xml,将以下内容注释掉，
<Context antiResourceLocking="false" privileged="true" >
<!--
  <Valve className="org.apache.catalina.valves.RemoteAddrValve"
         allow="127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1" />
  <Manager sessionAttributeValueClassNameFilter="java\.lang\.(?:Boolean|Integer|Long|Number|String)|org\.apache\.catalina\.filters\.CsrfPreventionFilter\$LruCache(?:\$1)?|java\.util\.(?:Linked)?HashMap"/>
-->
</Context>


```

**未修改文件前进行访问**

![img](assets/1190037-20171127161652222-1076194549.png)

```
<role rolename="manager-gui"/>
<user username="tomcat" password="s3cret" roles="manager-gui"/>
```

![img](assets/1190037-20171127161724815-1070672278.png)

```
<role rolename="admin-gui"/>
<user username="tomcat" password="s3cret" roles="admin-gui"/>
```

​         从而得出上面的配置文件信息。

##### 1、在web界面访问管理界面

![img](assets/1190037-20171127161751487-2030329982.png)

​         输入之前配置的账户与密码即可

![img](assets/1190037-20171127161800081-74753629.png)

![img](assets/1190037-20171127161808956-1963855479.png)

#### 5、Tomcat主配置文件详解

##### 1、server.xml组件类别

顶级组件：位于整个配置的顶层，如server。

容器类组件：可以包含其它组件的组件，如service、engine、host、context。

连接器组件：连接用户请求至tomcat，如connector。

被嵌套类组件：位于一个容器当中，不能包含其他组件，如Valve、logger。

```
<server>
     <service>
     <connector />
     <engine>
     <host>
     <context></context>
     </host>
     <host>
     <context></context>
     </host>
     </engine>
     </service>
</server>
```

##### 2、组件介绍

| **组件名称**            | **功能介绍**                                                 |
| ----------------------- | ------------------------------------------------------------ |
| **engine**              | 核心容器组件，catalina引擎，负责通过connector接收用户请求，并处理请求，将请求转至对应的虚拟主机host。 |
| **host**                | 类似于httpd中的虚拟主机，一般而言支持基于FQDN的虚拟主机。    |
| **context**             | 定义一个应用程序，是一个最内层的容器类组件（不能再嵌套）。配置context的主要目的指定对应对的webapp的根目录，类似于httpd的alias，其还能为webapp指定额外的属性，如部署方式等。 |
| **connector**           | 接收用户请求，类似于httpd的listen配置监听端口的。            |
| **service****（服务）** | 将connector关联至engine，因此一个service内部可以有多个connector，但只能有一个引擎engine。service内部有两个connector，一个engine。因此，一般情况下一个server内部只有一个service，一个service内部只有一个engine，但一个service内部可以有多个connector。 |
| **server**              | 表示一个运行于JVM中的tomcat实例。                            |
| **Valve**               | 阀门，拦截请求并在将其转至对应的webapp前进行某种处理操作，可以用于任何容器中，比如记录日志(access log valve)、基于IP做访问控制(remote address filter valve)。 |
| **logger**              | 日志记录器，用于记录组件内部的状态信息，可以用于除context外的任何容器中。 |
| **realm**               | 可以用于任意容器类的组件中，关联一个用户认证库，实现认证和授权。可以关联的认证库有两种：UserDatabaseRealm、MemoryRealm和JDBCRealm。 |
| **UserDatabaseRealm**   | 使用JNDI自定义的用户认证库。                                 |
| **MemoryRealm**         | 认证信息定义在tomcat-users.xml中。                           |
| **JDBCRealm**           | 认证信息定义在数据库中，并通过JDBC连接至数据库中查找认证用户。 |

##### 3、server.xml配置文件注释

```
<?xml version='1.0' encoding='utf-8'?>
<!--
<Server>元素代表整个容器,是Tomcat实例的顶层元素.由org.apache.catalina.Server接口来定义.它包含一个<Service>元素.并且它不能做为任何元素的子元素.
    port指定Tomcat监听shutdown命令端口.终止服务器运行时,必须在Tomcat服务器所在的机器上发出shutdown命令.该属性是必须的.
    shutdown指定终止Tomcat服务器运行时,发给Tomcat服务器的shutdown监听端口的字符串.该属性必须设置
-->
<Server port="8005" shutdown="SHUTDOWN">
  <Listener className="org.apache.catalina.startup.VersionLoggerListener" />
  <Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" />
  <Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" />
  <Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" />
  <Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" />
  <GlobalNamingResources>
    <Resource name="UserDatabase" auth="Container"
              type="org.apache.catalina.UserDatabase"
              description="User database that can be updated and saved"
              factory="org.apache.catalina.users.MemoryUserDatabaseFactory"
              pathname="conf/tomcat-users.xml" />
  </GlobalNamingResources>
  <!--service服务组件-->
  <Service name="Catalina">
    <!-- Connector主要参数说明（见下表） -->
    <Connector port="8080" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" />
    <Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />
    <!--engine,核心容器组件,catalina引擎,负责通过connector接收用户请求,并处理请求,将请求转至对应的虚拟主机host
        defaultHost指定缺省的处理请求的主机名，它至少与其中的一个host元素的name属性值是一样的
    -->
    <Engine name="Catalina" defaultHost="localhost">
      <!--Realm表示存放用户名，密码及role的数据库-->
      <Realm className="org.apache.catalina.realm.LockOutRealm">
        <Realm className="org.apache.catalina.realm.UserDatabaseRealm"
               resourceName="UserDatabase"/>
      </Realm>
      <!-- 详情常见下表（host参数详解）-->
      <Host name="localhost"  appBase="webapps"
            unpackWARs="true" autoDeploy="true">
        <!-- 详情常见下表（Context参数说明 ）-->
        <Context path="" docBase="" debug=""/>
        <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs"
               prefix="localhost_access_log" suffix=".txt"
               pattern="%h %l %u %t &quot;%r&quot; %s %b" />
      </Host>
    </Engine>
  </Service>
</Server>
```

##### 4、Connector主要参数说明

| **参数**              | **参数说明**                                                 |
| --------------------- | ------------------------------------------------------------ |
| **connector**         | 接收用户请求，类似于httpd的listen配置监听端口.               |
| **port**              | 指定服务器端要创建的端口号，并在这个端口监听来自客户端的请求。 |
| **address**           | 指定连接器监听的地址，默认为所有地址（即0.0.0.0）            |
| **protocol**          | 连接器使用的协议，支持HTTP和AJP。AJP（Apache Jserv Protocol）专用于tomcat与apache建立通信的， 在httpd反向代理用户请求至tomcat时使用（可见Nginx反向代理时不可用AJP协议）。 |
| **minProcessors**     | 服务器启动时创建的处理请求的线程数                           |
| **maxProcessors**     | 最大可以创建的处理请求的线程数                               |
| **enableLookups**     | 如果为true，则可以通过调用request.getRemoteHost()进行DNS查询来得到远程客户端的实际主机名，若为false则不进行DNS查询，而是返回其ip地址 |
| **redirectPort**      | 指定服务器正在处理http请求时收到了一个SSL传输请求后重定向的端口号 |
| **acceptCount**       | 指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理 |
| **connectionTimeout** | 指定超时的时间数(以毫秒为单位)                               |

##### 5、host参数详解

| **参数**              | **参数说明**                                                 |
| --------------------- | ------------------------------------------------------------ |
| **host**              | 表示一个虚拟主机                                             |
| **name**              | 指定主机名                                                   |
| **appBase**           | 应用程序基本目录，即存放应用程序的目录.一般为appBase="webapps"，相对于CATALINA_HOME而言的，也可以写绝对路径。 |
| **unpackWARs**        | 如果为true，则tomcat会自动将WAR文件解压，否则不解压，直接从WAR文件中运行应用程序 |
| **autoDeploy**        | 在tomcat启动时，是否自动部署。                               |
| **xmlValidation**     | 是否启动xml的校验功能，一般xmlValidation="false"。           |
| **xmlNamespaceAware** | 检测名称空间，一般xmlNamespaceAware="false"。                |

##### 6、Context参数说明

| **参数**       | **参数说明**                                                 |
| -------------- | ------------------------------------------------------------ |
| **Context**    | 表示一个web应用程序，通常为WAR文件                           |
| **docBase**    | 应用程序的路径或者是WAR文件存放的路径,也可以使用相对路径，起始路径为此Context所属Host中appBase定义的路径。 |
| **path**       | 表示此web应用程序的url的前缀，这样请求的url为http://localhost:8080/path/**** |
| **reloadable** | 这个属性非常重要，如果为true，则tomcat会自动检测应用程序的/WEB-INF/lib和/WEB-INF/classes目录的变化，自动装载新的应用程序，可以在不重启tomcat的情况下改变应用程序 |

#### 6、WEB站点部署

上线的代码有两种方式：

第一种方式是直接将程序目录放在webapps目录下面，这种方式大家已经明白了，就不多说了。

第二种方式是使用开发工具将程序打包成war包，然后上传到webapps目录下面。

##### 1、使用war包部署web站点

```
[root@web03 webapps]# pwd
/application/tomcat/webapps
[root@web03 webapps]# wget http://10.0.0.1/apache/tomcat/memtest.war
```

站点主动解压部署

```
[root@web03 webapps]# ls
docs  examples  host-manager  logs  manager  memtest  memtest.war  ROOT
```

浏览器访问：

*http://10.0.0.17:8080//memtest/meminfo.jsp*

![img](assets/1190037-20171127162004050-628167729.png)

##### 2、自定义默认网站目录

上面访问的网址为 *http://10.0.0.3:8080/memtest/meminfo.jsp*

现在想访问格式为*http://10.0.0.3:8080/meminfo.jsp*

**方法一**

将meminfo.jsp或其他程序放在tomcat/webapps/ROOT目录下即可。因为默认网站根目录为tomcat/webapps/ROOT

**方法二**

```
[root@web03 ~]# vim /application/tomcat/conf/server.xml +125
…… #添加上这两行
        <Context path="" docBase="/application/tomcat/webapps/memtest" debug="0" reloadable="false" crossContext="true"/>
        <Context path="/40team" docBase="/application/tomcat/webapps/memtest" debug="0" reloadable="false" crossContext="true"/>
……
```

修改配置文件后，要重启服务

```
[root@web03 ~]# /application/tomcat/bin/shutdown.sh 
[root@web03 ~]# /application/tomcat/bin/startup.sh  
```

##### 3、部署开源站点（jpress）

jpress官网：http://jpress.io

下载地址：https://github.com/JpressProjects/jpress

​         第一个里程碑：安装配置数据库

```
yum -y install mariadb-server
systemctl start mariadb.service
```

​         \#配置数据库

```
mysql
create database jpress DEFAULT CHARACTER SET utf8;
grant all on jpress.* to jpress@'localhost' identified by '123456';
exit
```

​         第二个里程碑：jpress站点上线

```
[root@web03 webapps]# pwd
/application/tomcat/webapps
[root@web03 webapps]# 链接：https://pan.baidu.com/s/16WmAwxXF3_BIJFLqvwR9rA 提取码：2021 
```

​         第三个里程碑：浏览器访问

浏览器访问： http://10.0.0.17:8080/jpress-web-newest/install

![img](assets/1190037-20171127162126425-251381726.png)

填写数据库信息

![img](assets/1190037-20171127162135190-1727193752.png)

设置站点名称等

![img](assets/1190037-20171127162142753-1410863007.png)

安装完成

![img](assets/1190037-20171127162149956-1281737675.png)

重启tomcat服务

```
[root@web03 ~]# /application/tomcat/bin/shutdown.sh 
[root@web03 ~]# /application/tomcat/bin/startup.sh  
```

#### 7、Tomcat多实例配置

**多虚拟主机**：nginx 多个Server标签（域名，ip，端口） 进程数量固定 master+worker

**多实例（多进程）**：同一个程序启动多次，分为两种情况:

第一种：一台机器跑多个站点； 

第二种：一个机器跑一个站点多个实例，配合负载均衡

##### 1、复制程序文件

```
    cd /application/tools/
    tar xf apache-tomcat-8.0.27.tar.gz
    cp -a apache-tomcat-8.0.27 tomcat8_1
    cp -a apache-tomcat-8.0.27 tomcat8_2
```

修改端口，以启动多实例。多实例之间端口不能一致

```
sed -i 's#8005#8011#;s#8080#8081#' tomcat8_1/conf/server.xml
sed -i 's#8005#8012#;s#8080#8082#' tomcat8_2/conf/server.xml
[root@web03 application]# diff tomcat8_1/conf/server.xml tomcat8_2/conf/server.xml
22c22
< <Server port="8011" shutdown="SHUTDOWN">
---
> <Server port="8012" shutdown="SHUTDOWN">
67c67
<          Define a non-SSL/TLS HTTP/1.1 Connector on port 8081
---
>          Define a non-SSL/TLS HTTP/1.1 Connector on port 8082
69c69
<     <Connector port="8081" protocol="HTTP/1.1"
---
>     <Connector port="8082" protocol="HTTP/1.1"
75c75
<                port="8081" protocol="HTTP/1.1"
---
>                port="8082" protocol="HTTP/1.1"
```

　　 将配置好的tomcat程序打包，以备之后使用

```
tar zcf muti_tomcat8.tar.gz ./tomcat8_1 ./tomcat8_2
```

启动tomcat多实例

```
 /application/tomcat8_1/bin/startup.sh 
 /application/tomcat8_2/bin/startup.sh
 
 上述启动方式可能存在问题:
cat /application/tomcat8_1/bin/start.sh
#!/bin/bash
#tomcat1
export CATALINA_BASE="/application/tomcat8_1"

case "$1" in

start)
    $CATALINA_BASE/bin/startup.sh
    ;;
stop)
    $CATALINA_BASE/bin/shutdown.sh
esac

#记得修改catalina.sh  
CATALINA_HOME=/usr/local/tomcat1
如果多实例部署使用JDK版本不同，再这里定义java
JAVA_HOME=
JRE_HOME=
```

检查端口是否启动

```
[root@web03 tomcat8_1]# netstat -lntup |grep java
tcp6   0   0 127.0.0.1:8011    :::*    LISTEN   31906/java
tcp6   0   0 127.0.0.1:8012    :::*    LISTEN   31932/java
tcp6   0   0 :::8080           :::*    LISTEN   31812/java
tcp6   0   0 :::8081           :::*    LISTEN   31906/java
tcp6   0   0 :::8082           :::*    LISTEN   31932/java
tcp6   0   0 127.0.0.1:8005    :::*    LISTEN   31812/java
tcp6   0   0 :::8009           :::*    LISTEN   31812/java
```

将每个实例的网页进行区分

```
echo 8081 >>/application/tomcat8_1/webapps/ROOT/index.jsp 
echo 8082 >>/application/tomcat8_2/webapps/ROOT/index.jsp
```

##### 2、在浏览器访问，进行测试

检查多实例的启动

​                  http://10.0.0.17:8082

![img](assets/1190037-20171127162343831-1147071210.png)

http://10.0.0.17:8081

![img](assets/1190037-20171127162353581-1370700278.png)

#### 8、tomcat反向代理集群

##### 1、负载均衡器说明

```
[root@lb01 ~]# cat /etc/redhat-release 
CentOS release 6.9 (Final)
[root@lb01 ~]# uname -a
Linux lb01 2.6.32-696.el6.x86_64 #1 SMP Tue Mar 21 19:29:05 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
[root@lb01 ~]# getenforce 
Disabled
[root@lb01 ~]# /etc/init.d/iptables status
iptables: Firewall is not running.
```

负载均衡软件使用nginx，详情参照

http://www.cnblogs.com/clsn/p/7750615.html

##### 2、配置负载均衡器

备份原配置文件

```
mv  /application/nginx/conf/nginx.conf{,.20171127}
    egrep -v '#|^$' /application/nginx/conf/nginx.conf.default  > /application/nginx/conf/nginx.conf
```

​         配置文件内容

```
[root@lb01 ~]# cat /application/nginx/conf/nginx.conf
worker_processes  1;
events {
    worker_connections  1024;
}
http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
    upstream web_pools {
        server 10.0.0.17:8081;
        server 10.0.0.17:8082;
    }

    server {
        listen       80;
        server_name  localhost;
        location / {
            root   html;
            index  index.jsp index.htm;
        	proxy_pass http://web_pools;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
    }
}
```

​         配置完成后重启nginx服务

```
/application/nginx/sbin/nginx -t 
/application/nginx/sbin/nginx -s reload
```

##### 3、使用命令进行访问测试

使用curl 命令进行测试，tail进行关键字提取

```
[root@lb01 ~]# curl -s 10.0.0.5|tail -1
8081
[root@lb01 ~]# curl -s 10.0.0.5|tail -1
8082
```

使用curl 命令进行测试，awk进行关键字提取

```
[root@lb01 ~]# curl -s 10.0.0.5|awk 'END{print}'
8082
[root@lb01 ~]# curl -s 10.0.0.5|awk 'END{print}'
8081
```

 

 使用curl 命令进行测试，sed进行关键字提取

```
[root@lb01 ~]# curl -s 10.0.0.5|sed -n '$p'
8082
[root@lb01 ~]# curl -s 10.0.0.5|sed -n '$p'
8081
```

##### 4、在浏览器上进行访问测试

![img](assets/1190037-20171127162541722-347092218.png)

![img](assets/1190037-20171127162551550-1844076575.png)

​         建议使用google浏览器chrome 的隐身模式进行访问，使用ctrl+f5 进行强制刷新

#### 9、监控tomcat集群状态(此处不讲，等监控部分详细讲)

##### 1、方法一：开发java监控页面

```
[root@web03 tomcat8_1]# cat /application/tomcat/webapps/memtest/meminfo.jsp 
<%
Runtime rtm = Runtime.getRuntime();
long mm = rtm.maxMemory()/1024/1024;
long tm = rtm.totalMemory()/1024/1024;
long fm = rtm.freeMemory()/1024/1024;

out.println("JVM memory detail info :<br>");
out.println("Max memory:"+mm+"MB"+"<br>");
out.println("Total memory:"+tm+"MB"+"<br>");
out.println("Free memory:"+fm+"MB"+"<br>");
out.println("Available memory can be used is :"+(mm+fm-tm)+"MB"+"<br>");
%>
```

##### 2、方法二：使用jps命令进行监控

```
[root@web03 ~]# jps -lvm

31906 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/application/tomcat8_1/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/application/tomcat8_1/endorsed -Dcatalina.base=/application/tomcat8_1 -Dcatalina.home=/application/tomcat8_1 -Djava.io.tmpdir=/application/tomcat8_1/temp

31812 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/application/tomcat/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/application/tomcat/endorsed -Dcatalina.base=/application/tomcat -Dcatalina.home=/application/tomcat -Djava.io.tmpdir=/application/tomcat/temp

31932 org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=/application/tomcat8_2/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.endorsed.dirs=/application/tomcat8_2/endorsed -Dcatalina.base=/application/tomcat8_2 -Dcatalina.home=/application/tomcat8_2 -Djava.io.tmpdir=/application/tomcat8_2/temp

32079 sun.tools.jps.Jps -lvm -Denv.class.path=.:/application/jdk/lib:/application/jdk/jre/lib:/application/jdk/lib/tools.jar -Dapplication.home=/application/jdk1.8.0_60 -Xms8m
```

##### 3、Tomcat远程监控功能

修改配置文件，开启远程监控

```
vim /application/tomcat8_1/bin/catalina.sh +97

CATALINA_OPTS="$CATALINA_OPTS
-Dcom.sun.management.jmxremote 
-Dcom.sun.management.jmxremote.port=12345  
-Dcom.sun.management.jmxremote.authenticate=false 
-Dcom.sun.management.jmxremote.ssl=false 
-Djava.rmi.server.hostname=10.0.0.17"
```

​         重启服务，检查12345端口是否开启

```
/application/tomcat8_1/bin/shutdown.sh 
/application/tomcat8_1/bin/startup.sh 
netstat -tunlp|grep 12345
```

​         检查端口

```
[root@web03 ~]# netstat -tunlp|grep 12345
tcp6       0      0 :::12345           :::*          LISTEN      33158/java  
```

**在windows****上监控tomcat**

**注意：windwos****需要安装jdk****环境！**

查考：http://www.oracle.com/technetwork/java/javase/downloads/index.html

​         软件路径

```
C:\Program Files\Java\jdk1.8.0_31\bin
jconsole.exe   jvisualvm.exe
```

**jconsole.exe** **使用说明**

![img](assets/1190037-20171127162727784-599308853.png)

​         连接成功即可进行监控，连接的时候注意端口信息。

![img](assets/1190037-20171127162738565-738384915.png)

**jvisualvm.exe****使用说明**

![img](assets/1190037-20171127162750784-48883054.png)

​         输入ip地址

![img](assets/1190037-20171127162759081-1663450024.png)

​         主机添加完成，添加JMX监控

![img](assets/1190037-20171127162808253-922440046.png)

​                  注意添加的时候输入端口信息。

![img](assets/1190037-20171127162819378-1066040054.png)

​         添加完成后就能够多tomcat程序进行监控。

##### 4、zabbix监控tomcat程序

zabbix搭建详情参考：*http://www.cnblogs.com/clsn/p/7885990.html*

**服务端安装配置java****监控服务**

```
[root@m01 ~]# yum install zabbix-java-gateway -y
```

**查看配置文件**

```
配置文件路径：/etc/zabbix/zabbix_java_gateway.conf
sed -i -e '220a JavaGateway=127.0.0.1' -e '236a StartJavaPollers=5'  /etc/zabbix/zabbix_server.conf
```

启动zabbix-java-gateway服务，与zabbix服务

```
systemctl start zabbix-java-gateway.service
systemctl restart zabbix-server.service
```

检查java端口是否开启

```
[root@m01 ~]# netstat -lntup |grep java
tcp6       0      0 :::10052   :::*    LISTEN      72971/java  
```

​         检查java进程是否存在

```
[root@m01 ~]# ps -ef |grep [j]ava
zabbix    72971      1  0 11:29 ?        00:00:00 java -server -Dlogback.configurationFile=/etc/zabbix/zabbix_java_gateway_logback.xml -classpath lib:lib/android-json-4.3_r3.1.jar:lib/logback-classic-0.9.27.jar:lib/logback-core-0.9.27.jar:lib/slf4j-api-1.6.1.jar:bin/zabbix-java-gateway-3.0.13.jar -Dzabbix.pidFile=/var/run/zabbix/zabbix_java.pid -Dzabbix.timeout=3 -Dsun.rmi.transport.tcp.responseTimeout=3000 com.zabbix.gateway.JavaGateway
zabbix    73255  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #1 [got 0 values in 0.000002 sec, idle 5 sec]
zabbix    73256  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #2 [got 0 values in 0.000002 sec, idle 5 sec]
zabbix    73257  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #3 [got 0 values in 0.000002 sec, idle 5 sec]
zabbix    73258  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #4 [got 0 values in 0.000002 sec, idle 5 sec]
zabbix    73259  73226  0 11:35 ?        00:00:00 /usr/sbin/zabbix_server: java poller #5 [got 0 values in 0.000004 sec, idle 5 sec]
```

**web****界面添加**

​         添加主机

![img](assets/1190037-20171127163059878-505035611.png) 

​         主机管理模板，注意是JMX模板

 ![img](assets/1190037-20171127163107737-761922553.png)

​         监控完成

![img](assets/1190037-20171127163113909-1086285598.png) 

##### 5、排除tomcat故障步骤

a. 查看catalina.out

b. 使用sh show-busy-java-threads.sh脚本进行检测

脚本下载地址

*https://files.cnblogs.com/files/clsn/show-busy-java-threads.sh*

#### 10、Tomcat安全优化

##### 1、telnet管理端口保护（强制）

| **类别**           | **配置内容及说明**                                           | **标准配置**                                      | **备注**                                                     |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------- | ------------------------------------------------------------ |
| telnet管理端口保护 | 1.修改默认的8005管理端口为不易猜测的端口（大于1024）；2.修改SHUTDOWN指令为其他字符串； | <Server port="**8527**" shutdown="**dangerous**"> | 1.以上配置项的配置内容只是建议配置，可以按照服务实际情况进行合理配置，但要求端口配置在**8000~8999**之间； |

##### 2、 ajp连接端口保护（推荐）

| **类别**         | **配置内容及说明**                                           | **标准配置**                                    | **备注**                                                     |
| ---------------- | ------------------------------------------------------------ | ----------------------------------------------- | ------------------------------------------------------------ |
| Ajp 连接端口保护 | 1.修改默认的ajp 8009端口为不易冲突的大于1024端口；2.通过iptables规则限制ajp端口访问的权限仅为线上机器； | <Connector port="**8528**"protocol="AJP/1.3" /> | 以上配置项的配置内容仅为建议配置，请按照服务实际情况进行合理配置，但要求端口配置在**8000~8999**之间；；保护此端口的目的在于防止线下的测试流量被mod_jk转发至线上tomcat服务器； |

##### 3、禁用管理端（强制）

| **类别**   | **配置内容及说明**                                           | **标准配置**                                                 | **备注**                                                     |
| ---------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 禁用管理端 | 1. 删除默认的{Tomcat安装目录}/conf/tomcat-users.xml文件，重启tomcat后将会自动生成新的文件；2. 删除{Tomcat安装目录}/webapps下默认的所有目录和文件；3.将tomcat 应用根目录配置为tomcat安装目录以外的目录； | <Context path="" docBase="**/home/work/local/tomcat****_webapps**"debug="0"reloadable="false"crossContext="true"/> | 对于前段web模块，Tomcat管理端属于tomcat的高危安全隐患，一旦被攻破，黑客通过上传web shell的方式将会直接取得服务器的控制权，后果极其严重； |

##### 4、降权启动（强制）

| **类别** | **配置内容及说明**                                           | **标准配置** | **备注**                                                     |
| -------- | ------------------------------------------------------------ | ------------ | ------------------------------------------------------------ |
| 降权启动 | 1.tomcat启动用户权限必须为非root权限，尽量降低tomcat启动用户的目录访问权限；2.如需直接对外使用80端口，可通过普通账号启动后，配置iptables规则进行转发； |              | 避免一旦tomcat 服务被入侵，黑客直接获取高级用户权限危害整个server的安全； |

```
[root@web03 ~]# useradd tomcat
[root@web03 ~]# cp -a /application/tools/tomcat8_1 /home/tomcat/
[root@web03 ~]# chown -R tomcat.tomcat /home/tomcat/tomcat8_1/
[root@web03 ~]# su -c '/home/tomcat/tomcat8_1/bin/startup.sh' tomcat
Using CATALINA_BASE:   /home/tomcat/tomcat8_1
Using CATALINA_HOME:   /home/tomcat/tomcat8_1
Using CATALINA_TMPDIR: /home/tomcat/tomcat8_1/temp
Using JRE_HOME:        /application/jdk
Using CLASSPATH:       /home/tomcat/tomcat8_1/bin/bootstrap.jar:/home/tomcat/tomcat8_1/bin/tomcat-juli.jar
Tomcat started.
[root@web03 ~]# ps -ef|grep tomcat
```

##### 5、文件列表访问控制（强制）

| **类别**         | **配置内容及说明**                                         | **标准配置**                                                 | **备注**                                             |
| ---------------- | ---------------------------------------------------------- | ------------------------------------------------------------ | ---------------------------------------------------- |
| 文件列表访问控制 | 1.conf/web.xml文件中default部分listings的配置必须为false； | <init-param><param-name>**listings**</param-name><param-value>**false**</param-value></init-param> | false为不列出目录文件，true为允许列出，默认为false； |

##### 6、版本信息隐藏（强制）

| **类别**     | **配置内容及说明**                                           | **标准配置**                                                 | **备注**                                                     |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 版本信息隐藏 | 1.修改conf/web.xml，重定向403、404以及500等错误到指定的错误页面；2.也可以通过修改应用程序目录下的WEB-INF/web.xml下的配置进行错误页面的重定向； | <error-page><error-code>**403**</error-code><location>**/forbidden.jsp**</location></error-page><error-page><error-code>**404**</error-code><location>**/notfound.jsp**</location></error-page><error-page><error-code>**500**</error-code><location>**/systembusy.jsp**</location></error-page> | 在配置中对一些常见错误进行重定向，避免当出现错误时tomcat默认显示的错误页面暴露服务器和版本信息；必须确保程序根目录下的错误页面已经存在； |

##### 7、Server header重写（推荐）

| **类别**          | **配置内容及说明**                       | **标准配置**           | **备注**                                                     |
| ----------------- | ---------------------------------------- | ---------------------- | ------------------------------------------------------------ |
| Server header重写 | 在HTTP Connector配置中加入server的配置； | server="**webserver**" | 当tomcat HTTP端口直接提供web服务时此配置生效，加入此配置，将会替换http 响应Server header部分的默认配置，默认是`Apache-Coyote/1.1` |

##### 8、访问限制（可选）

| **类别** | **配置内容及说明**         | **标准配置或操作**                                           | **备注**                                                     |
| -------- | -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 访问限制 | 通过配置，限定访问的ip来源 | <Context path="" docBase="/home/work/tomcat" debug="0" reloadable="false" crossContext="true"><Valve className="org.apache.catalina.valves.RemoteAddrValve" **allow="61.148.18.138,61.135.165.\*" deny="\*.\*.\*.\*"**/></Context> | 通过配置信任ip的白名单，拒绝非白名单ip的访问，此配置主要是针对高保密级别的系统，一般产品线不需要； |

##### 9、起停脚本权限回收（推荐）

| **类别**         | **配置内容及说明**                                           | **标准配置或操作**        | **备注**                             |
| ---------------- | ------------------------------------------------------------ | ------------------------- | ------------------------------------ |
| 起停脚本权限回收 | 去除其他用户对Tomcat的bin目录下shutdown.sh、startup.sh、catalina.sh的可执行权限； | chmod -R 744 tomcat/bin/* | 防止其他用户有起停线上Tomcat的权限； |

##### 10、 访问日志格式规范（推荐）

| **类别**         | **配置内容及说明**                                | **标准配置或操作**                                           | **备注**                                                     |
| ---------------- | ------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 访问日志格式规范 | 开启Tomcat默认访问日志中的Referer和User-Agent记录 | <Valve className="org.apache.catalina.valves.AccessLogValve"                 directory="logs"  prefix="localhost_access_log." suffix=".txt"                 pattern="%h %l %u %t %r %s %b %{Referer}i %{User-Agent}i %D" resolveHosts="false"/> | 开启Referer和User-Agent是为了一旦出现安全问题能够更好的根据日志进行问题排查； |

##### 11、 附录：建议配置及标准执行方案

**1.**       **配置部分（****${ CATALINA_HOME }conf/server.xml****）**

```
<Server port="8527" shutdown=" dangerous">

<!-- Define a non-SSL HTTP/1.1 Connector on port 8080 -->
<Connector port="8080" server="webserver"/> 

<!-- Define an AJP 1.3 Connector on port 8528 -->
<!--Define an accesslog --> 
<Valve className="org.apache.catalina.valves.AccessLogValve"
                 directory="logs"  prefix="localhost_access_log." suffix=".txt"
                 pattern="%h %l %u %t %r %s %b %{Referer}i %{User-Agent}i %D" resolveHosts="false"/>

    <Connector port="8528" protocol="AJP/1.3" />

<Context path="" docBase="/home/work/local/tomcat_webapps" debug="0" reloadable="false" crossContext="true"/>
```

 

**2.**       **配置部分（****${ CATALINA_HOME }conf/web.xml****或者****WEB-INF/web.xml****）**

```
<init-param>
    <param-name>listings</param-name>
    <param-value>false</param-value>
</init-param>

<error-page>
    <error-code>403</error-code>
    <location>/forbidden.jsp</location>
</error-page>
<error-page>
    <error-code>404</error-code>
    <location>/notfound.jsp</location>
</error-page>
<error-page>
    <error-code>500</error-code>
    <location>/systembusy.jsp</location>
</error-page>
```

**3.**       **删除如下****tomcat****的默认目录和默认文件**

```
tomcat/webapps/*
tomcat/conf/tomcat-user.xml
```

**4.**       **去除其他用户对****tomcat** **起停脚本的执行权限**

```
chmod 744 –R tomcat/bin/*
```

#### 11、Tomcat性能优化

tomcat性能取决于 内存大小

**上策：优化代码**

   该项需要开发经验足够丰富，对开发人员要求较高

**中策：jvm****优化机制** **垃圾回收机制** **把不需要的内存回收**

​                  优化jvm--优化垃圾回收策略

优化catalina.sh配置文件。在catalina.sh配置文件中添加以下代码

```
# tomcat分配1G内存模板
JAVA_OPTS="-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms1024m -Xmx1024m -XX:NewSize=512m -XX:MaxNewSize=512m -XX:PermSize=512m -XX:MaxPermSize=512m"        

JAVA_OPTS="-Djava.awt.headless=true -Dfile.encoding=UTF-8 -server -Xms800m -Xmx800m -XX:NewSize=400m -XX:MaxNewSize=400m -XX:PermSize=400m -XX:MaxPermSize=400m"    
# 重启服务
su -c '/home/tomcat/tomcat8_1/bin/shutdown.sh' tomcat
su -c '/home/tomcat/tomcat8_1/bin/startup.sh' tomcat
```

​         **修改之前**

![img](assets/1190037-20171127163243831-313808608.png)

​         **修改之后**

![img](assets/1190037-20171127163252128-1901433795.png)

**下策：加足够大的内存**

该项的资金投入较大

**下下策：每天0****点定时重启tomcat**

使用较为广泛

## 五、负载均衡集群

### 1、集群是什么？

① 集群（cluster）技术是一种较新的技术，通过集群技术，可以在付出较低成本的情况下获得在性能、可靠性、灵活性方面的相对较高的收益，其任务调度则是集群系统中的核心技术。

② 集群是一组相互独立的、通过高速网络互联的计算机，它们构成了一个组，并以单一系统的模式加以管理。一个客户与集群相互作用时，集群像是一个独立的服务器。

③ 集群组成后，可以利用多个计算机和组合进行海量请求处理（**负载均衡**），从而获得很高的处理效率，也可以用多个计算机做备份（高可用），使得任何一个机器坏了整个系统还是能正常运行。集群在目前互联网公司是必备的技术，极大提高互联网业务的可用性和可缩放性。

### 2、负载均衡集群技术

① 负载均衡（Load Balance）：负载均衡集群为企业需求提供了可解决容量问题的有效方案。负载均衡集群使负载可以在计算机集群中尽可能平均地分摊处理。

② 负载通常包括应用程序处理负载和网络流量负载。这样的系统非常适合向使用同一组应用程序的大量用户提供服务。每个节点都可以承担一定的处理负载，并且可以实现处理负载在节点之间的动态分配，以实现负载均衡。对于网络流量负载,当网络服务程序接受了高入网流量，以致无法迅速处理，这时，网络流量就会发送给在其它节点上运行的网络服务程序。也可根据服务器的承载能力，进行服务请求的分发，从而使用户的请求得到更快速的处理。

### 3、负载均衡集群技术的实现

负载均衡（Load Balance）

负载均衡技术类型：基于 4 层负载均衡技术和基于 7 层负载均衡技术

负载均衡实现方式：硬件负载均衡设备或者软件负载均衡

硬件负载均衡产品：**F5** BIG-IP 、Citrix Netscaler  、深信服 、Array 、Radware

软件负载均衡产品： **LVS**（Linux Virtual Server）、 Haproxy、Nginx、Ats（apache traffic server）

### 4、实现效果如图

![img](assets/1216496-20171104195646201-164801771.png)

### 5、负载均衡分类

负载均衡根据所采用的设备对象（**软/硬件负载均衡**），应用的OSI网络层次（**网络层次上的负载均衡**），及应用的地理结构（**本地/全局负载均衡**）等来分类。本文着重介绍的是根据应用的 OSI 网络层次来分类的两个负载均衡类型。

我们先来看一张图，相信很多同学对这张图都不陌生，这是一张网络模型图，包含了 OSI 模型及 TCP/IP 模型，两个模型虽然有一点点区别，但主要的目的是一样的，模型图描述了通信是怎么进行的。它解决了实现有效通信所需要的所有过程，并将这些过程划分为逻辑上的层。层可以简单地理解成数据通信需要的步骤。



![img](assets/6278284-13b2288a7eb059f8.webp)

OSI_TCP/IP

**根据负载均衡所作用在 OSI 模型的位置不同，负载均衡可以大概分为以下几类：**

- **二层负载均衡（mac）**

  根据OSI模型分的二层负载，一般是用虚拟mac地址方式，外部对虚拟MAC地址请求，负载均衡接收后分配后端实际的MAC地址响应。

- **三层负载均衡（ip）**

  一般采用虚拟IP地址方式，外部对虚拟的ip地址请求，负载均衡接收后分配后端实际的IP地址响应。

- **四层负载均衡（tcp）**

  在三层负载均衡的基础上，用ip+port接收请求，再转发到对应的机器。

- **七层负载均衡（http）**

  根据虚拟的url或IP，主机名接收请求，再转向相应的处理服务器。

在实际应用中，比较常见的就是四层负载及七层负载。这里也重点说下这两种负载。

### 6、四层负载均衡（基于IP+端口的负载均衡）

所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。



layer4

1. 在三层负载均衡的基础上，通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。
2. 以常见的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN 请求时，即通过上述方式选择一个最佳的服务器，并对报文中目标IP地址进行修改(改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发报文的同时可能还会对报文原来的源地址进行修改。
3. 对应的负载均衡器称为四层交换机（L4 switch），主要分析IP层及TCP/UDP层，实现四层负载均衡。此种负载均衡器不理解应用协议（如HTTP/FTP/MySQL等等）
   要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续这个连接的所有流量都同样转发到同一台服务器处理。
4. 实现四层负载均衡的软件有：
   - F5：硬件负载均衡器，功能很好，但是成本很高。
   - lvs：重量级的四层负载软件
   - nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活
   - haproxy：模拟四层转发，较灵活

### 7、七层的负载均衡（基于虚拟的URL或主机IP的负载均衡)

所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。



layer7

1. 在四层负载均衡的基础上（没有四层是绝对不可能有七层的），再考虑应用层的特征，比如同一个Web服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。举个例子，如果你的Web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。
2. 以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接(三次握手)后，才可能接受到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。负载均衡设备在这种情况下，更类似于一个**代理服务器**。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。
3. 对应的负载均衡器称为七层交换机（L7 switch），除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息，实现七层负载均衡。此种负载均衡器能理解应用协议。
4. 实现七层负载均衡的软件有：
   - haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
   - nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
   - apache：功能较差
   - Mysql proxy：功能尚可。

### 8、四层负载与七层负载的区别

举个例子形象的说明：四层负载均衡就像银行的自助排号机，每一个达到银行的客户根据排号机的顺序，选择对应的窗口接受服务；而七层负载均衡像银行大堂经理，先确认客户需要办理的业务，再安排排号。这样办理理财、存取款等业务的客户，会根据银行内部资源得到统一协调处理，加快客户业务办理流程。

```
|          | 四层负载均衡（layer 4）   | 七层负载均衡（layer 7）                         |
+----------+-------------------------+----------------------------------------------+
| 基于      | 基于IP+Port的           | 基于虚拟的URL或主机IP等。                        |
+----------+-------------------------+----------------------------------------------+
| 类似于    | 路由器                   | 代理服务器                                     |
+----------+-------------------------+----------------------------------------------+
| 握手次数  | 1 次                     | 2 次                                         |
+----------+-------------------------+---------------------------------------------+
| 复杂度    | 低                      | 高                                           |
+----------+-------------------------+----------------------------------------------+
| 性能     | 高；无需解析内容           | 中；需要算法识别 URL，Cookie 和 HTTP head 等信息 |
+----------+-------------------------+----------------------------------------------+
| 安全性   | 低，无法识别 DDoS等攻击     | 高， 可以防御SYN cookie以SYN flood等           |
+----------+-------------------------+----------------------------------------------+
| 额外功能  | 无                       | 会话保持，图片压缩，防盗链等                     |
```

总结：从上面的对比看来四层负载与七层负载最大的区别就是效率与功能的区别。四层负载架构设计比较简单，无需解析具体的消息内容，在网络吞吐量及处理能力上会相对比较高，而七层负载均衡的优势则体现在功能多，控制灵活强大。在具体业务架构设计时，使用七层负载或者四层负载还得根据具体的情况综合考虑。

### 9、LVS 实现四层负载均衡项目实战

#### 1、LVS 介绍

（1）LVS 是` Linux Virtual Server`的简称，也就是 Linux 虚拟服务器, 是一个由章文嵩博士发起的自由软件项目，它的官方站点是**www.linuxvirtualserver.org。**现在LVS已经是 Linux标准内核的一部分，在Linux2.4内核以前，使用LVS时必须要重新编译内核以支持LVS功能模块，但是从Linux2.4内核以后，已经完全内置了LVS的各个功能模块，无需给内核打任何补丁，可以直接使用LVS提供的各种功能。

（2）LVS自从1998年开始，发展到现在已经是一个比较成熟的技术项目了。可以利用LVS技术实现高可伸缩的、高可用的网络服务，例如WWW服务、Cache服务、DNS服务、FTP服务、MAIL服务、视频/音频点播服务等等，有许多比较著名网站和组织都在使用LVS架设的集群系统，例如：Linux的门户网站（www.linux.com）、向RealPlayer提供音频视频服务而闻名的Real公司（www.real.com）、全球最大的开源网站（sourceforge.net）等。

**（3）LVS软件作用：通过LVS提供的负载均衡技术和Linux操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。**

#### 2、LVS 优势与不足

##### 1、优势

**高并发连接**：LVS基于内核网络层面工作，有超强的承载能力和并发处理能力。单台LVS负载均衡器，可支持上万并发连接。

**稳定性强：**是工作在网络4层之上仅作分发之用，这个特点也决定了它在负载均衡软件里的性能最强，稳定性最好，对内存和cpu资源消耗极低。

**成本低廉：**硬件负载均衡器少则十几万，多则几十万上百万，LVS只需一台服务器和就能免费部署使用，性价比极高。

**配置简单：**LVS配置非常简单，仅需几行命令即可完成配置，也可写成脚本进行管理。

**支持多种算法：**支持多种论调算法，可根据业务场景灵活调配进行使用

**支持多种工作模型：**可根据业务场景，使用不同的工作模式来解决生产环境请求处理问题。

应用范围广：因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、DNS、ftp服务等等

##### 2、不足

工作在4层，不支持7层规则修改，机制过于庞大，不适合小规模应用。

#### 3、LVS 核心组件和专业术语

##### 1、核心组件

LVS的管理工具和内核模块 ipvsadm/ipvs

ipvsadm：用户空间的命令行工具，用于管理集群服务及集群服务上的RS等；

ipvs：工作于内核上的netfilter INPUT钩子之上的程序，可根据用户定义的集群实现请求转发；

##### 2、专业术语

**VS**：Virtual Server            #虚拟服务

**Director, Balancer**          #负载均衡器、分发器

**RS**：Real Server                #后端请求处理服务器 

**CIP**: Client IP                      #用户端IP

**VIP**：Director Virtual IP   #负载均衡器虚拟IP

**DIP**：Director IP               #负载均衡器IP

**RIP**：Real Server IP         #后端请求处理服务器IP

##### 3、具体图解

![img](assets/1216496-20171104195646779-1808181772.png)

#### 4、LVS工作内核模型及工作模式

① 当客户端的请求到达负载均衡器的内核空间时，首先会到达 PREROUTING 链。

② 当内核发现请求数据包的目的地址是本机时，将数据包送往 INPUT 链。

③ LVS由用户空间的ipvsadm和内核空间的IPVS组成，ipvsadm用来定义规则，IPVS利用ipvsadm定义的规则工作，IPVS工作在INPUT链上,当数据包到达INPUT链时，首先会被IPVS检查，如果数据包里面的目的地址及端口没有在规则里面，那么这条数据包将被放行至用户空间。

④ 如果数据包里面的目的地址及端口在规则里面，那么这条数据报文将被修改目的地址为事先定义好的后端服务器，并送往POSTROUTING链。

⑤ 最后经由POSTROUTING链发往后端服务器。

图解

![img](assets/1216496-20171104195647154-844173473.png)

 

#### 5、LVS负载均衡四种工作模式

##### 1、NAT工作模式

###### 1、LVS NAT 模式介绍

Virtual Server via NAT(VS-NAT):用地址翻译实现虚拟服务器｡地址转换器有能被外界访问到的合法IP地址,它修改来自专有网络的流出包的地址｡外界看起来包是来自地址转换器本身,当外界包送到转换器时,它能判断出应该将包送到内部网的哪个节点｡优点是节省IP 地址,能对内部进行伪装;缺点是效率低,因为返回给请求方的流量经过转换器｡

###### 2、LVS NAT 模式工作流程

(a). 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的 PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP

(b). PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链

(c). IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP

(d). POSTROUTING链通过选路，将数据包发送给Real Server

(e). Real Server比对发现目标为自己的IP，开始构建响应报文发回给Director Server。 此时报文的源IP为RIP，目标IP为CIP

(f). Director Server 把RS来到响应包，通过FORWORD 转发给client 在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP

###### 3、LVS NAT 模式图解

![img](assets/1216496-20171104195647435-6995388.png)

![img](assets/1216496-20171104195647763-946588891.png)

  

##### 2、DR 工作模式

###### 1、LVS DR 模式介绍

Virtual Server via Direct Routing(VS-DR):用直接路由技术实现虚拟服务器｡当参与集群的计算机和作为控制管理的计算机在**同一个网段时**可以用此方法,控制管理的计算机接收到请求包时直接送到参与集群的节点｡直接路由模式比较特别，很难说和什么方面相似，前种模式基本上都是工作在网络层上（三层），而直接路由模式则应该是工作在数据链路层上（二层）。

###### 2、LVS DR 模式工作原理 

DR和REAL SERVER都使用同一个IP对外服务。但只有DR对ARP请求进行响应，所有REAL SERVER对本身这个IP的ARP请求保持静默。也就是说，网关会把对这个服务IP的请求全部定向给DR，而DR收到数据包后根据调度算法，找出对应的 REAL SERVER，把目的MAC地址改为REAL SERVER的MAC并发给这台REAL SERVER。这时REAL SERVER收到这个数据包，则等于直接从客户端收到这个数据包无异，处理后直接返回给客户端。由于DR要对二层包头进行改换，所以DR和REAL SERVER之间必须在一个广播域，也可以简单的理解为在同一台交换机上

###### 3、LVS DR 模式工作流程

(a) 当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP

(b) PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链

(c) IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址

(d) 由于DR和RS在同一个网络中，所以是通过二层，数据链路层来传输。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至Real Server。

(e) RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文。处理完成之后，将响应报文通过lo接口传送给eth0网卡然后向外发出。 此时的源IP地址为VIP，目标IP为CIP

(f) 响应报文最终送达至客户端 

###### 4、LVS DR 模式特点

① 保证前端路由将目标地址为VIP报文统统发给Director Server，而不是RS

② RS可以使用私有地址；也可以是公网地址，如果使用公网地址，此时可以通过互联网对RIP进行直接访问

③ RS跟Director Server必须在同一个物理网络中

④ 所有的请求报文经由Director Server，但响应报文必须不能进过Director Server

⑤ 不支持地址转换，也不支持端口映射

⑥ RS可以是大多数常见的操作系统

⑦ RS的网关绝不允许指向DIP(因为我们不允许他经过director)

⑧ RS上的lo接口配置VIP的IP地址

###### 5、LVS DR 模式工作流程图解

![img](assets/1216496-20171104195648091-1186638337.png)

![img](assets/1216496-20171104195648529-1556710994.png)

![img](assets/1216496-20171104195648935-525866155.png)

 

##### 3、LVS TUN 工作模式

###### 1、LVS TUN 模式介绍

用IP隧道技术实现虚拟服务器｡这种方式是在集群的节点不在同一个网段时可用的转发机制,是将IP包封装在其他网络流量中的方法｡为了安全的考虑,应该使用隧道技术中的VPN,也可使用租用专线｡ 集群所能提供的服务是基于TCP/IP的Web服务､Mail服务､News服务､DNS服务､Proxy服务器等等.

TUN模式:采用NAT技术时，由于请求和响应报文都必须经过调度器地址重写，当客户请求越来越多时，调度器的处理能力将成为瓶颈。为了解决这个问题，调度器把请求报文通过IP隧道转发至真实服务器，而真实服务器将响应直接返回给客户，所以调度器只处理请求报文。由于一般网络服务应答比请求报文大许多，采用 VS/TUN技术后，集群系统的最大吞吐量可以提高10倍

###### 2、LVS TUN 模式工作流程

(a) 客户端将请求发往前端的负载均衡器，请求报文源地址是CIP，目标地址为VIP。

(b) 负载均衡器收到报文后，发现请求的是在规则里面存在的地址，那么它将在客户端请求报文的首部再封装一层IP报文,将源地址改为DIP，目标地址改为RIP,并将此包发送给RS。

(c) RS收到请求报文后，会首先拆开第一层封装,然后发现里面还有一层IP首部的目标地址是自己lo接口上的VIP，所以会处理次请求报文，并将响应报文**通过lo接口送给eth0网卡直接发送给客户端**。注意：需要设置lo接口的VIP不能在共网上出现 

###### 3、LVS TUN 模式图解

![img](assets/1216496-20171104195649248-1705324201.png)

![img](assets/1216496-20171104195649607-540503453.png)

 

##### 4、LVS full-nat 工作模式

vlvs-fullnat（双向转换）

通过请求报文的源地址为DIP，目标为RIP来实现转发：对于响应报文而言，修改源地址为VIP，目标地址为CIP来实现转发：

​          CIP --> DIP           VIP --> RIP

架构特点：这是一种对nat模型的改进，是一个扩展，使得RS与Director可以处于不同网络。

（1）RIP，DIP可以使用私有地址；

（2）RIP和DIP可以不再同一个网络中，且RIP的网关未必需要指向DIP；

（3）支持端口映射；

（4）RS的OS可以使用任意类型；

（5）请求报文经由Director，响应报文也经由Director

 

![img](assets/1216496-20171104195649951-2027809396.png)

 

##### 5、四者的区别

| 机器名称   | IP配置                             | 服务角色   | 备注                               |
| ---------- | ---------------------------------- | ---------- | ---------------------------------- |
| lvs-server | VIP:172.16.100.1 DIP:192.168.100.1 | 负载均衡器 | 开启路由功能（VIP桥接、DIP仅主机） |
| rs01       | RIP：192.168.100.2                 | 后端服务器 | 网关指向DIP（仅主机）              |
| rs02       | RIP：192.168.100.3                 | 后端服务器 | 网关指向DIP（仅主机）              |
| rs03       | RIP：192.168.100.4                 | 后端服务器 | 网关指向DIP（仅主机）              |


lvs-nat与lvs-fullnat：请求和响应报文都经由Director

   　　lvs-nat：RIP的网关要指向DIP

  　　 lvs-fullnat：RIP和DIP未必在同一IP网络，但要能通信

lvs-dr与lvs-tun：请求报文要经由Director，但响应报文由RS直接发往Client

  　　 lvs-dr：通过封装新的MAC首部实现，通过MAC网络转发

  　　 lvs-tun：通过在原IP报文外封装新IP头实现转发，支持远距离通信 

#### 6、LVS ipvsadm 命令的使用

##### 1、LVS-server安装lvs管理软件

```shell
yum -y install ipvsadm
```

程序包：ipvsadm（LVS管理工具）

Unit File: ipvsadm.service

主程序：/usr/sbin/ipvsadm

规则保存工具：/usr/sbin/ipvsadm-save

规则重载工具：/usr/sbin/ipvsadm-restore

配置文件：/etc/sysconfig/ipvsadm-config

##### 2、命令选项

```shell
-A --add-service #在服务器列表中新添加一条新的虚拟服务器记录
-t #表示为tcp服务
-u #表示为udp服务
-s --scheduler #使用的调度算法， rr | wrr | lc | wlc | lblb | lblcr | dh | sh | sed | nq 默认调度算法是 wlc
例：ipvsadm -A -t 192.168.1.2:80 -s wrr

-a --add-server  #在服务器表中添加一条新的真实主机记录
-t --tcp-service #说明虚拟服务器提供tcp服务
-u --udp-service #说明虚拟服务器提供udp服务
-r --real-server #真实服务器地址
-m --masquerading #指定LVS工作模式为NAT模式
-w --weight #真实服务器的权值
-g --gatewaying #指定LVS工作模式为直接路由器模式（也是LVS默认的模式）
-i --ip #指定LVS的工作模式为隧道模式
-p #会话保持时间，定义流量呗转到同一个realserver的会话存留时间
例：ipvsadm -a -t 192.168.1.2:80 -r 192.168.2.10:80 -m -w 1

-E -edit-service #编辑内核虚拟服务器表中的一条虚拟服务器记录。
-D -delete-service #删除内核虚拟服务器表中的一条虚拟服务器记录。
-C -clear #清除内核虚拟服务器表中的所有记录。
-R -restore #恢复虚拟服务器规则
-S -save #保存虚拟服务器规则，输出为-R 选项可读的格式
-e -edit-server #编辑一条虚拟服务器记录中的某条真实服务器记录
-d -delete-server #删除一条虚拟服务器记录中的某条真实服务器记录
-L|-l –list #显示内核虚拟服务器表

--numeric, -n：#以数字形式输出地址和端口号
--exact： #扩展信息，精确值 
--connection，-c： #当前IPVS连接输出
--stats： #统计信息
--rate ： #输出速率信息

参数也可以从/proc/net/ip_vs*映射文件中查看
-Z –zero #虚拟服务表计数器清零（清空当前的连接数量等）
```

#### 7、实现LVS持久连接

##### 1、定义

由于HTTP是一种无状态协议，每次请求完毕之后就立即断开了，当用户浏览购物网站挑选商品的时候，看到一件商品加入购物车，此过程被重定向到了REALSERVER1上面来，当把第二件商品加入购物车又被重定向到了REALSERVER2上面，最后结账的时候在REALSERVER2上面，只有一件商品，这显然是用户无法接受的，此时就需要一种持久连接机制，来把同一用户的HTTP请求在超时时间内都重定向到同一台REALSERVER，超时时间可以自己定义，比如说2个小时，在超时时间内服务器会不断追踪用户的访问请求，把某一用户的所有请求都转发到同一台REALSERVER上面

对于电子商务网站来说，用户在挑选商品的时候使用的是80端口来浏览的，当付款的时候则是通过443的ssl加密的方式，当然当用户挑选完商品付款的时候我们当然不希望https的443跳转到另外一台REALSERVER，很显然应该是同一REALSERVER才对，这时候就要用到基于防火墙标记的持久连接，通过定义端口的姻亲关系来实现 

##### 2、功能

无论ipvs使用何种scheduler，其都能够实现在指定时间范围内始终将来自同一个ip地址的请求发往同一个RS；此功能是通过lvs持久连接模板实现，其与调度方法无关；

```shell
iptables -t mangle -A PREROUTING -d 172.16.100.100 -p tcp --dport 80 -j MARK --set-mark 99
```

\#在iptables 打上标记，把80端口标记为99

```shell
 iptables -t mangle -A PREROUTING -d 172.16.100.100-p tcp --dport 443 -j MARK --set-mark 99
```

\#在iptables打上标记，把443端口标记为99

```shell
ipvsadm -A -f 99 -s rr -p
```

在lvs上建立基于99号标记的虚拟服务

```shell
ipvsadm -a -f 99 -r 172.16.100.2 -g
```

设置后端服务地址

```shell
ipvsadm -a -f 99 -r 172.16.100.3 -g
```

#### 8、LVS 负载均衡集群企业级应用实战

实现基于LVS负载均衡集群的电商网站架构

##### 1、业务需求

随着业务的发展，网站的访问量越来越大，网站访问量已经从原来的1000QPS，变为3000QPS，网站已经不堪重负，响应缓慢，面对此场景，单纯靠单台LNMP的架构已经无法承载更多的用户访问，此时需要用负载均衡技术，对网站容量进行扩充，来解决承载的问题。

考虑解决方案？

横向：scale out 

纵向：scale up

##### 2、环境准备

###### 1、准备虚拟机

 准备 3 台纯净的虚拟机，配置至少1G内存，硬盘50G, 1台为负载均衡器（LVS-server），两台 web 服务器

###### 2、LVS-server 安装lvs管理软件

```shell
yum -y install ipvsadm
```

程序包：ipvsadm（LVS管理工具）

Unit File: ipvsadm.service

主程序：/usr/sbin/ipvsadm

规则保存工具：/usr/sbin/ipvsadm-save

规则重载工具：/usr/sbin/ipvsadm-restore

配置文件：/etc/sysconfig/ipvsadm-config

###### 2、查看内核是否支持 IPVS

```shell
grep -i -C 10 "ipvs" /boot/config-VERSION-RELEASE.x86_64  # 根据内核版本号查看
```

###### 3、清空防火墙策略，关闭selinux

 ```shell
# 清空防火墙策略
[root@server ~]#iptables -F

#查看
[root@server ~]# getenforce
Disabled
# 临时关闭
[root@server ~]#setenforce 0
# 永久关闭
vim /etc/selinux/config
将 SELINUX=enforcing 改为SELINUX=disabled 

设置后需要重启才能生效
 ```

##### 4、LVS/NAT

实验说明：

1. 虚拟机网络使用NAT模式
2. client、调度器、Real Server都使用虚拟机或使用真实服务器
3. 虚拟机上网卡使用半虚拟化驱动，如果半虚拟化驱动异常，可以使用default/rtl8139

![lvs-01](assets/lvs-01.png)

![lvs-02](assets/lvs-02.png)

###### 1、LVS/NAT网络拓朴

Client:						          CIP: 192.168.122.0/24                                        

Director：  						 eth0：VIP：192.168.122.100                                      
\----------------------------------------------------------------------------------------------------------------------------
        							      eth1：DIP：10.10.10.1                                              
				                                                                                                         
Real Server： 	RIP: 10.10.10.10	10.10.10.20    10.10.10.30                                  
                                                                                                                          
DNS Server： 	www.tianyun.com  ===> 192.168.122.100                                
\----------------------------------------------------------------------------------------------------------------------------

建议：先在Real Server安装如httpd

###### 2、LVS/NAT模式实施

1、准备工作（集群中所有主机）［可选］

```
IP, hostname, hosts, NetworkManager, iptables, firewalld, SELinux, ssh trust, ntp	
[root@tianyun ~]# cat /etc/hosts
127.0.0.1      	    localhost
10.10.10.1	    director1.tianyun.com director1
10.10.10.10	    node1.tianyun.com node1 
10.10.10.20	    node2.tianyun.com node2 
10.10.10.30	    node3.tianyun.com node3 
```

2、RS配置

配置好网站服务器，测试所有RS						        //为了看到测试效果，建议提供不同的页面

默认网关均指向Directory的DIP                                //route add default gw  dip

3、Director分发器配置

配置VIP

```
[root@tianyun ~]# ip addr add dev eth0 192.168.122.100/24							
[root@tianyun ~]# vim /etc/sysctl.conf
net.ipv4.ip_forward = 1
[root@tianyun ~]# sysctl -p								//确保打开路由转发
[root@tianyun ~]#ln -sv /usr/src/kernels/3.10..... /usr/src/linux
```

定义LVS的分发策略

```
[root@tianyun ~]# yum -y install ipvsadm		     //RHEL确保LoadBalancer仓库可用
[root@tianyun ~]# ipvsadm -A -t 192.168.122.100:80 -s rr
[root@tianyun ~]# ipvsadm -a -t 192.168.122.100:80 -r 10.10.10.10 -m //-m masquerading (NAT)
[root@tianyun ~]# ipvsadm -a -t 192.168.122.100:80 -r 10.10.10.20 -m
[root@tianyun ~]# ipvsadm -a -t 192.168.122.100:80 -r 10.10.10.30 -m
[root@tianyun ~]# service ipvsadm save
[root@tianyun ~]# ipvsadm -L
[root@tianyun ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port        Forward Weight ActiveConn InActConn
TCP  192.168.122.100:80 rr
  -> 10.10.10.10:80                 Masq        1      0          1         
  -> 10.10.10.20:80                 Masq        1      0          1         
  -> 10.10.10.30:80                 Masq        1      0          1    

[root@tianyun ~]# ipvsadm -L -n --stats			      // 显示统计信息
[root@tianyun ~]# ipvsadm -L -n --rate				//看速率
[root@tianyun ~]# ipvsadm -Ln -c					//查看LVS的连接条目
[root@tianyun ~]# watch -n.5 'ipvsadm -Ln -c'
```

4、测试

```
[root@client ~]# elinks -dump http://192.168.122.100/
[root@client ~]# ab -c 1000 -n 1000 http://192.168.122.100/
```

5、小结

```
VS/NAT模式的原理是：当Director收到Client请求时，Director将数据包的目标IP由VIP转换为选中的Real Server的RIP来实现分发，
要求RS将网关指向Director的DIP。
特点是：配置简单，所有的入站、出站数据包都经过分发器。当数据量比较大时，分发器可能会出现网络瓶颈！因而支持的RS数量少。

Director必须开启kernel ip_forward
所有RealServer默认网关指向DIP
Director使用DIP和RealServer RIP通信
[root@director1 ~]# watch -n.5 'ipvsadm -Ln -c'
Every 0.5s: ipvsadm -Ln -c                            Tue Dec 29 06:41:15 2015

IPVS connection entries
pro expire         state       source             virtual            destination
TCP 00:32  SYN_RECV    192.168.122.1:55989 192.168.122.100:80 10.10.10.10:80
TCP 00:42  SYN_RECV    192.168.122.1:55991 192.168.122.100:80 10.10.10.20:80
TCP 00:41  SYN_RECV    192.168.122.1:55990 192.168.122.100:80 10.10.10.30:80
TCP 00:29  SYN_RECV    192.168.122.1:55988 192.168.122.100:80 10.10.10.20:80
TCP 00:59  SYN_RECV    192.168.122.1:55993 192.168.122.100:80 10.10.10.30:80
TCP 00:42  SYN_RECV    192.168.122.1:55992 192.168.122.100:80 10.10.10.10:80
```

##### 2、LVS/DR 模式

实验说明：
1.KVM网络使用NAT模式
2.DR模式要求Director DIP 和 所有RealServer RIP必须在同一个网段及广播域
3.所有节点网关均指定真实网关

![lvs-01](assets/lvs-01-1553070118410.png)

![lvs-02](assets/lvs-02-1553070125105.png)

![lvs-03](assets/lvs-03.png)

注：调度器和RealServer必须在同一个LAN, LAN可以使用公网IP，也可以使用private IP
公网IP：　前端路由器工作为路由模式
私网IP：   前端路由器工作为NAT，并将某个公网IP映射到VIP（private）



###### 1、网络拓朴

Client：                                  		CIP： 192.168.122.1

Director：  				       VIP：192.168.122.100 
								DIP：192.168.122.2                                       
											
Real Server： RIP：	192.168.122.10    192.168.122.20	 192.168.122.30
			 VIP：	192.168.122.100  192.168.122.100 192.168.122.100       Nor-arp
						 
DNS Server： www.tianyun.com  ===> 192.168.122.100

###### 2、LVS/DR模式实施

1、准备工作（集群中所有主机）

```
IP, hostname, hosts, iptables, firewalld, SELinux, ssh trust, ntp	
[root@tianyun ~]# cat /etc/hosts
127.0.0.1           	    localhost
192.168.122.2	    director1.tianyun.com director1
192.168.122.10	    node1.tianyun.com node1 
192.168.122.20	    node2.tianyun.com node2 
192.168.122.30	    node3.tianyun.com node3 
```

2、RS配置

配置好网站服务器，测试所有RS												     //为了测试效果，提供不同的页面

```
[root@tianyun ~]# yum -y install httpd
[root@tianyun ~]# ip addr add dev lo 192.168.122.100/32			     //在lo接口上绑定VIP
[root@tianyun ~]# echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore	     //non-arp
[root@tianyun ~]# echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce

修改/etc/sysctl.conf文件，然后sysctl -p刷新到内存，可以在下次重启依旧生效。
 net.ipv4.conf.all.arp_ignore=1
 net.ipv4.conf.all.arp_announce=2
```

3、Director分发器配置

配置VIP

```
[root@tianyun ~]# ip addr add dev eth0 192.168.122.100/32	//配置VIP
[root@tianyun ~]# yum -y install ipvsadm				//RHEL确保LoadBalancer仓库可用
```

定义LVS分发策略

```
[root@tianyun ~]# ipvsadm -C                        // 清除内核虚拟服务器表中的所有记录
[root@tianyun ~]# ipvsadm -A -t 192.168.122.100:80 -s rr 
[root@tianyun ~]# ipvsadm -a -t 192.168.122.100:80 -r 192.168.122.10 -g	
[root@tianyun ~]# ipvsadm -a -t 192.168.122.100:80 -r 192.168.122.20 -g
[root@tianyun ~]# ipvsadm -a -t 192.168.122.100:80 -r 192.168.122.30 -g
[root@tianyun ~]# service ipvsadm save
Saving IPVS table to /etc/sysconfig/ipvsadm:               [  OK  ]
[root@tianyun ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  	-> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.122.100:80 rr
  	-> 192.168.122.10:80              Route   1      0          0
  	-> 192.168.122.20:80              Route   1      0          0
  	-> 192.168.122.30:80              Route   1      0          0

[root@tianyun ~]# ipvsadm -L -n
[root@tianyun ~]# ipvsadm -L -n --stats			// 显示统计信息
[root@tianyun ~]# ipvsadm -L -n --rate			//看速率	
[root@tianyun ~]# ipvsadm -Ln -c				//查看LVS的连接条目		
[root@tianyun ~]# watch -n.5 'ipvsadm -Ln -c'
```

###### 4、测试

```
[root@client ~]# elinks -dump http://192.168.122.100
[root@client ~]# ab -c 1000 -n 1000 http://192.168.122.100/
[root@client ~]# tcpdump -nni eth0 -e host 192.168.122.100
```

###### 5、小结

```
VS/DR模式的原理是： 当一个client发送一个请求到VIP，Director根据VIP选择对应的real-server的Pool，根据算法，在Pool中选择一台Real-server，
然后将client的请求包发给选择的Real-server，最后选择的Real-server把应答包直接传给client
```

#### 10、LVS的调度算法

LVS的调度算法分为静态与动态两类。

##### 1、静态算法（4种）

只根据算法进行调度 而不考虑后端服务器的实际连接情况和负载情况

**①.RR**：轮叫调度（Round Robin）

　 调度器通过”轮叫”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上，它均等地对待每一台服务器，而不管服务器上实际的连接数和系统负载｡

**②.WRR**：加权轮叫（Weight RR）

　 调度器通过“加权轮叫”调度算法根据真实服务器的不同处理能力来调度访问请求。这样可以保证处理能力强的服务器处理更多的访问流量。调度器可以自动问询真实服务器的负载情况,并动态地调整其权值。

**③.DH**：目标地址散列调度（Destination Hash ）

　 根据请求的目标IP地址，作为散列键(HashKey)从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。

**④.SH**：源地址 hash（Source Hash）

　 源地址散列”调度算法根据请求的源IP地址，作为散列键(HashKey)从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空｡

##### 2、动态算法（6种）

前端的调度器会根据后端真实服务器的实际连接情况来分配请求

**①.LC**：最少链接（Least Connections）

　 调度器通过”最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群系统的真实服务器具有相近的系统性能，采用”最小连接”调度算法可以较好地均衡负载。

**②.WLC**：加权最少连接(默认采用的就是这种)（Weighted Least Connections）

　 在集群系统中的服务器性能差异较大的情况下，调度器采用“加权最少链接”调度算法优化负载均衡性能，具有较高权值的服务器将承受较大比例的活动连接负载｡调度器可以自动问询真实服务器的负载情况,并动态地调整其权值。

**③.SED**：最短期望延迟调度（Shortest Expected Delay ）

　 在WLC基础上改进，Overhead =  （ACTIVE+1）*256/加权，不再考虑非活动状态，把当前处于活动状态的数目+1来实现，数目最小的，接受下次请求，+1的目的是为了考虑加权的时候，非活动连接过多缺陷：当权限过大的时候，会倒置空闲服务器一直处于无连接状态。

**④.NQ**：永不排队/最少队列调度（Never Queue Scheduling NQ）

　 无需队列。如果有台  realserver的连接数＝0就直接分配过去，不需要再进行sed运算，保证不会有一个主机很空间。在SED基础上无论+几，第二次一定给下一个，保证不会有一个主机不会很空闲着，不考虑非活动连接，才用NQ，SED要考虑活动状态连接，对于DNS的UDP不需要考虑非活动连接，而httpd的处于保持状态的服务就需要考虑非活动连接给服务器的压力。

**⑤.LBLC**：基于局部性的最少链接（locality-Based Least Connections）

　  基于局部性的最少链接”调度算法是针对目标IP地址的负载均衡，目前主要用于Cache集群系统｡该算法根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器;若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则用“最少链接”的原则选出一个可用的服务器，将请求发送到该服务器｡

**⑥. LBLCR**：带复制的基于局部性最少连接（Locality-Based Least Connections with Replication）

　   带复制的基于局部性最少链接”调度算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统｡它与LBLC算法的不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射｡该算法根据请求的目标IP地址找出该目标IP地址对应的服务器组，按”最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器｡同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。

### 10、Nginx实现七层的负载均衡项目实战

Nginx通过Upstream模块实现负载均衡

#### 1、upstream 支持的负载均衡算法

```
轮询（默认）:可以通过weight指定轮询的权重，权重越大，被调度的次数越多
ip_hash：可以实现会话保持，将同一客户的IP调度到同一样后端服务器，可以解决session的问题，不能使用weight
consistent_hash：使用一个内部一致性hash算法来选择合适的后端节点
fair：可以根据请求页面的大小和加载时间长短进行调度，使用第三方的upstream_fair模块
url_hash：按请求的url的hash进行调度，从而使每个url定向到同一服务器，使用第三方的url_hash模块
```

#### 2、upstream支持的状态参数（主要用于对后端服务器的健康检查）

```
down：			   暂停对该服务器的调度
backup:				类似于LVS Sorry Server，当所有的非backup的服务器故障
max_fails:			请求失败的次数，默认为1
fail_timeout:		在经历max_fails次失败后，暂停服务的时间
```

```
upstream tianyun.com {
#      ip_hash;
        server 192.168.122.10 weight=1 max_fails=2 fail_timeout=2;
        server 192.168.122.20  weight=2 max_fails=2 fail_timeout=2;
        server 192.168.122.30 max_fails=2 fail_timeout=5 down;
        server 192.168.122.200 backup;
    }

注：当使用ip_hash时，服务器状态不可使用weight
```

#### 3、Nginx实现七层的负载均衡(同类服务)

```
调度到同一组后端服务器 
网站没按业务/版块拆分，所有后端服务器提供整站代码。
=================================================================================

拓扑结构

							[LB Nginx]
							20.20.20.20
							192.168.1.2

		[httpd]			[httpd]			[httpd]
		192.168.1.3	    192.168.1.4	    192.168.1.5

实施过程
1. nginx
http {
    upstream httpservers {
        server 192.168.1.3:80 weight=1 max_fails=2 fail_timeout=2;
        server 192.168.1.4:80 weight=2 max_fails=2 fail_timeout=2;
        server 192.168.1.5:80 weight=2 max_fails=2 fail_timeout=2;
        server 192.168.1.100:80 backup;
    }

    server {
      		location  / {
                proxy_pass  http://httpservers;
                proxy_set_header X-Real-IP $remote_addr;
      		}
     } 		     		
 }
 
2. Apache LogFormat 可选
LogFormat "%{X-Real-IP}i %l %u %t \"%r\" %>s %b \"%{Referer}i\" \"%{User-Agent}i\"" combined
LogFormat "%h %l %u %t \"%r\" %>s %b" common
LogFormat "%{Referer}i -> %U" referer
LogFormat "%{User-agent}i" agent

3. Nginx LogFormat

=================================================================================
```

###### 4、Nginx实现七层的负载均衡（不同类服务）

```
调度到不同组后端服务器
网站分区进行调度
=================================================================================

拓扑结构

							[vip: 20.20.20.20]

						[LB1 Nginx]		[LB2 Nginx]
					    192.168.1.2		192.168.1.3

		[index]		[milis]		 [videos]	   [images]  	  [news]
		 1.11		 1.21		   1.31			  1.41		   1.51
		 1.12		 1.22		   1.32			  1.42		   1.52
		 1.13		 1.23		   1.33			  1.43		   1.53
		 ...		 ...		    ...			  ...		    ...
		 /web     /web/milis    /web/videos     /web/images   /web/news
	  index.html  index.html     index.html      index.html   index.html

一、实施过程 
根据站点分区进行调度
http {
    upstream index {
        server 192.168.1.11:80 weight=1 max_fails=2 fail_timeout=2;
        server 192.168.1.12:80 weight=2 max_fails=2 fail_timeout=2;
        server 192.168.1.13:80 weight=2 max_fails=2 fail_timeout=2;
       }
       
    upstream milis {
        server 192.168.1.21:80 weight=1 max_fails=2 fail_timeout=2;
        server 192.168.1.22:80 weight=2 max_fails=2 fail_timeout=2;
        server 192.168.1.23:80 weight=2 max_fails=2 fail_timeout=2;
       }
       
     upstream videos {
        server 192.168.1.31:80 weight=1 max_fails=2 fail_timeout=2;
        server 192.168.1.32:80 weight=2 max_fails=2 fail_timeout=2;
        server 192.168.1.33:80 weight=2 max_fails=2 fail_timeout=2;
       }
       
     upstream images {
        server 192.168.1.41:80 weight=1 max_fails=2 fail_timeout=2;
        server 192.168.1.42:80 weight=2 max_fails=2 fail_timeout=2;
        server 192.168.1.43:80 weight=2 max_fails=2 fail_timeout=2;
       }
       
      upstream news {
        server 192.168.1.51:80 weight=1 max_fails=2 fail_timeout=2;
        server 192.168.1.52:80 weight=2 max_fails=2 fail_timeout=2;
        server 192.168.1.53:80 weight=2 max_fails=2 fail_timeout=2;
       }
       
     server {
          	location / {
      		proxy_pass http://index;
      		}
      		
      		location  /news {
      		proxy_pass http://news;
      		}
      		
      		location /milis {
      		proxy_pass http://milis;
      		}
      		
      		location ~* \.(wmv|mp4|rmvb)$ {
      		proxy_pass http://videos;
      		}
      		
      		location ~* \.(png|gif|jpg)$ {
      		proxy_pass http://images;
      		}
}
 
二、Keepalived实现调度器HA
注：主/备调度器均能够实现正常调度
1. 主/备调度器安装软件
[root@master ~]# yum -y install keepalived 
[root@backup ~]# yum -y install keepalived

2. Keepalived
BACKUP1
[root@tianyun ~]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id director1		//辅助改为director2
}

vrrp_instance VI_1 {
    state BACKUP
    nopreempt				    
    interface eth0				//VIP绑定接口
    virtual_router_id 80		//整个集群的调度器一致
    priority 100				//辅助改为50
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        20.20.20.20
    }
}

BACKUP2


3. 启动KeepAlived（主备均启动）
[root@tianyun ~]# chkconfig keepalived on
[root@tianyun ~]# service keepalived start
[root@tianyun ~]# ip addr

到此：
可以解决心跳故障keepalived
不能解决Nginx服务故障

4. 扩展对调度器Nginx健康检查（可选）
思路：
让Keepalived以一定时间间隔执行一个外部脚本，脚本的功能是当Nginx失败，则关闭本机的Keepalived
a. script
[root@master ~]# cat /etc/keepalived/check_nginx_status.sh
#!/bin/bash												        
/usr/bin/curl -I http://localhost &>/dev/null	
if [ $? -ne 0 ];then										    
	/etc/init.d/keepalived stop					    	
fi															        	
[root@master ~]# chmod a+x /etc/keepalived/check_nginx_status.sh

b. keepalived使用script
! Configuration File for keepalived

global_defs {
   router_id director1
}

vrrp_script check_nginx {
   script "/etc/keepalived/check_nginx_status.sh"
   interval 5
}

vrrp_instance VI_1 {
    state BACKUP
    interface eth0
    nopreempt
    virtual_router_id 90
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass tianyun
    }
    
    virtual_ipaddress {
        192.168.1.80
    }

    track_script {
        check_nginx
    }
}

注：必须先启动nginx，再启动keepalived
```



### 12、Haproxy 基础（了解）

![ha-03](assets/ha-03-1553072045883.png)

#### 1、Haproxy 实现七层负载

```
Keepalived + Haproxy
=================================================================================

/etc/haproxy/haproxy.cfg
global												      //关于进程的全局参数
    log         		    127.0.0.1 local2
    chroot      		/var/lib/haproxy
    pidfile     		    /var/run/haproxy.pid
    maxconn     	4000
    user        		    haproxy
    group       	    haproxy
    daemon			

defaults、listen、frontend、backend　//关于Proxy配置段
defaults 段用于为其它配置段提供默认参数
listen是frontend和backend的结合体

frontend        虚拟服务VIrtual Server      监听器                  接受访问并调度
backend        真实服务器Real Server       Web Servers       被调度的服务器

调度器可以同时为多个站点调度，如果使用frontend、backend的方式：
frontend1 backend1
frontend2 backend2
frontend3 backend3
```

```
Keepalived + Haproxy
=================================================================================


拓扑结构

							[vip: 192.168.122.100]

						[LB1 Haproxy]		[LB2 Haproxy]
						192.168.122.2	    192.168.122.3

				  [httpd]				 [httpd]		   [httpd]
				192.168.122.10		192.168.122.20		192.168.122.30
				

一、Haproxy实施步骤				
1. 准备工作（集群中所有主机）
IP, hostname, hosts, iptables, SELinux, ssh trust, ntp	
[root@tianyun ~]# cat /etc/hosts
127.0.0.1      	localhost
192.168.122.2	director1.tianyun.com active
192.168.122.3	director2.tianyun.com backup
192.168.122.10	node1.tianyun.com node1 
192.168.122.20	node2.tianyun.com node2
192.168.122.30	node2.tianyun.com node3

2. RS配置
配置好网站服务器，测试所有RS	

3. 调度器配置Haproxy（主/备）
[root@tianyun ~]# yum -y install haproxy	
[root@tianyun ~]# cp -rf /etc/haproxy/haproxy.cfg{,.bak}
[root@tianyun ~]# sed -i -r '/^[ ]*#/d;/^$/d' /etc/haproxy/haproxy.cfg
[root@tianyun ~]# vim /etc/haproxy/haproxy.cfg
global
...
defaults
...

----------------------------配置监控[可选]------------------------------
listen stats
    bind                    	*:1314
    stats                   	enable
    stats refresh 		30s
    stats                   	hide-version
    stats uri              	/haproxystats
    stats realm         	Haproxy\ stats
    stats auth           	tianyun:123
    stats admin         if TRUE
----------------------------------------------------------------------------

frontend web
    mode                   	http
    bind                    	    *:80
    default_backend    httpservers

backend httpservers
    balance roundrobin
    server http1 192.168.122.10:80 maxconn 2000 weight 1  check inter 1s rise 2 fall 2
    server http2 192.168.122.20:80 maxconn 2000 weight 1  check inter 1s rise 2 fall 2
    server http3 192.168.122.30:80 maxconn 2000 weight 1  check inter 1s rise 2 fall 2
    
[root@tianyun ~]# service haproxy restart
[root@tianyun ~]# chkconfig haproxy on

4. 测试调度器(主/备)

```

![ha-01](assets/ha-01.png)

![ha-02](assets/ha-02.png)

```
二、Keepalived实现调度器HA
注：主/备调度器均能够实现正常调度
1. 主/备调度器安装软件
[root@master ~]# yum -y install keepalived 
[root@backup ~]# yum -y install keepalived 

2. Keepalived
Master 
[root@tianyun ~]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id director1			//辅助改为director2
}

vrrp_instance VI_1 {
    state BACKUP
    nopreempt				
    interface eth0				//心跳接口，尽量单独连接心跳
    virtual_router_id 80		//MASTER,BACKUP一致
    priority 100					//辅助改为50
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.122.100
    }
}

BACKUP

3. 启动KeepAlived（主备均启动）
[root@tianyun ~]# chkconfig keepalived on
[root@tianyun ~]# service keepalived start
[root@tianyun ~]# ip addr


4. 扩展对调度器Haproxy健康检查（可选）
思路：
让Keepalived以一定时间间隔执行一个外部脚本，脚本的功能是当Haproxy失败，则关闭本机的Keepalived
a. script
[root@master ~]# cat /etc/keepalived/check_haproxy_status.sh
#!/bin/bash											        	
/usr/bin/curl -I http://localhost &>/dev/null	
if [ $? -ne 0 ];then									    	
	/etc/init.d/keepalived stop					    	
fi															        	
[root@master ~]# chmod a+x /etc/keepalived/check_haproxy_status.sh

b. keepalived使用script
! Configuration File for keepalived

global_defs {
   router_id director1
}

vrrp_script check_haproxy {
   script "/etc/keepalived/check_haproxy_status.sh"
   interval 5
}

vrrp_instance VI_1 {
    state BACKUP
    interface eth0
    nopreempt
    virtual_router_id 90
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass tianyun
    }
    virtual_ipaddress {
        192.168.122.100
    }

    track_script {
        check_haproxy
    }
}

=================================================================================


listen www.tianyun.com
    mode               http
    bind                *:80
    balance roundrobin
    #balance source
    server http1 192.168.122.10:80 maxconn 2000 weight 1  check inter 1s rise 2 fall 2
    server http2 192.168.122.20:80 maxconn 2000 weight 1  check inter 1s rise 2 fall 2
    server http3 192.168.122.30:80 maxconn 2000 weight 1  check inter 1s rise 2 fall 2

Haproxy Log:
[root@rhel6 ~]# tcpdump -i lo -nn port 514
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on lo, link-type EN10MB (Ethernet), capture size 65535 bytes
02:48:50.475524 IP 127.0.0.1.41350 > 127.0.0.1.514: SYSLOG local2.info, length: 176
02:48:55.479321 IP 127.0.0.1.41350 > 127.0.0.1.514: SYSLOG local2.info, length: 176
02:49:00.479946 IP 127.0.0.1.41350 > 127.0.0.1.514: SYSLOG local2.info, length: 176
02:49:05.476149 IP 127.0.0.1.41350 > 127.0.0.1.514: SYSLOG local2.info, length: 176
02:49:10.473743 IP 127.0.0.1.41350 > 127.0.0.1.514: SYSLOG local2.info, length: 176
02:49:15.481521 IP 127.0.0.1.41350 > 127.0.0.1.514: SYSLOG local2.info, length: 176

[root@rhel6 ~]# netstat -tunlp |grep :514


[root@tianyun ~]# vim /etc/sysconfig/rsyslog
SYSLOGD_OPTIONS="-c 2 -r"

[root@tianyun ~]# vim /etc/rsyslog.conf
# Provides UDP syslog reception
$ModLoad imudp
$UDPServerRun 514

# Provides TCP syslog reception
$ModLoad imtcp
$InputTCPServerRun 514

local2.*                       /var/log/haproxy.log

[root@tianyun ~]# service rsyslog restart
Shutting down system logger:                            [  OK  ]
Starting system logger:                                    [  OK  ]

[root@rhel6 ~]# netstat -tunlp |grep :514
tcp        0      0 0.0.0.0:514                 0.0.0.0:*                   LISTEN      2755/rsyslogd       
tcp        0      0 :::514                      :::*                        LISTEN      2755/rsyslogd       
udp        0      0 0.0.0.0:514                 0.0.0.0:*                               2755/rsyslogd       
udp        0      0 :::514                      :::*                                    2755/rsyslogd  

[root@rhel6 ~]# tailf /var/log/haproxy.log 
Jan 16 02:51:10 localhost haproxy[2734]: [16/Jan/2016:02:51:10.487] www.tianyun.com www.tianyun.com/http3 0/0/0/0/0 200 265 - - ---- 1/1/0/1/0 0/0 "HEAD / HTTP/1.1"
Jan 16 02:51:15 localhost haproxy[2734]: [16/Jan/2016:02:51:15.493] www.tianyun.com www.tianyun.com/http1 0/0/0/1/1 200 265 - - ---- 1/1/0/1/0 0/0 "HEAD / HTTP/1.1"
Jan 16 02:51:20 localhost haproxy[2734]: [16/Jan/2016:02:51:20.490] www.tianyun.com www.tianyun.com/http2 0/0/0/1/1 200 265 - - ---- 1/1/0/1/0 0/0 "HEAD / HTTP/1.1"



主/备调度器：
正常只有活跃的调度器发送组播
[root@tianyun ~]# tcpdump -i eth0 -nn vrrp
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on eth0, link-type EN10MB (Ethernet), capture size 65535 bytes
02:13:38.483890 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:39.484731 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:40.487664 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:41.488244 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:42.489277 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:43.490422 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:44.491214 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:45.491975 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:46.492977 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
02:13:47.494123 IP 192.168.122.56 > 224.0.0.18: VRRPv2, Advertisement, vrid 88, prio 100, authtype simple, intvl 1s, length 20
```



#### 2、Haproxy 实现四层负载

```
Haproxy L4
=================================================================================

global
    log                     127.0.0.1 local2
    chroot                /var/lib/haproxy
    pidfile                 /var/run/haproxy.pid
    maxconn            4000
    user                   haproxy
    group                 haproxy
    daemon
    
defaults
    mode                  http
    log                      global
    option                 dontlognull
    retries                 3
    maxconn             3000
    contimeout          50000
    clitimeout            50000
    srvtimeout           50000

listen stats
    bind                    *:1314
    stats                   enable
    stats                   hide-version
    stats uri               /haproxystats
    stats realm          Haproxy\ stats
    stats auth            tianyun:123
    stats admin          if TRUE

frontend web
    option                   httplog
    option                   http-server-close
    option forwardfor   except 127.0.0.0/8
   #option                  redispatch
    mode                    http
    bind                      *:80
    default_backend    httpservers

backend httpservers
    balance roundrobin
    server http1 192.168.122.10:80 check maxconn 2000
    server http2 192.168.122.20:80 check maxconn 2000
    server http3 192.168.122.30:80 check maxconn 2000

listen mysql
    bind *:3306
    mode tcp
    balance roundrobin
    server mysql1 192.168.122.40:3306 weight 1  check inter 1s rise 2 fall 2
    server mysql2 192.168.122.50:3306 weight 1  check inter 1s rise 2 fall 2
    server mysql3 192.168.122.60:3306 weight 1  check inter 1s rise 2 fall 2

=================================================================================    

```

![ha-04](assets/ha-04.png)



### 13、企业 keepalived 高可用项目实战

#### 1、Keepalived VRRP 介绍

Virtual Route Redundancy Protocol，即虚拟路由冗余协议。它主要是实现路由器高可用的容错协议。
将多台路由器组成路由器组（Router Group），组中包括Master及Backup，在外部看来就像一台路由
器，拥有一个VIP。Master会发送组播消息，当Backup在指定的时间收不到vrrp包就会认为master宕掉，
然后通过VRRP协议再次竞选新的路由器当Master，从而保证路由器的高可用。

在VRRP协议实现中，虚拟路由器使用00-00-5E-00-01-XX作为虚拟MAC地址，XX就是唯一的VRID。

#### 2、LVS_Director + KeepAlived

```
LVS_Director + KeepAlived

KeepAlived在该项目中的功能：
1. 管理IPVS的路由表（包括对RealServer做健康检查）
2. 实现调度器的HA
http://www.keepalived.org

[root@tianyun ~]# tcpdump -i eth0 -nn vrrp
注：
在主/备节点抓包，正常应该看到当前活跃的节点向224.0.0.18发送组播
如果均看到本机向224.0.0.18发送组播，则是心跳故障，可能是防火墙阻止的组播，同时建议关闭SElinux

同一个广播域中有多套Keepalived HA Cluster，它们使用的组播地址都是224.0.0.18，通过virtual_router_id区分

Keepalived所执行的外部脚本命令建议使用绝对路径
=================================================================================

项目环境： VS/DR

Client						                   192.168.122.1
 
Director分发器	主192.168.122.10	               备192.168.122.20 	    VIP    192.168.122.100


Real Server		192.168.122.30     192.168.122.40	 192.168.122.50 	 VIP lo  192.168.122.100/32


实施步骤：
1. RS配置(web1,web2)
配置好网站服务器，测试所有RS														   
[root@web1 ~]# echo "ip addr add dev lo 192.168.122.100/32" >> /etc/rc.local				
[root@web1 ~]# echo "net.ipv4.conf.all.arp_ignore = 1" >> /etc/sysctl.conf
               echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
[root@web1 ~]# sysctl -p
[root@web1 ~]# yum -y install httpd php php-mysql
[root@web1 ~]# echo "web1..." >> /var/www/html/index.html 

2. 主/备调度器安装软件
[root@lvs-master ~]# yum -y install ipvsadm keepalived 
[root@lvs-backup ~]# yum -y install ipvsadm keepalived

3. Keepalived
lvs-master
获得Real Server测试页面的MD5SUM值
[root@lvs-master ~]# genhash -s 192.168.122.30 -p 80 -u /test.html
MD5SUM = f5ac8127b3b6b85cdc13f237c6005d80

[root@lvs-master ~]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id lvs-master	            //辅助改为lvs-backup
}

vrrp_instance VI_1 {
    state BACKUP				
    nopreempt                              //不抢占
    interface eth0				            //VIP绑定接口
    mcast src ip x.x.x.x                //发送组播的源IP，心跳线网卡
    virtual_router_id 80		            //VRID 同一组集群，主备一致  虚拟路由器 MAC 00-00-5E-00-01-{VRID}
    priority 100					            //本节点优先级，辅助改为50
    advert_int 1                            //检查间隔，默认为1s
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.122.100
    }
}

virtual_server 192.168.122.100 80 {   //LVS配置，可以是fwmark 80
    delay_loop 6
    lb_algo rr                                    //LVS调度算法
    lb_kind DR                                  //LVS集群模式（路由模式）
    nat_mask 255.255.255.0
    persistence_timeout 20            //持久性连接
    protocol TCP                              //健康检查使用的协议
    sorry_server 2.2.2.2 80             //当所有real server不可用时
  
    real_server 192.168.122.30 80 {
        weight 1
        inhibit_on_failure                  //当该节点失败时，把权重设置为0，而不是从IPVS中删除
        HTTP_GET {						      //健康检查
            url {
              path /test.html
              digest f5ac8127b3b6b85cdc13f237c6005d80
            }
            connect_port 80                 //检查的端口
            connect_timeout 3            //连接超时的时间
            nb_get_retry 3                   //重新连接的次数
            delay_before_retry 2         //重连的间隔
        }
    }

    real_server 192.168.122.40 80 {
        weight 1
        inhibit_on_failure
        HTTP_GET {
            url {
              path /test.html
              digest f5ac8127b3b6b85cdc13f237c6005d80
            }
            connect_timeout 3
            nb_get_retry 3
            delay_before_retry 3
        }
     }
}

lvs-backup

5. 启动KeepAlived（主备均启动）
[root@lvs-master ~]# chkconfig keepalived on
[root@lvs-master ~]# service keepalived start
[root@lvs-master ~]# tail -f /var/log/messages

[root@tianyun ~]# ipvsadm -Ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.122.100:80 wrr
  -> 192.168.122.30:80               Route   1      0          0         
  -> 192.168.122.30:80               Route   3      0          0   


LB集群测试
所有分发器和Real Server都正常

主分发器故障及恢复

Real Server故障及恢复

```

#### 2、Haproxy_Director + Keepalived

```
Haproxy_Director + Keepalived
=================================================================================


一、Haproxy负载均衡
主/备调度器均能够实现正常调度


二、Keepalived实现调度器HA
注：主/备调度器均能够实现正常调度
1. 主/备调度器安装软件
[root@master ~]# yum -y install keepalived 
[root@backup ~]# yum -y install keepalived 

2. Keepalived
Master 
[root@tianyun ~]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id director1	    //辅助改为director2
}

vrrp_instance VI_1 {
    state BACKUP
    nopreempt				
    interface eth0				//VIP绑定接口
    virtual_router_id 80		//MASTER,BACKUP一致
    priority 100					//辅助改为50
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.122.100
    }
}

BACKUP


3. 启动KeepAlived（主备均启动）
[root@tianyun ~]# chkconfig keepalived on
[root@tianyun ~]# service keepalived start
[root@tianyun ~]# ip addr


4. 扩展对调度器Haproxy健康检查（可选）
思路：
让Keepalived以一定时间间隔执行一个外部脚本，脚本的功能是当Haproxy失败，则关闭本机的Keepalived
a. script
[root@master ~]# cat /etc/keepalived/check_haproxy_status.sh
#!/bin/bash											        	
/usr/bin/curl -I http://localhost &>/dev/null	
if [ $? -ne 0 ];then									    	
	/etc/init.d/keepalived stop					    	
fi															        	
[root@master ~]# chmod a+x /etc/keepalived/check_haproxy_status.sh

b. keepalived使用script
! Configuration File for keepalived

global_defs {
   router_id director1
}

vrrp_script check_haproxy {
   script "/etc/keepalived/check_haproxy_status.sh"
   interval 5
}

vrrp_instance VI_1 {
    state BACKUP
    interface eth0
    nopreempt
    virtual_router_id 90
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass tianyun
    }
    virtual_ipaddress {
        192.168.122.100
    }

    track_script {
        check_haproxy
    }
}

```

#### 3、Nginx_Director + Keepalived

```
Nginx_Director + Keepalived
=================================================================================


一、Nginx负载均衡
主/备调度器均能够实现正常调度


二、Keepalived实现调度器HA
1. 主/备调度器安装软件
[root@master ~]# yum -y install keepalived 
[root@backup ~]# yum -y install keepalived

2. Keepalived
BACKUP1
[root@tianyun ~]# vim /etc/keepalived/keepalived.conf
! Configuration File for keepalived

global_defs {
   router_id director1		//辅助改为director2
}

vrrp_instance VI_1 {
    state BACKUP
    nopreempt				    
    interface eth0				//VIP绑定接口
    virtual_router_id 80		//整个集群的调度器一致
    priority 100					//辅助改为50
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.1.80
    }
}

BACKUP2


3. 启动KeepAlived（主备均启动）
[root@tianyun ~]# chkconfig keepalived on
[root@tianyun ~]# service keepalived start
[root@tianyun ~]# ip addr

到此：
可以解决心跳故障  keepalived
不能解决Nginx服务故障

4. 扩展对调度器Nginx健康检查（可选）
思路：
让Keepalived以一定时间间隔执行一个外部脚本，脚本的功能是当Nginx失败，则关闭本机的Keepalived
a. script
[root@master ~]# cat /etc/keepalived/check_nginx_status.sh
#!/bin/bash											        	
/usr/bin/curl -I http://localhost &>/dev/null	
if [ $? -ne 0 ];then									    	
	/etc/init.d/keepalived stop					    	
fi															        	
[root@master ~]# chmod a+x /etc/keepalived/check_nginx_status.sh

b. keepalived使用script
! Configuration File for keepalived

global_defs {
   router_id director1
}

vrrp_script check_nginx {
   script "/etc/keepalived/check_nginx_status.sh"
   interval 5
}

vrrp_instance VI_1 {
    state BACKUP
    interface eth0
    nopreempt
    virtual_router_id 90
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass tianyun
    }
    
    virtual_ipaddress {
        192.168.1.80
    }

    track_script {
        check_nginx
    }
}

注：必须先启动nginx，再启动keepalived
```

#### 4、MySQL+Keepalived

```
Keepalived+mysql 自动切换

项目环境：
VIP 192.168.122.100
mysql1 192.168.122.10
mysql2 192.168.122.20
 
一、mysql 主主同步        （不使用共享存储，数据保存本地存储）
二、安装keepalived 
三、keepalived 主备配置文件
四、mysql状态检测脚本/root/bin/keepalived_check_mysql.sh
五、测试及诊断
注 keepalived之间使用vrrp组播方式通信使用的IP地址是224.0.0.18
＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝ 

实施步骤：
一、mysql 主主同步 <略>

二、安装keepalived 
[root@tianyun ~]# yum -y install ipvsadm kernel-headers kernel-devel openssl-devel popt-devel
[root@tianyun ~]# wget http://www.keepalived.org/software/keepalived-1.2.2.tar.gz
[root@tianyun ~]# tar zxvf keepalived-1.2.2.tar.gz
[root@tianyun ~]# cd keepalived-1.2.2
[root@tianyun ~]# ./configure --prefix=/
[root@tianyun ~]# make 
[root@tianyun ~]# make install
	
三、keepalived 主备配置文件
 192.168.122.10 Master配置
 [root@tianyun ~]# vim /etc/keepalived/keepalived.conf
＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝
! Configuration File for keepalived

global_defs {
   router_id mysql1
}

vrrp_script check_run {
   script "/root/keepalived_check_mysql.sh"
   interval 5
}

vrrp_instance VI_1 {
    state MASTER
    interface eth0
    virtual_router_id 88
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass tianyun
    }

    track_script {
        check_run
    }

    virtual_ipaddress {
        192.168.122.100
    }
}

＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝



192.168.122.20 Slave配置
 [root@tianyun ~]# vim /etc/keepalived/keepalived.conf
＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝
! Configuration File for keepalived

global_defs {
   router_id mysql2
}

vrrp_script check_run {
   script "/root/keepalived_check_mysql.sh"
   interval 5
}

vrrp_instance VI_1 {
    state BACKUP
    interface eth0
    virtual_router_id 88
    priority 50
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass tianyun
    }

    track_script {
        check_run
    }

    virtual_ipaddress {
        192.168.122.100
    }
}

1. 注意空格
2. 日志查看脚本是否被执行
[root@xen2 ~]# tail -f /var/log/messages 
Jun 19 15:20:19 xen1 Keepalived_vrrp[6341]: Using LinkWatch kernel netlink reflector...
Jun 19 15:20:19 xen1 Keepalived_vrrp[6341]: VRRP sockpool: [ifindex(2), proto(112), fd(11,12)]
Jun 19 15:20:19 xen1 Keepalived_vrrp[6341]: VRRP_Script(check_run) succeeded

＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝


四、mysql状态检测脚本/root/keepalived_check_mysql.sh（两台MySQL同样的脚本）
版本一：简单使用：
#!/bin/bash
/usr/bin/mysql -uroot -p123 -e "show status" &>/dev/null 
if [ $? -ne 0 ] ;then 
	service keepalived stop
fi 


版本二：检查多次：
[root@tianyun ~]#  vim  /root/keepalived_check_mysql.sh
#!/bin/bash 
MYSQL=/usr/local/mysql/bin/mysql
MYSQL_HOST=localhost 
MYSQL_USER=root 
MYSQL_PASSWORD=tianyun
CHECK_TIME=3

#mysql  is working MYSQL_OK is 1 , mysql down MYSQL_OK is 0 
MYSQL_OK=1
 
check_mysql_helth (){ 
    $MYSQL -h $MYSQL_HOST -u $MYSQL_USER -p${MYSQL_PASSWORD} -e "show status" &>/dev/null 
    if [ $? -eq 0 ] ;then 
    	MYSQL_OK=1
    else 
    	MYSQL_OK=0 
    fi 
    return $MYSQL_OK 
}
 
while [ $CHECK_TIME -ne 0 ]
do 
    check_mysql_helth 
	if [ $MYSQL_OK -eq 1 ] ; then 
    		exit 0 
	fi
 
	if [ $MYSQL_OK -eq 0 ] &&  [ $CHECK_TIME -eq 1 ];then
     		/etc/init.d/keepalived stop					
     		exit 1								
 	fi										
	let CHECK_TIME--
 	sleep 1 
done

版本三：检查多次：
[root@tianyun ~]#  vim  /root/keepalived_check_mysql.sh
#!/bin/bash 
MYSQL=/usr/local/mysql/bin/mysql
MYSQL_HOST=localhost 
MYSQL_USER=root 
MYSQL_PASSWORD=tianyun
CHECK_TIME=3

#mysql  is working MYSQL_OK is 1 , mysql down MYSQL_OK is 0 
MYSQL_OK=1
 
check_mysql_helth (){ 
    $MYSQL -h $MYSQL_HOST -u $MYSQL_USER -p${MYSQL_PASSWORD} -e "show status" &>/dev/null 
    if [ $? -eq 0 ] ;then 
    	MYSQL_OK=1
    else 
    	MYSQL_OK=0 
    fi 
    return $MYSQL_OK 
}
 
while [ $CHECK_TIME -ne 0 ]
do 
    check_mysql_helth 
	if [ $MYSQL_OK -eq 1 ] ; then 
    		exit 0 
	fi
 
	let CHECK_TIME--
 	sleep 1 
done

/etc/init.d/keepalived stop					
exit 1				
＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝

[root@tianyun ~]# chmod 755 /root/keepalived_check_mysql.sh

两边均启动keepalived
[root@tianyun ~]# /etc/init.d/keepalived start
[root@tianyun ~]# /etc/init.d/keepalived start
[root@tianyun ~]# chkconfig --add keepalived
[root@tianyun ~]# chkconfig keepalived on
```





tomcat

```

1. 部署JAVA环境
# tar xf jdk-8u91-linux-x64.tar.gz -C /usr/local
# ln -s /usr/local/jdk1.8.0_91 /usr/local/java

# vim /etc/profile
#vim /etc/profile.d/jdk.sh    //建议使用这种方式

JAVA_HOME=/usr/local/java
PATH=$JAVA_HOME/bin:$PATH
export JAVA_HOME PATH

# source /etc/profile.d/jdk.sh        //使环境变量生效

# env |grep JAVA
JAVA_HOME=/usr/local/java
# java -version
java version "1.8.0_91"
Java(TM) SE Runtime Environment (build 1.8.0_91-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)

2. 安装Tomcat:
# tar xf apache-tomcat-7.0.34.tar.gz -C /usr/local/
# ln -s /usr/local/apache-tomcat-7.0.34 /usr/local/tomcat

定义Tomcat所需环境变量:
# vim /etc/profile.d/tomcat.sh							//定义Tomcat环境变量
CATALINA_HOME=/usr/local/tomcat								//Tomcat安装目录
export CATALINA_HOME
# source /etc/profile.d/tomcat.sh

启动Tomcat
# /usr/local/tomcat/bin/startup.sh 		//启动tomcat
Using CATALINA_BASE:   /usr/local/tomcat
Using CATALINA_HOME:   /usr/local/tomcat
Using CATALINA_TMPDIR: /usr/local/tomcat/temp
Using JRE_HOME:        /usr/java/jdk1.7.0_11
Using CLASSPATH:       /usr/local/tomcat/bin/bootstrap.jar:/usr/local/tomcat/bin/tomcat-juli.jar

# netstat -tnlp |grep java
tcp        0      0 ::ffff:127.0.0.1:8005       :::*                   LISTEN      6191/java           
tcp        0      0 :::8009                     :::*                        LISTEN      6191/java           
tcp        0      0 :::8080                     :::*                        LISTEN      6191/java  
      
# /usr/local/tomcat/bin/shutdown.sh	//关闭tomcat

```

















